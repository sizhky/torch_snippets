[
  {
    "objectID": "imgaug_loader.html",
    "href": "imgaug_loader.html",
    "title": "Imgaug",
    "section": "",
    "text": "from torch_snippets.loader import read, pd, show\n\nIM = read(\"/Users/yeshwanth.y/code/torch_snippets/assets/Preamble.png\")\nDF = pd.read_csv(\"/Users/yeshwanth.y/code/torch_snippets/assets/Preamble.csv\")\nDF = to_relative(DF, *IM.shape[:2])\nDF.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1\n\n\n\n\n\n\n\n\n\n\n\nim = IM.copy()\nim = rescale(im, sz=(400, 600))\nshow(im, sz=5)\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rescale(im, df, (400, 600))\nshow(im, df=df, sz=5)\ndf.head()\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in &lt;cell line: 3&gt;()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; df = DF.copy()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; im = IM.copy()\n----&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt; im, df = rescale(im, df, (400, 600))\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; show(im, df=df, sz=5)\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt; df.head()\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in rescale(im, bbs, sz)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=110'&gt;111&lt;/a&gt; H, W = get_size(sz, h, w)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=111'&gt;112&lt;/a&gt; aug = iaa.Resize({\"height\": H, \"width\": W})\n--&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=112'&gt;113&lt;/a&gt; im, bbs = do(im, bbs, aug)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=113'&gt;114&lt;/a&gt; if to_pil:\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=114'&gt;115&lt;/a&gt;     im = PIL.Image.fromarray(im)\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in do(img, bbs, aug, cval)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=41'&gt;42&lt;/a&gt;         __df = combine_xyXY_to_bb(__df)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=42'&gt;43&lt;/a&gt;     bbs = __df\n---&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=43'&gt;44&lt;/a&gt; if bbs == []:\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=44'&gt;45&lt;/a&gt;     return img, []\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=45'&gt;46&lt;/a&gt; return img, bbs\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:705, in _comp_method_FRAME.&lt;locals&gt;.f(self, other)\n    701 @Appender(f\"Wrapper for comparison method {op_name}\")\n    702 def f(self, other):\n    703     axis = 1  # only relevant for Series other case\n--&gt; 705     self, other = _align_method_FRAME(self, other, axis, level=None, flex=False)\n    707     # See GH#4537 for discussion of scalar op behavior\n    708     new_data = dispatch_to_series(self, other, op, axis=axis)\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:503, in _align_method_FRAME(left, right, axis, flex, level)\n    496         raise ValueError(\n    497             \"Unable to coerce to Series/DataFrame, \"\n    498             f\"dimension must be &lt;= 2: {right.shape}\"\n    499         )\n    501 elif is_list_like(right) and not isinstance(right, (ABCSeries, ABCDataFrame)):\n    502     # GH17901\n--&gt; 503     right = to_series(right)\n    505 if flex is not None and isinstance(right, ABCDataFrame):\n    506     if not left._indexed_same(right):\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:465, in _align_method_FRAME.&lt;locals&gt;.to_series(right)\n    463 else:\n    464     if len(left.columns) != len(right):\n--&gt; 465         raise ValueError(\n    466             msg.format(req_len=len(left.columns), given_len=len(right))\n    467         )\n    468     right = left._constructor_sliced(right, index=left.columns)\n    469 return right\n\nValueError: Unable to coerce to Series, length must be 6: given 0\n\n\n\n\n\n\n\nfor i in range(11):\n    angle = (i - 5) * 5\n    print(angle)\n    im = rotate(IM, angle=angle)\n    show(im, sz=1)\n\n-25\n\n\n\n\n\n\n\n\n\n-20\n\n\n\n\n\n\n\n\n\n-15\n\n\n\n\n\n\n\n\n\n-10\n\n\n\n\n\n\n\n\n\n-5\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n15\n\n\n\n\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n25\n\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rotate(im, df, 90)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.693277\n0.249538\n0.745098\n0.569316\n\n\n1\nNLTHE\n1\n0.600840\n0.288355\n0.628852\n0.401109\n\n\n2\nPEOPLE\n1\n0.600840\n0.402957\n0.628852\n0.510166\n\n\n3\nOF\n1\n0.603641\n0.493530\n0.627451\n0.545287\n\n\n4\nINDIA,\n1\n0.600840\n0.548983\n0.628852\n0.630314\n\n\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = pad(im, df, deltas=(90, 90), cval=0)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.310536\n0.302521\n0.550832\n0.343137\n\n\n1\nNLTHE\n1\n0.340111\n0.394958\n0.425139\n0.417367\n\n\n2\nPEOPLE\n1\n0.426987\n0.394958\n0.506470\n0.417367\n\n\n3\nOF\n1\n0.493530\n0.396359\n0.532348\n0.415966\n\n\n4\nINDIA,\n1\n0.536044\n0.394958\n0.597043\n0.417367\n\n\n\n\n\n\n\n\n\n\nAll functions will work with data frames that contain either of absolute/relative coordinates, and will preserve the image type (np.ndarray or PIL.Image.Image) too\n\ndf = DF.copy()\nim = IM.copy()\nheight, width = im.shape\nshow(df.head())\nim = PIL.Image.fromarray(im)\nim, df = rotate(im, df, 45, cval=127)\nim, df = pad(im, df, deltas=(200, 200), cval=0)\nim, df = rescale(im, df, sz=(300, 300))\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;class 'PIL.Image.Image'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.500000\n0.326667\n0.613333\n0.440000\n\n\n1\nNLTHE\n1\n0.473333\n0.383333\n0.516667\n0.426667\n\n\n2\nPEOPLE\n1\n0.506667\n0.416667\n0.550000\n0.460000\n\n\n3\nOF\n1\n0.536667\n0.446667\n0.560000\n0.470000\n\n\n4\nINDIA,\n1\n0.550000\n0.460000\n0.586667\n0.493333",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#section",
    "href": "imgaug_loader.html#section",
    "title": "Imgaug",
    "section": "",
    "text": "from torch_snippets.loader import read, pd, show\n\nIM = read(\"/Users/yeshwanth.y/code/torch_snippets/assets/Preamble.png\")\nDF = pd.read_csv(\"/Users/yeshwanth.y/code/torch_snippets/assets/Preamble.csv\")\nDF = to_relative(DF, *IM.shape[:2])\nDF.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#rescale",
    "href": "imgaug_loader.html#rescale",
    "title": "Imgaug",
    "section": "",
    "text": "im = IM.copy()\nim = rescale(im, sz=(400, 600))\nshow(im, sz=5)\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rescale(im, df, (400, 600))\nshow(im, df=df, sz=5)\ndf.head()\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in &lt;cell line: 3&gt;()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; df = DF.copy()\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; im = IM.copy()\n----&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt; im, df = rescale(im, df, (400, 600))\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; show(im, df=df, sz=5)\n      &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt; df.head()\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in rescale(im, bbs, sz)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=110'&gt;111&lt;/a&gt; H, W = get_size(sz, h, w)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=111'&gt;112&lt;/a&gt; aug = iaa.Resize({\"height\": H, \"width\": W})\n--&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=112'&gt;113&lt;/a&gt; im, bbs = do(im, bbs, aug)\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=113'&gt;114&lt;/a&gt; if to_pil:\n    &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=114'&gt;115&lt;/a&gt;     im = PIL.Image.fromarray(im)\n\n/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb Cell 8 in do(img, bbs, aug, cval)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=41'&gt;42&lt;/a&gt;         __df = combine_xyXY_to_bb(__df)\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=42'&gt;43&lt;/a&gt;     bbs = __df\n---&gt; &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=43'&gt;44&lt;/a&gt; if bbs == []:\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=44'&gt;45&lt;/a&gt;     return img, []\n     &lt;a href='vscode-notebook-cell:/Users/yeshwanth.y/code/torch_snippets/nbs/imgaug_loader.ipynb#W6sZmlsZQ%3D%3D?line=45'&gt;46&lt;/a&gt; return img, bbs\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:705, in _comp_method_FRAME.&lt;locals&gt;.f(self, other)\n    701 @Appender(f\"Wrapper for comparison method {op_name}\")\n    702 def f(self, other):\n    703     axis = 1  # only relevant for Series other case\n--&gt; 705     self, other = _align_method_FRAME(self, other, axis, level=None, flex=False)\n    707     # See GH#4537 for discussion of scalar op behavior\n    708     new_data = dispatch_to_series(self, other, op, axis=axis)\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:503, in _align_method_FRAME(left, right, axis, flex, level)\n    496         raise ValueError(\n    497             \"Unable to coerce to Series/DataFrame, \"\n    498             f\"dimension must be &lt;= 2: {right.shape}\"\n    499         )\n    501 elif is_list_like(right) and not isinstance(right, (ABCSeries, ABCDataFrame)):\n    502     # GH17901\n--&gt; 503     right = to_series(right)\n    505 if flex is not None and isinstance(right, ABCDataFrame):\n    506     if not left._indexed_same(right):\n\nFile ~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/__init__.py:465, in _align_method_FRAME.&lt;locals&gt;.to_series(right)\n    463 else:\n    464     if len(left.columns) != len(right):\n--&gt; 465         raise ValueError(\n    466             msg.format(req_len=len(left.columns), given_len=len(right))\n    467         )\n    468     right = left._constructor_sliced(right, index=left.columns)\n    469 return right\n\nValueError: Unable to coerce to Series, length must be 6: given 0",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#rotate",
    "href": "imgaug_loader.html#rotate",
    "title": "Imgaug",
    "section": "",
    "text": "for i in range(11):\n    angle = (i - 5) * 5\n    print(angle)\n    im = rotate(IM, angle=angle)\n    show(im, sz=1)\n\n-25\n\n\n\n\n\n\n\n\n\n-20\n\n\n\n\n\n\n\n\n\n-15\n\n\n\n\n\n\n\n\n\n-10\n\n\n\n\n\n\n\n\n\n-5\n\n\n\n\n\n\n\n\n\n0\n\n\n\n\n\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n10\n\n\n\n\n\n\n\n\n\n15\n\n\n\n\n\n\n\n\n\n20\n\n\n\n\n\n\n\n\n\n25\n\n\n\n\n\n\n\n\n\n\ndf = DF.copy()\nim = IM.copy()\nim, df = rotate(im, df, 90)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.693277\n0.249538\n0.745098\n0.569316\n\n\n1\nNLTHE\n1\n0.600840\n0.288355\n0.628852\n0.401109\n\n\n2\nPEOPLE\n1\n0.600840\n0.402957\n0.628852\n0.510166\n\n\n3\nOF\n1\n0.603641\n0.493530\n0.627451\n0.545287\n\n\n4\nINDIA,\n1\n0.600840\n0.548983\n0.628852\n0.630314",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#pad",
    "href": "imgaug_loader.html#pad",
    "title": "Imgaug",
    "section": "",
    "text": "df = DF.copy()\nim = IM.copy()\nim, df = pad(im, df, deltas=(90, 90), cval=0)\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.310536\n0.302521\n0.550832\n0.343137\n\n\n1\nNLTHE\n1\n0.340111\n0.394958\n0.425139\n0.417367\n\n\n2\nPEOPLE\n1\n0.426987\n0.394958\n0.506470\n0.417367\n\n\n3\nOF\n1\n0.493530\n0.396359\n0.532348\n0.415966\n\n\n4\nINDIA,\n1\n0.536044\n0.394958\n0.597043\n0.417367",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "imgaug_loader.html#augmentations-as-monads",
    "href": "imgaug_loader.html#augmentations-as-monads",
    "title": "Imgaug",
    "section": "",
    "text": "All functions will work with data frames that contain either of absolute/relative coordinates, and will preserve the image type (np.ndarray or PIL.Image.Image) too\n\ndf = DF.copy()\nim = IM.copy()\nheight, width = im.shape\nshow(df.head())\nim = PIL.Image.fromarray(im)\nim, df = rotate(im, df, 45, cval=127)\nim, df = pad(im, df, deltas=(200, 200), cval=0)\nim, df = rescale(im, df, sz=(300, 300))\nshow(im, df=df, sz=20)\nprint(type(im))\ndf.head()\n\n\n\n\n\n\n\n\nx\ny\nX\nY\ntext\nblock_id\n\n\n\n\n0\n0.249538\n0.253501\n0.569316\n0.305322\nConstITUtIO\n0\n\n\n1\n0.288355\n0.369748\n0.401109\n0.397759\nNLTHE\n1\n\n\n2\n0.402957\n0.369748\n0.510166\n0.397759\nPEOPLE\n1\n\n\n3\n0.493530\n0.371148\n0.545287\n0.394958\nOF\n1\n\n\n4\n0.548983\n0.369748\n0.630314\n0.397759\nINDIA,\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;class 'PIL.Image.Image'&gt;\n\n\n\n\n\n\n\n\n\ntext\nblock_id\nx\ny\nX\nY\n\n\n\n\n0\nConstITUtIO\n0\n0.500000\n0.326667\n0.613333\n0.440000\n\n\n1\nNLTHE\n1\n0.473333\n0.383333\n0.516667\n0.426667\n\n\n2\nPEOPLE\n1\n0.506667\n0.416667\n0.550000\n0.460000\n\n\n3\nOF\n1\n0.536667\n0.446667\n0.560000\n0.470000\n\n\n4\nINDIA,\n1\n0.550000\n0.460000\n0.586667\n0.493333",
    "crumbs": [
      "Imgaug"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Utilities for simple needs",
    "section": "",
    "text": "# Time it\nfrom torch_snippets import *\n\nCPU times: user 1.57 s, sys: 1.59 s, total: 3.16 s\nWall time: 731 ms\nBelow we are trying to extract the __all__ list from all Python files of the torch_snippets directory.\nThrough the code, you can already see some of the elements of torch-snippets in action.\nimport ast\n\nos.environ[\n    \"AD_MAX_ITEMS\"\n] = (  # os is already imported by torch_snippets, along with many other useful libraries\n    \"1000\"  # Set the maximum number of items to display in the AD object\n)\n\n\n@tryy  # This is a decorator that catches exceptions\ndef extract_all_list(file_path):\n    file = readfile(file_path, silent=True)  # Read the file\n    tree = ast.parse(file, filename=file_path)\n\n    for node in tree.body:\n        if isinstance(node, ast.Assign):\n            for target in node.targets:\n                if isinstance(target, ast.Name) and target.id == \"__all__\":\n                    if isinstance(node.value, ast.List):\n                        all_list = [\n                            elt.value\n                            for elt in node.value.elts\n                            if isinstance(elt, ast.Constant)\n                        ]\n                        return all_list\n    return None\n\n\ndef print_all_lists_in_directory(directory):\n    dir = P(directory)  # Create a pathlib.Path object\n    for f in dir.ls():  # Iterate over all files in the directory\n        if f.extn == \"py\" and f.stem not in [\n            \"__init__\",\n            \"_nbdev\",\n        ]:  # If it's a Python file and not __init__.py\n            all_list = extract_all_list(f)\n            if all_list is not None and len(all_list) &gt; 0:\n                h2(f.stem)  # Print the name of the file as a heading in jupyter\n                print(\n                    AD({\"items\": all_list})\n                )  # AD is an intelligent dictionary that can display itself nicely\nprint(P().resolve())\n\n/Users/yeshwanth/Code/Personal/torch_snippets/nbs\n# Specify the directory containing the Python files\ndirectory_path = \"../torch_snippets\"\nprint_all_lists_in_directory(directory_path)\n\nmisc\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - Timer (🏷️ str)\n  1 - track2 (🏷️ str)\n  2 - summarize_input (🏷️ str)\n  3 - timeit (🏷️ str)\n  4 - io (🏷️ str)\n  5 - tryy (🏷️ str)\n\n```\n\n\n\nload_defaults\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - ifnone (🏷️ str)\n  1 - exists (🏷️ str)\n  2 - loadifexists (🏷️ str)\n\n```\n\n\n\ntext_utils\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - textify (🏷️ str)\n  1 - find_lines (🏷️ str)\n  2 - find_blocks (🏷️ str)\n  3 - find_substring (🏷️ str)\n  4 - get_line_data_from_word_data (🏷️ str)\n  5 - edit_distance_path (🏷️ str)\n  6 - group_blocks (🏷️ str)\n\n```\n\n\n\npaths\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - valid_methods (🏷️ str)\n  1 - P (🏷️ str)\n  2 - ls (🏷️ str)\n  3 - print_folder_summary (🏷️ str)\n  4 - dill (🏷️ str)\n  5 - input_to_str (🏷️ str)\n  6 - output_to_path (🏷️ str)\n  7 - process_f (🏷️ str)\n  8 - get_fs (🏷️ str)\n  9 - P0 (🏷️ str)\n  10 - stem (🏷️ str)\n  11 - stems (🏷️ str)\n  12 - extn (🏷️ str)\n  13 - remove_file (🏷️ str)\n  14 - isdir (🏷️ str)\n  15 - makedir (🏷️ str)\n  16 - fname (🏷️ str)\n  17 - fname2 (🏷️ str)\n  18 - parent (🏷️ str)\n  19 - Glob (🏷️ str)\n  20 - find (🏷️ str)\n  21 - zip_files (🏷️ str)\n  22 - unzip_file (🏷️ str)\n  23 - list_zip (🏷️ str)\n  24 - md5 (🏷️ str)\n  25 - remove_duplicates (🏷️ str)\n  26 - common_items (🏷️ str)\n  27 - folder_summary (🏷️ str)\n  28 - readlines (🏷️ str)\n  29 - readfile (🏷️ str)\n  30 - writelines (🏷️ str)\n  31 - tree (🏷️ str)\n  32 - folder_structure_to_dict (🏷️ str)\n  33 - folder_structure_to_json (🏷️ str)\n  34 - rename_batch (🏷️ str)\n  35 - dumpdill (🏷️ str)\n  36 - loaddill (🏷️ str)\n\n```\n\n\n\ncharts\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - alt (🏷️ str)\n  1 - Chart (🏷️ str)\n  2 - CM (🏷️ str)\n  3 - radar (🏷️ str)\n  4 - confusion_matrix (🏷️ str)\n  5 - spider (🏷️ str)\n  6 - upsetaltair_top_level_configuration (🏷️ str)\n  7 - UpSetAltair (🏷️ str)\n\n```\n\n\n\npdf_loader\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - PDF (🏷️ str)\n  1 - dump_pdf_images (🏷️ str)\n  2 - preview_pdf (🏷️ str)\n\n```\n\n\n\ninteractive_show\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - COLORS (🏷️ str)\n  1 - to_networkx (🏷️ str)\n  2 - plot_image (🏷️ str)\n  3 - plot_graph (🏷️ str)\n  4 - tonp (🏷️ str)\n  5 - tolist (🏷️ str)\n  6 - convert_to_nx (🏷️ str)\n  7 - viz2 (🏷️ str)\n  8 - df2graph_nodes (🏷️ str)\n  9 - ishow (🏷️ str)\n\n```\n\n\n\nregistry\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - Config (🏷️ str)\n  1 - AttrDict (🏷️ str)\n  2 - registry (🏷️ str)\n  3 - tryeval (🏷️ str)\n  4 - parse_base (🏷️ str)\n  5 - parse (🏷️ str)\n  6 - parse_and_resolve (🏷️ str)\n  7 - parse_string (🏷️ str)\n\n```\n\n\n\nmarkup2\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - AD (🏷️ str)\n  1 - Config (🏷️ str)\n  2 - isnamedtupleinstance (🏷️ str)\n  3 - unpack (🏷️ str)\n  4 - AttrDict (🏷️ str)\n  5 - pretty_json (🏷️ str)\n  6 - read_json (🏷️ str)\n  7 - write_json (🏷️ str)\n  8 - write_jsonl (🏷️ str)\n  9 - read_jsonl (🏷️ str)\n  10 - read_yaml (🏷️ str)\n  11 - write_yaml (🏷️ str)\n  12 - read_xml (🏷️ str)\n  13 - write_xml (🏷️ str)\n\n```\n\n\n\ninspector\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - inspect (🏷️ str)\n\n```\n\n\n\ntorch_loader\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - torch (🏷️ str)\n  1 - th (🏷️ str)\n  2 - torchvision (🏷️ str)\n  3 - T (🏷️ str)\n  4 - transforms (🏷️ str)\n  5 - nn (🏷️ str)\n  6 - np (🏷️ str)\n  7 - F (🏷️ str)\n  8 - Dataset (🏷️ str)\n  9 - DataLoader (🏷️ str)\n  10 - optim (🏷️ str)\n  11 - Report (🏷️ str)\n  12 - Reshape (🏷️ str)\n  13 - Permute (🏷️ str)\n  14 - device (🏷️ str)\n  15 - save_torch_model_weights_from (🏷️ str)\n  16 - load_torch_model_weights_to (🏷️ str)\n  17 - detach (🏷️ str)\n  18 - cat_with_padding (🏷️ str)\n\n```\n\n\n\nlogger\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - console (🏷️ str)\n  1 - reset_logger_width (🏷️ str)\n  2 - logger (🏷️ str)\n  3 - Trace (🏷️ str)\n  4 - Debug (🏷️ str)\n  5 - Info (🏷️ str)\n  6 - Warn (🏷️ str)\n  7 - Excep (🏷️ str)\n  8 - warn_mode (🏷️ str)\n  9 - info_mode (🏷️ str)\n  10 - debug_mode (🏷️ str)\n  11 - trace_mode (🏷️ str)\n  12 - excep_mode (🏷️ str)\n  13 - in_warn_mode (🏷️ str)\n  14 - in_info_mode (🏷️ str)\n  15 - in_debug_mode (🏷️ str)\n  16 - in_trace_mode (🏷️ str)\n  17 - in_excep_mode (🏷️ str)\n  18 - frames (🏷️ str)\n  19 - get_console (🏷️ str)\n  20 - reset_logger (🏷️ str)\n  21 - get_logger_level (🏷️ str)\n  22 - logger_mode (🏷️ str)\n  23 - in_logger_mode (🏷️ str)\n  24 - notify_waiting (🏷️ str)\n\n```\n\n\n\nmarkup\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - AttrDict (🏷️ str)\n  1 - json (🏷️ str)\n  2 - Config (🏷️ str)\n  3 - isnamedtupleinstance (🏷️ str)\n  4 - unpack (🏷️ str)\n  5 - hash_tensor (🏷️ str)\n  6 - hash_pandas_dataframe (🏷️ str)\n  7 - AttrDictDeprecated (🏷️ str)\n  8 - decompose (🏷️ str)\n  9 - pretty_json (🏷️ str)\n  10 - read_json (🏷️ str)\n  11 - write_json (🏷️ str)\n  12 - write_jsonl (🏷️ str)\n  13 - read_jsonl (🏷️ str)\n  14 - read_yaml (🏷️ str)\n  15 - write_yaml (🏷️ str)\n  16 - read_xml (🏷️ str)\n  17 - write_xml (🏷️ str)\n\n```\n\n\n\nsklegos\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - ColumnSelector (🏷️ str)\n  1 - GroupedPredictor (🏷️ str)\n  2 - EstimatorTransformer (🏷️ str)\n  3 - train_test_split (🏷️ str)\n  4 - MakeFrame (🏷️ str)\n  5 - ImputeMissingValues (🏷️ str)\n  6 - LambdaTransformer (🏷️ str)\n  7 - Cat2Num (🏷️ str)\n  8 - SplitDateColumn (🏷️ str)\n\n```\n\n\n\nipython\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - save_notebook (🏷️ str)\n  1 - backup_this_notebook (🏷️ str)\n  2 - backup_all_notebooks (🏷️ str)\n  3 - backup_folders_of_nbs (🏷️ str)\n  4 - display_dfs_side_by_side (🏷️ str)\n  5 - show_big_dataframe (🏷️ str)\n  6 - h1 (🏷️ str)\n  7 - h2 (🏷️ str)\n  8 - h3 (🏷️ str)\n  9 - h4 (🏷️ str)\n  10 - h5 (🏷️ str)\n  11 - h6 (🏷️ str)\n  12 - store_scrap (🏷️ str)\n  13 - shutdown_current_notebook (🏷️ str)\n\n```\n\n\n\n../torch_snippets/loader.py:532: SyntaxWarning: invalid escape sequence '\\$'\n  puttext(ax, text.replace(\"$\", \"\\$\"), tuple(bbs[ix][:2]), size=text_sz)\n\n\nloader\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - B (🏷️ str)\n  1 - Blank (🏷️ str)\n  2 - batchify (🏷️ str)\n  3 - C (🏷️ str)\n  4 - choose (🏷️ str)\n  5 - common (🏷️ str)\n  6 - crop_from_bb (🏷️ str)\n  7 - diff (🏷️ str)\n  8 - E (🏷️ str)\n  9 - flatten (🏷️ str)\n  10 - Image (🏷️ str)\n  11 - jitter (🏷️ str)\n  12 - L (🏷️ str)\n  13 - lzip (🏷️ str)\n  14 - line (🏷️ str)\n  15 - lines (🏷️ str)\n  16 - to_absolute (🏷️ str)\n  17 - to_relative (🏷️ str)\n  18 - enlarge_bbs (🏷️ str)\n  19 - shrink_bbs (🏷️ str)\n  20 - logger (🏷️ str)\n  21 - np (🏷️ str)\n  22 - now (🏷️ str)\n  23 - nunique (🏷️ str)\n  24 - os (🏷️ str)\n  25 - pad (🏷️ str)\n  26 - pd (🏷️ str)\n  27 - pdfilter (🏷️ str)\n  28 - pdb (🏷️ str)\n  29 - PIL (🏷️ str)\n  30 - print (🏷️ str)\n  31 - puttext (🏷️ str)\n  32 - randint (🏷️ str)\n  33 - rand (🏷️ str)\n  34 - re (🏷️ str)\n  35 - read (🏷️ str)\n  36 - readPIL (🏷️ str)\n  37 - rect (🏷️ str)\n  38 - resize (🏷️ str)\n  39 - rotate (🏷️ str)\n  40 - see (🏷️ str)\n  41 - show (🏷️ str)\n  42 - store_attr (🏷️ str)\n  43 - subplots (🏷️ str)\n  44 - sys (🏷️ str)\n  45 - toss (🏷️ str)\n  46 - track (🏷️ str)\n  47 - tqdm (🏷️ str)\n  48 - Tqdm (🏷️ str)\n  49 - trange (🏷️ str)\n  50 - unique (🏷️ str)\n  51 - uint (🏷️ str)\n  52 - write (🏷️ str)\n  53 - BB (🏷️ str)\n  54 - bbfy (🏷️ str)\n  55 - xywh2xyXY (🏷️ str)\n  56 - df2bbs (🏷️ str)\n  57 - bbs2df (🏷️ str)\n  58 - Info (🏷️ str)\n  59 - Warn (🏷️ str)\n  60 - Debug (🏷️ str)\n  61 - Excep (🏷️ str)\n  62 - reset_logger (🏷️ str)\n  63 - get_logger_level (🏷️ str)\n  64 - in_debug_mode (🏷️ str)\n  65 - debug_mode (🏷️ str)\n  66 - typedispatch (🏷️ str)\n  67 - defaultdict (🏷️ str)\n  68 - Counter (🏷️ str)\n  69 - dcopy (🏷️ str)\n  70 - patch_to (🏷️ str)\n  71 - split (🏷️ str)\n  72 - train_test_split (🏷️ str)\n  73 - init_plt (🏷️ str)\n  74 - init_cv2 (🏷️ str)\n\n```\n\n\n\nimgaug_loader\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - do (🏷️ str)\n  1 - bw (🏷️ str)\n  2 - rotate (🏷️ str)\n  3 - pad (🏷️ str)\n  4 - get_size (🏷️ str)\n  5 - rescale (🏷️ str)\n  6 - crop (🏷️ str)\n  7 - imgaugbbs2bbs (🏷️ str)\n  8 - bbs2imgaugbbs (🏷️ str)\n\n```\n\n\n\ndates\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - make_uniform_date_format (🏷️ str)\n  1 - ALL_DATE_FORMATS (🏷️ str)\n  2 - are_dates_equal (🏷️ str)\n  3 - today (🏷️ str)\n\n```\n\n\n\nprofiler\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - time_profiler (🏷️ str)\n\n```\n\n\n\nbokeh_loader\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - parse_sz (🏷️ str)\n  1 - get_bplot (🏷️ str)\n\n```\n\n\n\nbb_utils\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - randint (🏷️ str)\n  1 - BB (🏷️ str)\n  2 - df2bbs (🏷️ str)\n  3 - bbs2df (🏷️ str)\n  4 - bbfy (🏷️ str)\n  5 - jitter (🏷️ str)\n  6 - compute_eps (🏷️ str)\n  7 - enlarge_bbs (🏷️ str)\n  8 - shrink_bbs (🏷️ str)\n  9 - iou (🏷️ str)\n  10 - compute_distance_matrix (🏷️ str)\n  11 - compute_distances (🏷️ str)\n  12 - split_bb_to_xyXY (🏷️ str)\n  13 - combine_xyXY_to_bb (🏷️ str)\n  14 - is_absolute (🏷️ str)\n  15 - is_relative (🏷️ str)\n  16 - to_relative (🏷️ str)\n  17 - to_absolute (🏷️ str)\n  18 - merge_by_bb (🏷️ str)\n  19 - isin (🏷️ str)\n\n```\n\n\n\nadapters\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - np_2_b64 (🏷️ str)\n  1 - b64_2_np (🏷️ str)\n  2 - b64_2_file (🏷️ str)\n  3 - bytes_2_file (🏷️ str)\n  4 - file_2_bytes (🏷️ str)\n  5 - csvs_2_cvat (🏷️ str)\n  6 - cvat_2_csvs (🏷️ str)\n  7 - df_2_yolo (🏷️ str)\n  8 - yolo_2_df (🏷️ str)\n\n```\n\n\n\ndecorators\n\n\n\n```↯ AttrDict ↯\nitems[]\n  0 - format (🏷️ str)\n  1 - warn_on_fail (🏷️ str)\n  2 - timeit (🏷️ str)\n  3 - io (🏷️ str)\n  4 - check_kwargs_not_none (🏷️ str)\n\n```",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#misc",
    "href": "index.html#misc",
    "title": "Utilities for simple needs",
    "section": "misc",
    "text": "misc",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#load_defaults",
    "href": "index.html#load_defaults",
    "title": "Utilities for simple needs",
    "section": "load_defaults",
    "text": "load_defaults",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#text_utils",
    "href": "index.html#text_utils",
    "title": "Utilities for simple needs",
    "section": "text_utils",
    "text": "text_utils",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#paths",
    "href": "index.html#paths",
    "title": "Utilities for simple needs",
    "section": "paths",
    "text": "paths",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#charts",
    "href": "index.html#charts",
    "title": "Utilities for simple needs",
    "section": "charts",
    "text": "charts",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#pdf_loader",
    "href": "index.html#pdf_loader",
    "title": "Utilities for simple needs",
    "section": "pdf_loader",
    "text": "pdf_loader",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#interactive_show",
    "href": "index.html#interactive_show",
    "title": "Utilities for simple needs",
    "section": "interactive_show",
    "text": "interactive_show",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#registry",
    "href": "index.html#registry",
    "title": "Utilities for simple needs",
    "section": "registry",
    "text": "registry",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#markup2",
    "href": "index.html#markup2",
    "title": "Utilities for simple needs",
    "section": "markup2",
    "text": "markup2",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#inspector",
    "href": "index.html#inspector",
    "title": "Utilities for simple needs",
    "section": "inspector",
    "text": "inspector",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#torch_loader",
    "href": "index.html#torch_loader",
    "title": "Utilities for simple needs",
    "section": "torch_loader",
    "text": "torch_loader",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#logger",
    "href": "index.html#logger",
    "title": "Utilities for simple needs",
    "section": "logger",
    "text": "logger",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#markup",
    "href": "index.html#markup",
    "title": "Utilities for simple needs",
    "section": "markup",
    "text": "markup",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#sklegos",
    "href": "index.html#sklegos",
    "title": "Utilities for simple needs",
    "section": "sklegos",
    "text": "sklegos",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#ipython",
    "href": "index.html#ipython",
    "title": "Utilities for simple needs",
    "section": "ipython",
    "text": "ipython",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#loader",
    "href": "index.html#loader",
    "title": "Utilities for simple needs",
    "section": "loader",
    "text": "loader",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#imgaug_loader",
    "href": "index.html#imgaug_loader",
    "title": "Utilities for simple needs",
    "section": "imgaug_loader",
    "text": "imgaug_loader",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#dates",
    "href": "index.html#dates",
    "title": "Utilities for simple needs",
    "section": "dates",
    "text": "dates",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#profiler",
    "href": "index.html#profiler",
    "title": "Utilities for simple needs",
    "section": "profiler",
    "text": "profiler",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#bokeh_loader",
    "href": "index.html#bokeh_loader",
    "title": "Utilities for simple needs",
    "section": "bokeh_loader",
    "text": "bokeh_loader",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#bb_utils",
    "href": "index.html#bb_utils",
    "title": "Utilities for simple needs",
    "section": "bb_utils",
    "text": "bb_utils",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#adapters",
    "href": "index.html#adapters",
    "title": "Utilities for simple needs",
    "section": "adapters",
    "text": "adapters",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "index.html#decorators",
    "href": "index.html#decorators",
    "title": "Utilities for simple needs",
    "section": "decorators",
    "text": "decorators",
    "crumbs": [
      "Utilities for simple needs"
    ]
  },
  {
    "objectID": "bokeh_plotting.html",
    "href": "bokeh_plotting.html",
    "title": "Bokeh Plots",
    "section": "",
    "text": "bplot = get_bplot()\nbplot.line(np.arange(100), np.cumsum(np.random.uniform(size=100)))\nbshow(bplot)",
    "crumbs": [
      "Bokeh Plots"
    ]
  },
  {
    "objectID": "logging.html",
    "href": "logging.html",
    "title": "Rich Logging and printing",
    "section": "",
    "text": "Logging is packed in these 5 functions\n\nreset_logger(\"trace\", console_width=80)\nTrace(\"Testing {1,2,3}\")\nDebug(\"TESTING {1,2,3}\")\nInfo(\"TESTING {1,2,3}\")\nWarn(\"TESTING {1,2,3}\")\nExcep(\"TESTING {1,2,3}\")\n\n[08/24/24 12:16:05] TRACE    Testing {1,2,3}            1838145784.py:&lt;module&gt;:2\n\n\n\n                    DEBUG    TESTING {1,2,3}            1838145784.py:&lt;module&gt;:3\n\n\n\n                    INFO     TESTING {1,2,3}            1838145784.py:&lt;module&gt;:4\n\n\n\n                    WARNING  TESTING {1,2,3}            1838145784.py:&lt;module&gt;:5\n\n\n\n                    ERROR    TESTING {1,2,3}            1838145784.py:&lt;module&gt;:6\n                             NoneType: None                                     \n                                                                                \n                                                                                \n\n\n\nExcep will also print a traceback\n\ndef do():\n    try:\n        1 / 0\n    except Exception as e:\n        Excep(e)\n\n\ndef do2():\n    do()\n\n\ndo2()\n\n[08/24/24 12:16:07] ERROR    division by zero                 1923207781.py:do:5\n                             ZeroDivisionError: division by                     \n                             zero                                               \n                                                                                \n                             ╭─ Traceback (most recent call─╮                   \n                             │ in do:3                      │                   \n                             │                              │                   \n                             │    1 def do():               │                   \n                             │    2 │   try:                │                   \n                             │ ❱  3 │   │   1 / 0           │                   \n                             │    4 │   except Exception as │                   \n                             │    5 │   │   Excep(e)        │                   \n                             │    6                         │                   \n                             ╰──────────────────────────────╯                   \n                             ZeroDivisionError: division by                     \n                             zero                                               \n\n\n\nAll logging functions have an optional depth that will be helpful to raise the context level to outer functions\n\ndef do():\n    Info(\"In do\")\n\n\ndo()\n\n[08/24/24 12:16:15] INFO     In do                             809811040.py:do:2\n\n\n\n\ndef do2():\n    Info(\"Log will still say it is from `do2` now, to the right of log print\")\n\n\ndef do():\n    do2()\n\n\ndo()\n\n[08/24/24 12:17:13] INFO     Log will still say it is from   2099333876.py:do2:2\n                             `do2` now, to the right of log                     \n                             print                                              \n\n\n\n\ndef do2():\n    Info(\"But now, log will still say it is from do\", depth=1)\n\n\ndef do():\n    do2()\n\n\ndo()\n\n[08/24/24 12:17:25] INFO     But now, log will still say it   4054019042.py:do:5\n                             is from do",
    "crumbs": [
      "Rich Logging and printing"
    ]
  },
  {
    "objectID": "logging.html#ez-logging",
    "href": "logging.html#ez-logging",
    "title": "Rich Logging and printing",
    "section": "",
    "text": "Logging is packed in these 5 functions\n\nreset_logger(\"trace\", console_width=80)\nTrace(\"Testing {1,2,3}\")\nDebug(\"TESTING {1,2,3}\")\nInfo(\"TESTING {1,2,3}\")\nWarn(\"TESTING {1,2,3}\")\nExcep(\"TESTING {1,2,3}\")\n\n[08/24/24 12:16:05] TRACE    Testing {1,2,3}            1838145784.py:&lt;module&gt;:2\n\n\n\n                    DEBUG    TESTING {1,2,3}            1838145784.py:&lt;module&gt;:3\n\n\n\n                    INFO     TESTING {1,2,3}            1838145784.py:&lt;module&gt;:4\n\n\n\n                    WARNING  TESTING {1,2,3}            1838145784.py:&lt;module&gt;:5\n\n\n\n                    ERROR    TESTING {1,2,3}            1838145784.py:&lt;module&gt;:6\n                             NoneType: None                                     \n                                                                                \n                                                                                \n\n\n\nExcep will also print a traceback\n\ndef do():\n    try:\n        1 / 0\n    except Exception as e:\n        Excep(e)\n\n\ndef do2():\n    do()\n\n\ndo2()\n\n[08/24/24 12:16:07] ERROR    division by zero                 1923207781.py:do:5\n                             ZeroDivisionError: division by                     \n                             zero                                               \n                                                                                \n                             ╭─ Traceback (most recent call─╮                   \n                             │ in do:3                      │                   \n                             │                              │                   \n                             │    1 def do():               │                   \n                             │    2 │   try:                │                   \n                             │ ❱  3 │   │   1 / 0           │                   \n                             │    4 │   except Exception as │                   \n                             │    5 │   │   Excep(e)        │                   \n                             │    6                         │                   \n                             ╰──────────────────────────────╯                   \n                             ZeroDivisionError: division by                     \n                             zero                                               \n\n\n\nAll logging functions have an optional depth that will be helpful to raise the context level to outer functions\n\ndef do():\n    Info(\"In do\")\n\n\ndo()\n\n[08/24/24 12:16:15] INFO     In do                             809811040.py:do:2\n\n\n\n\ndef do2():\n    Info(\"Log will still say it is from `do2` now, to the right of log print\")\n\n\ndef do():\n    do2()\n\n\ndo()\n\n[08/24/24 12:17:13] INFO     Log will still say it is from   2099333876.py:do2:2\n                             `do2` now, to the right of log                     \n                             print                                              \n\n\n\n\ndef do2():\n    Info(\"But now, log will still say it is from do\", depth=1)\n\n\ndef do():\n    do2()\n\n\ndo()\n\n[08/24/24 12:17:25] INFO     But now, log will still say it   4054019042.py:do:5\n                             is from do",
    "crumbs": [
      "Rich Logging and printing"
    ]
  },
  {
    "objectID": "logging.html#logging-level-and-context",
    "href": "logging.html#logging-level-and-context",
    "title": "Rich Logging and printing",
    "section": "Logging Level and context",
    "text": "Logging Level and context\n\n\nin_logger_mode\n\n in_logger_mode (level:str)\n\nreturn’s T/F, checking if logger is in a specific mode or not\n\n\n\nlogger_mode\n\n logger_mode (level)\n\ntemporarily, using with context, set the level to something else\n\n\n\nget_logger_level\n\n get_logger_level ()\n\nget the current logger’s level\nLet’s log every level in the do function below. We can control what we need to log from outside the function’s context by\nusing with &lt;level&gt;_model():\n\ndef do():\n    Trace(0)\n    Debug(1)\n    Info(2)\n    Warn(3)\n    Excep(4)\n\n\ndef line(x):\n    sep = \"=\" * 20\n    print(f\"{sep}{x}{sep}\")\n    print(f\"{in_excep_mode()=}\")\n    print(f\"{in_warn_mode()=}\")\n    print(f\"{in_info_mode()=}\")\n    print(f\"{in_debug_mode()=}\")\n    print(f\"{in_trace_mode()=}\")\n\n\nreset_logger()\n\nwith excep_mode():\n    line(\"Excep mode\")\n    do()\n\nwith warn_mode():\n    line(\"Warn mode\")\n    do()\n\nwith info_mode():\n    line(\"Info mode\")\n    do()\n\nwith debug_mode():\n    line(\"Debug mode\")\n    do()\n\nwith trace_mode():\n    line(\"Trace mode\")\n    do()\n\n====================Excep mode====================\nin_excep_mode()=True\nin_warn_mode()=False\nin_info_mode()=False\nin_debug_mode()=False\nin_trace_mode()=False\n\n\n[08/24/24 12:13:08] ERROR    4                                                                                                                            3432048509.py:do:6\n                             NoneType: None                                                                                                                                 \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n====================Warn mode====================\nin_excep_mode()=False\nin_warn_mode()=True\nin_info_mode()=False\nin_debug_mode()=False\nin_trace_mode()=False\n\n\n[08/24/24 12:13:08] WARNING  3                                                                                                                            3432048509.py:do:5\n\n\n\n                    ERROR    4                                                                                                                            3432048509.py:do:6\n                             NoneType: None                                                                                                                                 \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n====================Info mode====================\nin_excep_mode()=False\nin_warn_mode()=False\nin_info_mode()=True\nin_debug_mode()=False\nin_trace_mode()=False\n\n\n[08/24/24 12:13:08] INFO     2                                                                                                                            3432048509.py:do:4\n\n\n\n                    WARNING  3                                                                                                                            3432048509.py:do:5\n\n\n\n                    ERROR    4                                                                                                                            3432048509.py:do:6\n                             NoneType: None                                                                                                                                 \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n====================Debug mode====================\nin_excep_mode()=False\nin_warn_mode()=False\nin_info_mode()=False\nin_debug_mode()=True\nin_trace_mode()=False\n\n\n[08/24/24 12:13:08] DEBUG    1                                                                                                                            3432048509.py:do:3\n\n\n\n                    INFO     2                                                                                                                            3432048509.py:do:4\n\n\n\n                    WARNING  3                                                                                                                            3432048509.py:do:5\n\n\n\n                    ERROR    4                                                                                                                            3432048509.py:do:6\n                             NoneType: None                                                                                                                                 \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n====================Trace mode====================\nin_excep_mode()=False\nin_warn_mode()=False\nin_info_mode()=False\nin_debug_mode()=False\nin_trace_mode()=True\n\n\n[08/24/24 12:13:08] TRACE    0                                                                                                                            3432048509.py:do:2\n\n\n\n                    DEBUG    1                                                                                                                            3432048509.py:do:3\n\n\n\n                    INFO     2                                                                                                                            3432048509.py:do:4\n\n\n\n                    WARNING  3                                                                                                                            3432048509.py:do:5\n\n\n\n                    ERROR    4                                                                                                                            3432048509.py:do:6\n                             NoneType: None                                                                                                                                 \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\nThe in_&lt;level&gt;_mode gives an additional layer of control, to be used for debugging dynamically. Let’s say, you want to show an image (for the sake of debugging)\n\ndef do(im_path):\n    from torch_snippets import show, read\n\n    im = read(im_path)\n    show(im, sz=3)\n    print(im.mean())\n\n\ndo(\"assets/Preamble.png\")\n\n145.5542982442515\n\n\n\n\n\n\n\n\n\nBut now you are happy with your code and don’t want the show, say the code is going to production. A common way out is to just comment that line\n\ndef do(im_path):\n    from torch_snippets import show, read\n\n    im = read(im_path)\n    # show(im, sz=3) # line is commented, but will need to be re-uncommented any time it needs debugging\n    print(im.mean())\n\n\ndo(\"assets/Preamble.png\")\n\n145.5542982442515\n\n\nBut if you want to re-check, it’s a pain to again uncomment. Not to mention this method is not scalable to 100s of lines of code. The simple way to deal with such transient code that needs to activate only when you want it to, is to enclose in an if in_&lt;level&gt;_mode conditional like so\n\ndef do(im_path):\n    from torch_snippets import show, read\n\n    im = read(im_path)\n    if in_debug_mode():\n        show(im, sz=3)\n    print(im.mean())\n\n\ndo(\"assets/Preamble.png\")\n\n145.5542982442515\n\n\nThis way, you can always activate the show by calling do with a temporary with_debug_mode context\n\nwith debug_mode():\n    do(\"assets/Preamble.png\")\n\n\n\n\n\n\n\n\n145.5542982442515",
    "crumbs": [
      "Rich Logging and printing"
    ]
  },
  {
    "objectID": "logging.html#notify-waiting",
    "href": "logging.html#notify-waiting",
    "title": "Rich Logging and printing",
    "section": "Notify Waiting",
    "text": "Notify Waiting\n\nreset_logger(console_width=100)\n\nwith trace_mode():\n    with notify_waiting(\"Downloading\"):\n        time.sleep(10)\n\nwith notify_waiting(\"Downloading\", spinner=\"guess_the_movie\"):\n    time.sleep(10)\n\nwith notify_waiting(\"One more message\", spinner=\"earth\"):\n    time.sleep(3)\n\n[08/24/24 12:36:51] TRACE    Available Spinners: dict_keys(['dots', 'dots2', 'dots3', 'dots4', 'dots5', 'dots6', 'dots7', 'dots8', 'dots9',  3340474699.py:notify_waiting:41\n                             'dots10', 'dots11', 'dots12', 'dots8Bit', 'line', 'line2', 'pipe', 'simpleDots', 'simpleDotsScrolling', 'star',                                \n                             'star2', 'flip', 'hamburger', 'growVertical', 'growHorizontal', 'balloon', 'balloon2', 'noise', 'bounce',                                      \n                             'boxBounce', 'boxBounce2', 'triangle', 'arc', 'circle', 'squareCorners', 'circleQuarters', 'circleHalves',                                     \n                             'squish', 'toggle', 'toggle2', 'toggle3', 'toggle4', 'toggle5', 'toggle6', 'toggle7', 'toggle8', 'toggle9',                                    \n                             'toggle10', 'toggle11', 'toggle12', 'toggle13', 'arrow', 'arrow2', 'arrow3', 'bouncingBar', 'bouncingBall',                                    \n                             'smiley', 'monkey', 'hearts', 'clock', 'earth', 'material', 'moon', 'runner', 'pong', 'shark', 'dqpb',                                         \n                             'weather', 'christmas', 'grenade', 'point', 'layer', 'betaWave', 'aesthetic', 'guess', 'guess_the_movie'])                                     \n                                                                                                                                                                            \n                             Using: clock                                                                                                                                   \n\n\n\n\n\n\n\n\n\n[08/24/24 12:37:01] INFO     Downloading - Completed in 10.01 s                                                                                   contextlib.py:__exit__:144\n\n\n\n\n\n\n\n\n\n[08/24/24 12:37:11] INFO     Downloading - Completed in 10.01 s                                                                                   contextlib.py:__exit__:144\n\n\n\n\n\n\n\n\n\n[08/24/24 12:37:14] INFO     One more message - Completed in 3.00 s                                                                               contextlib.py:__exit__:144",
    "crumbs": [
      "Rich Logging and printing"
    ]
  },
  {
    "objectID": "report.html#section",
    "href": "report.html#section",
    "title": "torch_snippets",
    "section": "",
    "text": "from torch_snippets.torch_loader import Report\nimport numpy as np\nimport time\n\n\nn_epochs = 3\nreport = Report(n_epochs)\nrandom_walker1 = 0\nrandom_walker2 = 0\n\nfor epoch in range(n_epochs):\n    for ix in range(1000):\n        report.record(\n            pos=epoch + (ix + 1) / 1000,\n            loss=random_walker1,\n            val_loss=random_walker2,\n            end=\"\\r\",\n        )\n        random_walker1 += np.random.normal()\n        random_walker2 += np.random.normal()\n        time.sleep(0.001)\n    report.report_avgs(epoch + 1)\n\nreport.plot()\n\nEPOCH: 1.000    loss: -6.503    val_loss: -3.093    (1.19s - 2.38s remaining)))\nEPOCH: 2.000    loss: 48.754    val_loss: -6.265    (2.37s - 1.18s remaining))\nEPOCH: 3.000    loss: 38.115    val_loss: -29.732   (3.54s - 0.00s remaining)\n\n\n\n\n\n\n\n\n\n\nn_epochs = 5\nreport = Report(n_epochs, old_report=report)\n\nfor epoch in range(n_epochs):\n    for ix in range(1000):\n        report.record(\n            pos=epoch + (ix + 1) / 1000,\n            loss=random_walker1,\n            val_loss=random_walker2,\n            end=\"\\r\",\n        )\n        random_walker1 += np.random.normal()\n        random_walker2 += np.random.normal()\n        time.sleep(0.001)\n    report.report_avgs(epoch + 1)\n\nEPOCH: 1.000    loss: 29.338    val_loss: -74.955   (1.17s - 4.70s remaining))\nEPOCH: 2.000    loss: 0.340 val_loss: -110.763  (2.35s - 3.52s remaining)))\nEPOCH: 3.000    loss: 30.617    val_loss: -84.599   (3.51s - 2.34s remaining))\nEPOCH: 4.000    loss: 34.309    val_loss: -27.520   (4.68s - 1.17s remaining)\nEPOCH: 5.000    loss: 15.252    val_loss: -46.033   (5.85s - 0.00s remaining)\n\n\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nax.vlines(0, -100, 100, colors=[\"red\"])\nreport.plot(ax=ax)",
    "crumbs": [
      "Report"
    ]
  },
  {
    "objectID": "registry.html",
    "href": "registry.html",
    "title": "Registry",
    "section": "",
    "text": "Suppose you have a file called config.ini like so…\n\n!cat /tmp/config.ini\n\n\n[META]\nversion = 0.0.1\nname = mnist\nroot = /home/me/projects/${META.name}\ndescription = This is a sample\n    config file with a multiline\n    description. These are useful for\n    project descriptions/changelog/devnotes etc...\n\n[Data]\nsource = https://files.fast.ai/data/examples/mnist_tiny.tgz\nroot = ${META.root}/data/\n\n[misc]\nx = 1\ny = 20\nz = float(${x}*${y}**2)\na = ['hello','hi','how','are','you', ${x}*${z}*${y}]\nb = {\"hi\": 1, \"hello\": 2}\n\n[load]\n    [load.test]\n    @load = print_root_location\n    root = ${Data.root}\n    \n    [load.csv]\n    @load = load_csv_function\n    root = ${Data.root}\n    \n    [load.json]\n    @load = load_json_class\n    root = ${Data.root}\n    \n    \n\n\n\nYou can load it up as an AttrDict\n\nconfig = parse(\"/tmp/config.ini\")\nassert config.META.version == \"0.0.1\"\nassert config.META.root == \"/home/me/projects/mnist\"\nassert isinstance(config.misc.b, AttrDict), type(config.project.data.b)\nassert isinstance(config.misc.a, L)\n\nNotice, how the ${} variables got resolved.\nNot just that, the varaible z got computed on the fly.\nNot just that, some of the variables like list and dict got resolved into their respective python data structures.\n\nconfig.pretty()\n\n{\n    \"Data\": {\n        \"root\": \"/home/me/projects/mnist/data/\",\n        \"source\": \"https://files.fast.ai/data/examples/mnist_tiny.tgz\"\n    },\n    \"META\": {\n        \"description\": \"This is a sample\\nconfig file with a multiline\\ndescription. These are useful for\\nproject \ndescriptions/changelog/devnotes etc...\",\n        \"name\": \"mnist\",\n        \"root\": \"/home/me/projects/mnist\",\n        \"version\": \"0.0.1\"\n    },\n    \"load\": {\n        \"csv\": {\n            \"@load\": null,\n            \"root\": \"/home/me/projects/mnist/data/\"\n        },\n        \"json\": {\n            \"@load\": \"load_json_class\",\n            \"root\": \"/home/me/projects/mnist/data/\"\n        },\n        \"test\": {\n            \"@load\": \"print_root_location\",\n            \"root\": \"/home/me/projects/mnist/data/\"\n        }\n    },\n    \"misc\": {\n        \"a\": [\n            \"hello\",\n            \"hi\",\n            \"how\",\n            \"are\",\n            \"you\",\n            8000.0\n        ],\n        \"b\": {\n            \"hello\": 2,\n            \"hi\": 1\n        },\n        \"x\": 1,\n        \"y\": 20,\n        \"z\": 400.0\n    }\n}\n\n\n\n\nprint(config.META.description)\n\nThis is a sample\nconfig file with a multiline\ndescription. These are useful for\nproject descriptions/changelog/devnotes etc...\n\n\nYou can also register/call python functions/callables/classes/objects to strings by running\n\nregistry.create(\"load\")\n\n\n@registry.load.register(\"print_root_location\")\ndef printer(root):\n    return root\n\n\n@registry.load.register(\"load_csv_function\")\ndef _load_csv_function(root):\n    def load_csv_function(file):\n        return f\"Loading file from {root}/{file}\"\n\n    return load_csv_function\n\n\n@registry.load.register(\"load_json_class\")\nclass JsonLoader:\n    def __init__(self, root):\n        self.root = root\n\n    def __call__(self, file):\n        assert file.endswith(\"json\")\n        return f\"Loading file from {self.root}/{file}\"\n\n… and resolve them on parse\n\nconfig = parse_and_resolve(\"/tmp/config.ini\")\n\n\nconfig.load.test\n\n'/home/me/projects/mnist/data/'\n\n\n\nconfig.load.csv(file=\"file.csv\")\n\n'Loading file from /home/me/projects/mnist/data//file.csv'\n\n\n\nconfig.load.json(file=\"file.json\")\n\n'Loading file from /home/me/projects/mnist/data//file.json'",
    "crumbs": [
      "Registry"
    ]
  },
  {
    "objectID": "config.html",
    "href": "config.html",
    "title": "torch_snippets",
    "section": "",
    "text": "DeepLearningConfig\n\n DeepLearningConfig ()\n\n*A configuration class for deep learning models.\nThis class provides methods to access and manipulate configuration settings.\nAttributes: input_variables (list): List of input variables defined in the class constructor.\nMethods: keys(): Returns the list of input variables. getitem(key): Returns the value of the specified key. contains(key): Checks if the specified key is present in the input variables. from_ini_file(filepath, config_root=None): Creates an instance of the class from an INI file. repr(): Returns a string representation of the class.\nExample usage: config = DeepLearningConfig() config.from_ini_file(‘config.ini’) print(config.keys()) print(config[‘learning_rate’])*\n\nfrom torch_snippets.registry import parse_string\nfrom torch_snippets.torch_loader import *\nfrom torch_snippets import writelines\n\n\nconfig_str = \"\"\"\n[META]\nexperiment = mnist.v1\ndescription = Training MLP with \n    mnist data on 10k images only\n    using huggingface trainer and \n    cosine annealing\n\n[ModelConfig]\nn_layers = 3\nn_hidden = 256\nn_classes = 10\n\n[DatasetConfig]\nroot = /home/datasets/mnist\ntrain = ${root}/train\nval = ${root}/val\ntrain_subset = 10000\nval_subest = ${train_subset}//10\n\n[TrainingConfig]\nmax_steps = ${DatasetConfig.train_subset} * 5\nlearning_rate = 3e-4\noutput_dir = ./results/${META.experiment}\nper_device_train_batch_size = 256\nper_device_eval_batch_size = ${per_device_train_batch_size}\nevaluation_strategy = \"steps\"\neval_steps = 500\nlogging_strategy = ${evaluation_strategy}\nlogging_steps = ${eval_steps}//100\nsave_strategy = ${evaluation_strategy}\nsave_steps = ${eval_steps}\nsave_total_limit = 1\nseed = 1234\nlabel_names = ['targets']\nlr_scheduler_type = cosine\n\"\"\".strip()\n\nconfig = parse_string(config_str)\n\n\nclass MNIST(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(768, config.n_hidden),\n            *[\n                nn.Sequential(nn.Linear(config.n_hidden, config.n_hidden), nn.ReLU())\n                for _ in range(config.n_layers - 1)\n            ],\n            nn.Linear(config.n_hidden, config.n_classes)\n        )\n\n    def forward(self, images): ...\n\n\nmodel = MNIST(config.ModelConfig)\nprint(model)\n\nMNIST(\n  (model): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (2): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (3): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n\n\nIf needed, configs can be unpacked like a dictionary too\n\nclass MNIST(nn.Module):\n    \"\"\"\n    A PyTorch module for a multi-layer perceptron (MLP) model for MNIST classification.\n\n    Args:\n        n_hidden (int): The number of hidden units in each hidden layer.\n        n_classes (int): The number of output classes.\n        n_layers (int): The number of hidden layers in the model.\n\n    Attributes:\n        model (nn.Sequential): The sequential model that represents the MLP.\n\n    \"\"\"\n\n    def __init__(self, *, n_hidden, n_classes, n_layers):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(768, n_hidden),\n            *[\n                nn.Sequential(nn.Linear(n_hidden, n_hidden), nn.ReLU())\n                for _ in range(n_layers - 1)\n            ],\n            nn.Linear(n_hidden, n_classes)\n        )\n\n    def forward(self, images): ...\n\n\nmodel = MNIST(**config.ModelConfig)\nprint(model)\n\nMNIST(\n  (model): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (2): Sequential(\n      (0): Linear(in_features=256, out_features=256, bias=True)\n      (1): ReLU()\n    )\n    (3): Linear(in_features=256, out_features=10, bias=True)\n  )\n)\n\n\n\n\n\nGenericConfig\n\n GenericConfig (**kwargs)\n\n*A configuration class for deep learning models.\nThis class provides methods to access and manipulate configuration settings.\nAttributes: input_variables (list): List of input variables defined in the class constructor.\nMethods: keys(): Returns the list of input variables. getitem(key): Returns the value of the specified key. contains(key): Checks if the specified key is present in the input variables. from_ini_file(filepath, config_root=None): Creates an instance of the class from an INI file. repr(): Returns a string representation of the class.\nExample usage: config = DeepLearningConfig() config.from_ini_file(‘config.ini’) print(config.keys()) print(config[‘learning_rate’])*\nGenericConfig is a special class that can have attributes solely based on the config file, i.e., when we are unsure what are the arguments in the config going to be\n\nwritelines(config_str.split(\"\\n\"), \"/tmp/tmp.ini\", \"w\")\ntraining_config = GenericConfig.from_ini_file(\n    \"/tmp/tmp.ini\", config_root=\"TrainingConfig\"\n)\n\n\ndef train(**kwargs):\n    for k, v in kwargs.items():\n        print(k, v)\n\n\ntrain(**training_config)\n\nmax_steps 50000\nlearning_rate 0.00030000000000000003\noutput_dir ./results/mnist.v1\nper_device_train_batch_size 256\nper_device_eval_batch_size 256\nevaluation_strategy steps\neval_steps 500\nlogging_strategy steps\nlogging_steps 5\nsave_strategy steps\nsave_steps 500\nsave_total_limit 1\nseed 1234\nlabel_names ['targets']\nlr_scheduler_type cosine",
    "crumbs": [
      "config.html"
    ]
  },
  {
    "objectID": "paths.html",
    "href": "paths.html",
    "title": "Paths",
    "section": "",
    "text": "print(P().ls())\nprint(P().resolve())\n\n[» _quarto.yml, » decorators.ipynb, » markups.ipynb, » sidebar.yml, » AttrDict.ipynb, » interactive_show.ipynb, » load_defautls.ipynb, » sklegos.ipynb, » bounding_boxes.ipynb, » show.ipynb, » pdf.ipynb, » charts.ipynb, » paths.ipynb, » nbdev.yml, » tmp.csv, » jupyter_notebook.ipynb, » config.ipynb, » misc.ipynb, » registry.ipynb, » adapters.ipynb, » report.ipynb, » .ipynb_checkpoints, » capsule.ipynb, » logging.ipynb, » inspector.ipynb, » bokeh_plotting.ipynb, » index.ipynb, » imgaug_loader.ipynb]\n/Users/yeshwanth/Code/Personal/torch_snippets/nbs\n\n\n\n# !touch tmp.txt tmp.csv\n# # x = P()\n# x.tmp__csv, x.tmp__txt, x.misc\n\n\n!rm tmp.txt tmp.misc\n\nrm: tmp.txt: No such file or directory\nrm: tmp.misc: No such file or directory\n\n\n\n\n\n\n Path.rm (confirm_prompt='Are you sure you want to delete `{self}`?\n          [y/N]', silent=True, missing_ok=True, force=False,\n          dry_run=False)\n\n\n\n\n\n\n remove_file (dry_run)\n\n\n\n\n\n\n Path.cp (to)\n\n\n\n\n\n\n Path.mv (to)\n\n\n\n\n\n\n Path.sample (pattern='*')\n\n\n\n\n\n\n extn (fpath)\n\n\n\n\n\n\n Path.extn ()\n\n\n\n\n\n\n Path.sz ()\n\n\n\n\n\n\n Path.size ()\n\n\n\n\n\n\n Path.rmtree (prompt='Really remove `{self}` and its contents? [y/n] ',\n              force=False)\n\n\np = P(\"test.txt\")\np.touch()\nlogger.info(p.size())\n\n[08/24/24 11:12:12] INFO     0 KB                                                                                                                   1417366103.py:&lt;module&gt;:3\n\n\n\nPath objects can be moved and copied\n\np = p.mv(\"test1.txt\")\nq = p.cp(\"test2.txt\")\n\nPath objects have a size, extn (extension) and parent attributes\n\nassert isinstance(q, P)\nassert q.size() == \"0 KB\"\nassert str(p) == \"test1.txt\"\nassert p.extn == \"txt\"\nassert p.parent == P()\n\nThey can be deleted with/without a prompt\n\np.rm(force=True)\nq.rm(confirm_prompt=False)\n\nFolders can be globbed with a default of everything\n\np = P(\"../torch_snippets\")\nassert P().ls() == P().Glob()\np.Glob(\"*.py\")\n\n(#34) [» ../torch_snippets/misc.py,» ../torch_snippets/load_defaults.py,» ../torch_snippets/text_utils.py,» ../torch_snippets/_nbdev.py,» ../torch_snippets/paths.py,» ../torch_snippets/charts.py,» ../torch_snippets/pdf_loader.py,» ../torch_snippets/interactive_show.py,» ../torch_snippets/registry.py,» ../torch_snippets/markup2.py,» ../torch_snippets/_modidx.py,» ../torch_snippets/inspector.py,» ../torch_snippets/__init__.py,» ../torch_snippets/tmp.py,» ../torch_snippets/torch_loader.py,» ../torch_snippets/logger.py,» ../torch_snippets/markup.py,» ../torch_snippets/fastcores.py,» ../torch_snippets/sklegos.py,» ../torch_snippets/cli.py...]\n\n\nYou can sample a random file from the directory\n\nq = p.sample(\"*.py\")\nInfo(f\"Sample file: `{q}`\")\nInfo(f\"Sample file size: `{q.size()}`\")\n\n                    INFO     Sample file: `../torch_snippets/logger.py`                                                                             1725593160.py:&lt;module&gt;:2\n\n\n\n                    INFO     Sample file size: `9 KB`                                                                                               1725593160.py:&lt;module&gt;:3\n\n\n\n\ntry:\n    p.size()\nexcept Exception as e:\n    logger.warning(e)\n\n                    WARNING  `../torch_snippets` is a directory                                                                                     1980994904.py:&lt;module&gt;:4\n\n\n\n\np = P(\"test.txt\")\np.touch()\nassert isdir(p) == False\nassert fname(p) == \"test.txt\"\nassert parent(p) == P()\nassert stem(p) == \"test\"\nassert extn(p) == \"txt\"\n\nprint(find(\"capsule\", Glob(\"./\")))\n\np.rm(confirm_prompt=False)\n\ncapsule.ipynb\n\n\n\n\n\n\n\n list_zip (file)\n\n\n\n\n\n\n unzip_file (file, dest)\n\n\n\n\n\n\n zip_files (list_of_files, dest)\n\n\n!touch test1.txt test2.txt\nf = zip_files(P().Glob(\"*.txt\"), \"test.tar.gz\")\nunzip_file(f, \"./\")\n[f.rm(force=True) for f in P().Glob(\"*.txt\")]\nP(\"test.tar.gz\").rm(force=True)\n\n!touch test1.txt test2.txt\nf = zip_files(P().Glob(\"*.txt\"), \"test.zip\")\nunzip_file(f, \"./\")\n[f.rm(force=True) for f in P().Glob(\"*.txt\")]\nP(\"test.zip\").rm(force=True)\n\n                    INFO     Zipping 2 files to test.tar.gz...                                                                                     3826617683.py:zip_files:8\n\n\n\n100%|██████████| 2/2 [00:00&lt;00:00, 649.78it/s]\n/var/folders/1_/71dqv9vx2750gmyz77q_f45w0000gn/T/ipykernel_40147/3826617683.py:27: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  f.extractall(dest)\n\n\n                    INFO     Zipping 2 files to test.zip...                                                                                        3826617683.py:zip_files:8\n\n\n\n100%|██████████| 2/2 [00:00&lt;00:00, 2958.94it/s]\n\n\n\n\n\n\n\n folder_summary (thing)\n\n\n\n\n\n\n common_items (*fldrs, verbose=True)\n\n\n\n\n\n\n remove_duplicates (files)\n\nCheck a list of files and remove duplicates based on their checksum\n\n\n\n\n\n md5 (fname)\n\n\nmd5(\"paths.ipynb\")\n\n'74eb392fa44e9293fb30ffed68c14112'\n\n\n\n\n\n\n\n Path.write_lines (lines, mode)\n\n\n\n\n\n\n writelines (lines, file, mode)\n\n\n\n\n\n\n Path.print_file (**kwargs)\n\n\n\n\n\n\n printfile (*args, **kwargs)\n\n\n\n\n\n\n Path.read_file (**kwargs)\n\n\n\n\n\n\n readfile (*args, **kwargs)\n\n\n\n\n\n\n Path.read_lines (silent=False, encoding=None)\n\n\n\n\n\n\n readlines (fpath, silent=False, encoding=None, _strip=True)\n\n\nP(\"paths.ipynb\").read_lines()[:10]\n\n                    INFO     loaded 1075 lines                                                                                                   2901855681.py:read_lines:13\n\n\n\n['{',\n '\"cells\": [',\n '{',\n '\"cell_type\": \"raw\",',\n '\"metadata\": {},',\n '\"source\": [',\n '\"# Paths\\\\n\",',\n '\"Utilities to manipulate Paths\\\\n\",',\n '\"---\\\\n\",',\n '\"{}\\\\n\",']\n\n\n\n\n\n\n\n tree (directory='./', filelimit=50, to=None)\n\n\nP(\"../\").tree\n\n/Users/yeshwanth/Code/Personal/torch_snippets\n ── LICENSE\n ── LICENSE.txt\n ── MANIFEST\n ── MANIFEST.in\n ── Makefile\n ── README.md\n ── Screenshot 2022-09-08 at 4.40.18 PM.png\n ── __module_timing__.py.lprof\n ── _proc\n     ── AttrDict.ipynb\n     ── _quarto.yml\n     ── adapters.ipynb\n     ── bokeh_plotting.ipynb\n     ── bounding_boxes.ipynb\n     ── capsule.ipynb\n     ── charts.ipynb\n     ── config.ipynb\n     ── decorators.ipynb\n     ── docs\n         ── AttrDict.html\n         ── adapters.html\n         ── bokeh_plotting.html\n         ── bounding_boxes.html\n         ── bounding_boxes_files\n             ── figure-html\n                 ── cell-6-output-1.png\n                 ── cell-7-output-1.png\n                 ── cell-8-output-1.png\n                 ── cell-9-output-1.png\n         ── capsule.html\n         ── capsule_files\n             ── figure-html\n                 ── cell-6-output-2.png\n         ── charts.html\n         ── charts_files\n             ── figure-html\n                 ── cell-7-output-1.png\n         ── config.html\n         ── decorators.html\n         ── imgaug_loader.html\n         ── imgaug_loader_files\n             ── figure-html\n                 ── cell-3-output-1.png\n                 ── cell-5-output-10.png\n                 ── cell-5-output-12.png\n                 ── cell-5-output-14.png\n                 ── cell-5-output-16.png\n                 ── cell-5-output-18.png\n                 ── cell-5-output-2.png\n                 ── cell-5-output-20.png\n                 ── cell-5-output-22.png\n                 ── cell-5-output-4.png\n                 ── cell-5-output-6.png\n                 ── cell-5-output-8.png\n                 ── cell-6-output-1.png\n                 ── cell-7-output-1.png\n                 ── cell-8-output-2.png\n         ── index.html\n         ── inspector.html\n         ── interactive_show.html\n         ── jupyter_notebook.html\n         ── load_defautls.html\n         ── logging.html\n         ── markups.html\n         ── misc.html\n         ── paths.html\n         ── pdf.html\n         ── registry.html\n         ── report.html\n         ── report_files\n             ── figure-html\n                 ── cell-3-output-2.png\n                 ── cell-5-output-1.png\n         ── robots.txt\n         ── search.json\n         ── show.html\n         ── show_files\n             ── figure-html\n                 ── cell-2-output-1.png\n                 ── cell-3-output-1.png\n                 ── cell-4-output-2.png\n                 ── cell-4-output-4.png\n                 ── cell-4-output-6.png\n                 ── cell-5-output-1.png\n                 ── cell-8-output-1.png\n                 ── cell-9-output-1.png\n         ── site_libs\n             ── bootstrap\n                 ── bootstrap-icons.css\n                 ── bootstrap-icons.woff\n                 ── bootstrap.min.css\n                 ── bootstrap.min.js\n             ── clipboard\n                 ── clipboard.min.js\n             ── quarto-html\n                 ── anchor.min.js\n                 ── popper.min.js\n                 ── quarto-syntax-highlighting.css\n                 ── quarto.js\n                 ── tippy.css\n                 ── tippy.umd.min.js\n             ── quarto-nav\n                 ── headroom.min.js\n                 ── quarto-nav.js\n             ── quarto-search\n                 ── autocomplete.umd.js\n                 ── fuse.min.js\n                 ── quarto-search.js\n         ── sitemap.xml\n         ── sklegos.html\n     ── imgaug_loader.ipynb\n     ── index.ipynb\n     ── inspector.ipynb\n     ── interactive_show.ipynb\n     ── jupyter_notebook.ipynb\n     ── load_defautls.ipynb\n     ── logging.ipynb\n     ── markups.ipynb\n     ── misc.ipynb\n     ── nbdev.yml\n     ── paths.ipynb\n     ── pdf.ipynb\n     ── registry.ipynb\n     ── report.ipynb\n     ── show.ipynb\n     ── sidebar.yml\n     ── sklegos.ipynb\n     ── test.txt\n     ── test1.txt\n     ── test2.txt\n     ── tmp.csv\n     ── tmp.txt\n ── assets\n     ── Preamble.csv\n     ── Preamble.png\n     ── avgs0.png\n     ── avgs1.png\n     ── demo.gif\n ── backups\n     ── testing\n         ── 0000.html\n ── build\n     ── bdist.macosx-11.1-arm64\n     ── lib\n         ── torch_snippets\n             ── __init__.py\n             ── __module_timing__.py\n             ── _modidx.py\n             ── _nbdev.py\n             ── adapters.py\n             ── bb_utils.py\n             ── bokeh_loader.py\n             ── charts.py\n             ── cli.py\n             ── dates.py\n             ── decorators.py\n             ── fastcores.py\n             ── icecream.py\n             ── imgaug_loader.py\n             ── inspector.py\n             ── interactive_show.py\n             ── ipython.py\n             ── load_defaults.py\n             ── loader.py\n             ── logger.py\n             ── markup.py\n             ── markup2.py\n             ── misc.py\n             ── paths.py\n             ── pdf_loader.py\n             ── registry.py\n             ── s3_loader.py\n             ── scp.py\n             ── sklegos.py\n             ── text_utils.py\n             ── thinc_parser\n                 ── __init__.py\n                 ── parser.py\n             ── tmp.py\n             ── torch_loader.py\n             ── trainer\n                 ── __init__.py\n                 ── capsule.py\n                 ── config.py\n                 ── hooks.py\n                 ── neural_graph.py\n             ── video.py\n             ── zen.py\n ── changelog.md\n ── conda\n     ── torch_snippets\n         ── meta.yaml\n ── debug\n     ── profile_time.txt\n     ── profile_time_202408241027.txt\n ── dist\n     ── torch_snippets-0.6.0-py3-none-any.whl\n     ── torch_snippets-0.6.0.tar.gz\n ── docker-compose.yml\n ── docs\n     ── AttrDict.html\n     ── adapters.html\n     ── bokeh_plotting.html\n     ── bounding_boxes.html\n     ── bounding_boxes_files\n         ── figure-html\n             ── cell-6-output-1.png\n             ── cell-7-output-1.png\n             ── cell-8-output-1.png\n             ── cell-9-output-1.png\n     ── capsule.html\n     ── capsule_files\n         ── figure-html\n             ── cell-5-output-2.png\n     ── charts.html\n     ── charts_files\n         ── figure-html\n             ── cell-7-output-1.png\n     ── config.html\n     ── decorators.html\n     ── imgaug_loader.html\n     ── imgaug_loader_files\n         ── figure-html\n             ── cell-3-output-1.png\n             ── cell-5-output-10.png\n             ── cell-5-output-12.png\n             ── cell-5-output-14.png\n             ── cell-5-output-16.png\n             ── cell-5-output-18.png\n             ── cell-5-output-2.png\n             ── cell-5-output-20.png\n             ── cell-5-output-22.png\n             ── cell-5-output-4.png\n             ── cell-5-output-6.png\n             ── cell-5-output-8.png\n             ── cell-6-output-1.png\n             ── cell-7-output-1.png\n             ── cell-8-output-2.png\n     ── index.html\n     ── inspector.html\n     ── interactive_show.html\n     ── jupyter_notebook.html\n     ── load_defautls.html\n     ── logging.html\n     ── markups.html\n     ── misc.html\n     ── paths.html\n     ── pdf.html\n     ── registry.html\n     ── report.html\n     ── report_files\n         ── figure-html\n             ── cell-3-output-2.png\n             ── cell-5-output-1.png\n     ── robots.txt\n     ── search.json\n     ── show.html\n     ── show_files\n         ── figure-html\n             ── cell-2-output-1.png\n             ── cell-3-output-1.png\n             ── cell-4-output-2.png\n             ── cell-4-output-4.png\n             ── cell-4-output-6.png\n             ── cell-5-output-1.png\n             ── cell-8-output-1.png\n             ── cell-9-output-1.png\n     ── site_libs\n         ── bootstrap\n             ── bootstrap-icons.css\n             ── bootstrap-icons.woff\n             ── bootstrap.min.css\n             ── bootstrap.min.js\n         ── clipboard\n             ── clipboard.min.js\n         ── quarto-html\n             ── anchor.min.js\n             ── popper.min.js\n             ── quarto-syntax-highlighting.css\n             ── quarto.js\n             ── tippy.css\n             ── tippy.umd.min.js\n         ── quarto-nav\n             ── headroom.min.js\n             ── quarto-nav.js\n         ── quarto-search\n             ── autocomplete.umd.js\n             ── fuse.min.js\n             ── quarto-search.js\n     ── sitemap.xml\n     ── sklegos.html\n ── nbs\n     ── AttrDict.ipynb\n     ── _quarto.yml\n     ── adapters.ipynb\n     ── bokeh_plotting.ipynb\n     ── bounding_boxes.ipynb\n     ── capsule.ipynb\n     ── charts.ipynb\n     ── config.ipynb\n     ── decorators.ipynb\n     ── imgaug_loader.ipynb\n     ── index.ipynb\n     ── inspector.ipynb\n     ── interactive_show.ipynb\n     ── jupyter_notebook.ipynb\n     ── load_defautls.ipynb\n     ── logging.ipynb\n     ── markups.ipynb\n     ── misc.ipynb\n     ── nbdev.yml\n     ── paths.ipynb\n     ── pdf.ipynb\n     ── registry.ipynb\n     ── report.ipynb\n     ── show.ipynb\n     ── sidebar.yml\n     ── sklegos.ipynb\n     ── tmp.csv\n ── requirements.txt\n ── scripts.ipynb\n ── settings.ini\n ── setup.cfg\n ── setup.py\n ── testing.ipynb\n ── tmp.ini\n ── torch_snippets\n     ── __init__.py\n     ── __module_timing__.py\n     ── __pycache__\n         ── __init__.cpython-312.pyc\n         ── __module_timing__.cpython-312.pyc\n         ── bb_utils.cpython-312.pyc\n         ── bokeh_loader.cpython-312.pyc\n         ── charts.cpython-312.pyc\n         ── cli.cpython-312.pyc\n         ── dates.cpython-312.pyc\n         ── decorators.cpython-312.pyc\n         ── icecream.cpython-312.pyc\n         ── inspector.cpython-312.pyc\n         ── ipython.cpython-312.pyc\n         ── load_defaults.cpython-312.pyc\n         ── loader.cpython-312.pyc\n         ── logger.cpython-312.pyc\n         ── markup.cpython-312.pyc\n         ── markup2.cpython-312.pyc\n         ── misc.cpython-312.pyc\n         ── paths.cpython-312.pyc\n         ── pdf_loader.cpython-312.pyc\n         ── registry.cpython-312.pyc\n         ── s3_loader.cpython-312.pyc\n         ── torch_loader.cpython-312.pyc\n         ── zen.cpython-312.pyc\n     ── _modidx.py\n     ── _nbdev.py\n     ── adapters.py\n     ── bb_utils.py\n     ── bokeh_loader.py\n     ── charts.py\n     ── cli.py\n     ── dates.py\n     ── decorators.py\n     ── fastcores.py\n     ── icecream.py\n     ── imgaug_loader.py\n     ── inspector.py\n     ── interactive_show.py\n     ── ipython.py\n     ── load_defaults.py\n     ── loader.py\n     ── logger.py\n     ── markup.py\n     ── markup2.py\n     ── misc.py\n     ── paths.py\n     ── pdf_loader.py\n     ── registry.py\n     ── s3_loader.py\n     ── scp.py\n     ── sklegos.py\n     ── text_utils.py\n     ── thinc_parser\n         ── __init__.py\n         ── __pycache__\n             ── __init__.cpython-312.pyc\n             ── parser.cpython-312.pyc\n         ── parser.py\n     ── tmp.py\n     ── torch_loader.py\n     ── trainer\n         ── __init__.py\n         ── __pycache__\n             ── __init__.cpython-312.pyc\n             ── capsule.cpython-312.pyc\n         ── capsule.py\n         ── config.py\n         ── hooks.py\n         ── neural_graph.py\n     ── video.py\n     ── zen.py\n ── torch_snippets.egg-info\n     ── PKG-INFO\n     ── SOURCES.txt\n     ── dependency_links.txt\n     ── entry_points.txt\n     ── not-zip-safe\n     ── requires.txt\n     ── top_level.txt\n\n61 directories, 348 files\n\n\n\n\n\n\n\n\n folder_structure_to_json (path, output_file=None)\n\nCreates a JSON file representing the folder structure of the given directory.\n\n\n\n\n\n folder_structure_to_dict (path)\n\nRecursively constructs a nested dictionary that represents the folder structure.\n\nx = P(\"tmp.txt\")\nx.touch()\nx.write_lines([i for i in range(1000)], mode=\"w\")\nlines = x.read_lines()\nassert lines == [f\"{i}\" for i in range(1000)]\nlogger.info(x.size())\n\nx.rm(confirm_prompt=False)\n\n[08/24/24 11:12:13] INFO     loaded 1000 lines                                                                                                   2901855681.py:read_lines:13\n\n\n\n                    INFO     3 KB                                                                                                                   1033976698.py:&lt;module&gt;:6\n\n\n\n\n\n\n\n\n loaddill (fpath)\n\nLoad a python object from a dill file\n\n\n\n\n\n dumpdill (obj, fpath, silent=False, message='Dumped object of size\n           ≈{fsize} @ \"{fpath}\" in {dumptime:.2e} seconds')\n\nDump a python object as a dill file (better replacement to pickle)\n\np = P(\"test.tmp\")\ndumpdill([1, 2, 3], p)\ny = loaddill(p)\np.rm(confirm_prompt=False)\nassert y == [1, 2, 3]\n\n                    INFO     Dumped object of size ≈0 KB @ \"test.tmp\" in 4.11e-04 seconds                                                            554288780.py:&lt;module&gt;:2",
    "crumbs": [
      "Paths"
    ]
  },
  {
    "objectID": "paths.html#section",
    "href": "paths.html#section",
    "title": "Paths",
    "section": "",
    "text": "print(P().ls())\nprint(P().resolve())\n\n[» _quarto.yml, » decorators.ipynb, » markups.ipynb, » sidebar.yml, » AttrDict.ipynb, » interactive_show.ipynb, » load_defautls.ipynb, » sklegos.ipynb, » bounding_boxes.ipynb, » show.ipynb, » pdf.ipynb, » charts.ipynb, » paths.ipynb, » nbdev.yml, » tmp.csv, » jupyter_notebook.ipynb, » config.ipynb, » misc.ipynb, » registry.ipynb, » adapters.ipynb, » report.ipynb, » .ipynb_checkpoints, » capsule.ipynb, » logging.ipynb, » inspector.ipynb, » bokeh_plotting.ipynb, » index.ipynb, » imgaug_loader.ipynb]\n/Users/yeshwanth/Code/Personal/torch_snippets/nbs\n\n\n\n# !touch tmp.txt tmp.csv\n# # x = P()\n# x.tmp__csv, x.tmp__txt, x.misc\n\n\n!rm tmp.txt tmp.misc\n\nrm: tmp.txt: No such file or directory\nrm: tmp.misc: No such file or directory\n\n\n\n\n\n\n Path.rm (confirm_prompt='Are you sure you want to delete `{self}`?\n          [y/N]', silent=True, missing_ok=True, force=False,\n          dry_run=False)\n\n\n\n\n\n\n remove_file (dry_run)\n\n\n\n\n\n\n Path.cp (to)\n\n\n\n\n\n\n Path.mv (to)\n\n\n\n\n\n\n Path.sample (pattern='*')\n\n\n\n\n\n\n extn (fpath)\n\n\n\n\n\n\n Path.extn ()\n\n\n\n\n\n\n Path.sz ()\n\n\n\n\n\n\n Path.size ()\n\n\n\n\n\n\n Path.rmtree (prompt='Really remove `{self}` and its contents? [y/n] ',\n              force=False)\n\n\np = P(\"test.txt\")\np.touch()\nlogger.info(p.size())\n\n[08/24/24 11:12:12] INFO     0 KB                                                                                                                   1417366103.py:&lt;module&gt;:3\n\n\n\nPath objects can be moved and copied\n\np = p.mv(\"test1.txt\")\nq = p.cp(\"test2.txt\")\n\nPath objects have a size, extn (extension) and parent attributes\n\nassert isinstance(q, P)\nassert q.size() == \"0 KB\"\nassert str(p) == \"test1.txt\"\nassert p.extn == \"txt\"\nassert p.parent == P()\n\nThey can be deleted with/without a prompt\n\np.rm(force=True)\nq.rm(confirm_prompt=False)\n\nFolders can be globbed with a default of everything\n\np = P(\"../torch_snippets\")\nassert P().ls() == P().Glob()\np.Glob(\"*.py\")\n\n(#34) [» ../torch_snippets/misc.py,» ../torch_snippets/load_defaults.py,» ../torch_snippets/text_utils.py,» ../torch_snippets/_nbdev.py,» ../torch_snippets/paths.py,» ../torch_snippets/charts.py,» ../torch_snippets/pdf_loader.py,» ../torch_snippets/interactive_show.py,» ../torch_snippets/registry.py,» ../torch_snippets/markup2.py,» ../torch_snippets/_modidx.py,» ../torch_snippets/inspector.py,» ../torch_snippets/__init__.py,» ../torch_snippets/tmp.py,» ../torch_snippets/torch_loader.py,» ../torch_snippets/logger.py,» ../torch_snippets/markup.py,» ../torch_snippets/fastcores.py,» ../torch_snippets/sklegos.py,» ../torch_snippets/cli.py...]\n\n\nYou can sample a random file from the directory\n\nq = p.sample(\"*.py\")\nInfo(f\"Sample file: `{q}`\")\nInfo(f\"Sample file size: `{q.size()}`\")\n\n                    INFO     Sample file: `../torch_snippets/logger.py`                                                                             1725593160.py:&lt;module&gt;:2\n\n\n\n                    INFO     Sample file size: `9 KB`                                                                                               1725593160.py:&lt;module&gt;:3\n\n\n\n\ntry:\n    p.size()\nexcept Exception as e:\n    logger.warning(e)\n\n                    WARNING  `../torch_snippets` is a directory                                                                                     1980994904.py:&lt;module&gt;:4\n\n\n\n\np = P(\"test.txt\")\np.touch()\nassert isdir(p) == False\nassert fname(p) == \"test.txt\"\nassert parent(p) == P()\nassert stem(p) == \"test\"\nassert extn(p) == \"txt\"\n\nprint(find(\"capsule\", Glob(\"./\")))\n\np.rm(confirm_prompt=False)\n\ncapsule.ipynb\n\n\n\n\n\n\n\n list_zip (file)\n\n\n\n\n\n\n unzip_file (file, dest)\n\n\n\n\n\n\n zip_files (list_of_files, dest)\n\n\n!touch test1.txt test2.txt\nf = zip_files(P().Glob(\"*.txt\"), \"test.tar.gz\")\nunzip_file(f, \"./\")\n[f.rm(force=True) for f in P().Glob(\"*.txt\")]\nP(\"test.tar.gz\").rm(force=True)\n\n!touch test1.txt test2.txt\nf = zip_files(P().Glob(\"*.txt\"), \"test.zip\")\nunzip_file(f, \"./\")\n[f.rm(force=True) for f in P().Glob(\"*.txt\")]\nP(\"test.zip\").rm(force=True)\n\n                    INFO     Zipping 2 files to test.tar.gz...                                                                                     3826617683.py:zip_files:8\n\n\n\n100%|██████████| 2/2 [00:00&lt;00:00, 649.78it/s]\n/var/folders/1_/71dqv9vx2750gmyz77q_f45w0000gn/T/ipykernel_40147/3826617683.py:27: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  f.extractall(dest)\n\n\n                    INFO     Zipping 2 files to test.zip...                                                                                        3826617683.py:zip_files:8\n\n\n\n100%|██████████| 2/2 [00:00&lt;00:00, 2958.94it/s]\n\n\n\n\n\n\n\n folder_summary (thing)\n\n\n\n\n\n\n common_items (*fldrs, verbose=True)\n\n\n\n\n\n\n remove_duplicates (files)\n\nCheck a list of files and remove duplicates based on their checksum\n\n\n\n\n\n md5 (fname)\n\n\nmd5(\"paths.ipynb\")\n\n'74eb392fa44e9293fb30ffed68c14112'\n\n\n\n\n\n\n\n Path.write_lines (lines, mode)\n\n\n\n\n\n\n writelines (lines, file, mode)\n\n\n\n\n\n\n Path.print_file (**kwargs)\n\n\n\n\n\n\n printfile (*args, **kwargs)\n\n\n\n\n\n\n Path.read_file (**kwargs)\n\n\n\n\n\n\n readfile (*args, **kwargs)\n\n\n\n\n\n\n Path.read_lines (silent=False, encoding=None)\n\n\n\n\n\n\n readlines (fpath, silent=False, encoding=None, _strip=True)\n\n\nP(\"paths.ipynb\").read_lines()[:10]\n\n                    INFO     loaded 1075 lines                                                                                                   2901855681.py:read_lines:13\n\n\n\n['{',\n '\"cells\": [',\n '{',\n '\"cell_type\": \"raw\",',\n '\"metadata\": {},',\n '\"source\": [',\n '\"# Paths\\\\n\",',\n '\"Utilities to manipulate Paths\\\\n\",',\n '\"---\\\\n\",',\n '\"{}\\\\n\",']\n\n\n\n\n\n\n\n tree (directory='./', filelimit=50, to=None)\n\n\nP(\"../\").tree\n\n/Users/yeshwanth/Code/Personal/torch_snippets\n ── LICENSE\n ── LICENSE.txt\n ── MANIFEST\n ── MANIFEST.in\n ── Makefile\n ── README.md\n ── Screenshot 2022-09-08 at 4.40.18 PM.png\n ── __module_timing__.py.lprof\n ── _proc\n     ── AttrDict.ipynb\n     ── _quarto.yml\n     ── adapters.ipynb\n     ── bokeh_plotting.ipynb\n     ── bounding_boxes.ipynb\n     ── capsule.ipynb\n     ── charts.ipynb\n     ── config.ipynb\n     ── decorators.ipynb\n     ── docs\n         ── AttrDict.html\n         ── adapters.html\n         ── bokeh_plotting.html\n         ── bounding_boxes.html\n         ── bounding_boxes_files\n             ── figure-html\n                 ── cell-6-output-1.png\n                 ── cell-7-output-1.png\n                 ── cell-8-output-1.png\n                 ── cell-9-output-1.png\n         ── capsule.html\n         ── capsule_files\n             ── figure-html\n                 ── cell-6-output-2.png\n         ── charts.html\n         ── charts_files\n             ── figure-html\n                 ── cell-7-output-1.png\n         ── config.html\n         ── decorators.html\n         ── imgaug_loader.html\n         ── imgaug_loader_files\n             ── figure-html\n                 ── cell-3-output-1.png\n                 ── cell-5-output-10.png\n                 ── cell-5-output-12.png\n                 ── cell-5-output-14.png\n                 ── cell-5-output-16.png\n                 ── cell-5-output-18.png\n                 ── cell-5-output-2.png\n                 ── cell-5-output-20.png\n                 ── cell-5-output-22.png\n                 ── cell-5-output-4.png\n                 ── cell-5-output-6.png\n                 ── cell-5-output-8.png\n                 ── cell-6-output-1.png\n                 ── cell-7-output-1.png\n                 ── cell-8-output-2.png\n         ── index.html\n         ── inspector.html\n         ── interactive_show.html\n         ── jupyter_notebook.html\n         ── load_defautls.html\n         ── logging.html\n         ── markups.html\n         ── misc.html\n         ── paths.html\n         ── pdf.html\n         ── registry.html\n         ── report.html\n         ── report_files\n             ── figure-html\n                 ── cell-3-output-2.png\n                 ── cell-5-output-1.png\n         ── robots.txt\n         ── search.json\n         ── show.html\n         ── show_files\n             ── figure-html\n                 ── cell-2-output-1.png\n                 ── cell-3-output-1.png\n                 ── cell-4-output-2.png\n                 ── cell-4-output-4.png\n                 ── cell-4-output-6.png\n                 ── cell-5-output-1.png\n                 ── cell-8-output-1.png\n                 ── cell-9-output-1.png\n         ── site_libs\n             ── bootstrap\n                 ── bootstrap-icons.css\n                 ── bootstrap-icons.woff\n                 ── bootstrap.min.css\n                 ── bootstrap.min.js\n             ── clipboard\n                 ── clipboard.min.js\n             ── quarto-html\n                 ── anchor.min.js\n                 ── popper.min.js\n                 ── quarto-syntax-highlighting.css\n                 ── quarto.js\n                 ── tippy.css\n                 ── tippy.umd.min.js\n             ── quarto-nav\n                 ── headroom.min.js\n                 ── quarto-nav.js\n             ── quarto-search\n                 ── autocomplete.umd.js\n                 ── fuse.min.js\n                 ── quarto-search.js\n         ── sitemap.xml\n         ── sklegos.html\n     ── imgaug_loader.ipynb\n     ── index.ipynb\n     ── inspector.ipynb\n     ── interactive_show.ipynb\n     ── jupyter_notebook.ipynb\n     ── load_defautls.ipynb\n     ── logging.ipynb\n     ── markups.ipynb\n     ── misc.ipynb\n     ── nbdev.yml\n     ── paths.ipynb\n     ── pdf.ipynb\n     ── registry.ipynb\n     ── report.ipynb\n     ── show.ipynb\n     ── sidebar.yml\n     ── sklegos.ipynb\n     ── test.txt\n     ── test1.txt\n     ── test2.txt\n     ── tmp.csv\n     ── tmp.txt\n ── assets\n     ── Preamble.csv\n     ── Preamble.png\n     ── avgs0.png\n     ── avgs1.png\n     ── demo.gif\n ── backups\n     ── testing\n         ── 0000.html\n ── build\n     ── bdist.macosx-11.1-arm64\n     ── lib\n         ── torch_snippets\n             ── __init__.py\n             ── __module_timing__.py\n             ── _modidx.py\n             ── _nbdev.py\n             ── adapters.py\n             ── bb_utils.py\n             ── bokeh_loader.py\n             ── charts.py\n             ── cli.py\n             ── dates.py\n             ── decorators.py\n             ── fastcores.py\n             ── icecream.py\n             ── imgaug_loader.py\n             ── inspector.py\n             ── interactive_show.py\n             ── ipython.py\n             ── load_defaults.py\n             ── loader.py\n             ── logger.py\n             ── markup.py\n             ── markup2.py\n             ── misc.py\n             ── paths.py\n             ── pdf_loader.py\n             ── registry.py\n             ── s3_loader.py\n             ── scp.py\n             ── sklegos.py\n             ── text_utils.py\n             ── thinc_parser\n                 ── __init__.py\n                 ── parser.py\n             ── tmp.py\n             ── torch_loader.py\n             ── trainer\n                 ── __init__.py\n                 ── capsule.py\n                 ── config.py\n                 ── hooks.py\n                 ── neural_graph.py\n             ── video.py\n             ── zen.py\n ── changelog.md\n ── conda\n     ── torch_snippets\n         ── meta.yaml\n ── debug\n     ── profile_time.txt\n     ── profile_time_202408241027.txt\n ── dist\n     ── torch_snippets-0.6.0-py3-none-any.whl\n     ── torch_snippets-0.6.0.tar.gz\n ── docker-compose.yml\n ── docs\n     ── AttrDict.html\n     ── adapters.html\n     ── bokeh_plotting.html\n     ── bounding_boxes.html\n     ── bounding_boxes_files\n         ── figure-html\n             ── cell-6-output-1.png\n             ── cell-7-output-1.png\n             ── cell-8-output-1.png\n             ── cell-9-output-1.png\n     ── capsule.html\n     ── capsule_files\n         ── figure-html\n             ── cell-5-output-2.png\n     ── charts.html\n     ── charts_files\n         ── figure-html\n             ── cell-7-output-1.png\n     ── config.html\n     ── decorators.html\n     ── imgaug_loader.html\n     ── imgaug_loader_files\n         ── figure-html\n             ── cell-3-output-1.png\n             ── cell-5-output-10.png\n             ── cell-5-output-12.png\n             ── cell-5-output-14.png\n             ── cell-5-output-16.png\n             ── cell-5-output-18.png\n             ── cell-5-output-2.png\n             ── cell-5-output-20.png\n             ── cell-5-output-22.png\n             ── cell-5-output-4.png\n             ── cell-5-output-6.png\n             ── cell-5-output-8.png\n             ── cell-6-output-1.png\n             ── cell-7-output-1.png\n             ── cell-8-output-2.png\n     ── index.html\n     ── inspector.html\n     ── interactive_show.html\n     ── jupyter_notebook.html\n     ── load_defautls.html\n     ── logging.html\n     ── markups.html\n     ── misc.html\n     ── paths.html\n     ── pdf.html\n     ── registry.html\n     ── report.html\n     ── report_files\n         ── figure-html\n             ── cell-3-output-2.png\n             ── cell-5-output-1.png\n     ── robots.txt\n     ── search.json\n     ── show.html\n     ── show_files\n         ── figure-html\n             ── cell-2-output-1.png\n             ── cell-3-output-1.png\n             ── cell-4-output-2.png\n             ── cell-4-output-4.png\n             ── cell-4-output-6.png\n             ── cell-5-output-1.png\n             ── cell-8-output-1.png\n             ── cell-9-output-1.png\n     ── site_libs\n         ── bootstrap\n             ── bootstrap-icons.css\n             ── bootstrap-icons.woff\n             ── bootstrap.min.css\n             ── bootstrap.min.js\n         ── clipboard\n             ── clipboard.min.js\n         ── quarto-html\n             ── anchor.min.js\n             ── popper.min.js\n             ── quarto-syntax-highlighting.css\n             ── quarto.js\n             ── tippy.css\n             ── tippy.umd.min.js\n         ── quarto-nav\n             ── headroom.min.js\n             ── quarto-nav.js\n         ── quarto-search\n             ── autocomplete.umd.js\n             ── fuse.min.js\n             ── quarto-search.js\n     ── sitemap.xml\n     ── sklegos.html\n ── nbs\n     ── AttrDict.ipynb\n     ── _quarto.yml\n     ── adapters.ipynb\n     ── bokeh_plotting.ipynb\n     ── bounding_boxes.ipynb\n     ── capsule.ipynb\n     ── charts.ipynb\n     ── config.ipynb\n     ── decorators.ipynb\n     ── imgaug_loader.ipynb\n     ── index.ipynb\n     ── inspector.ipynb\n     ── interactive_show.ipynb\n     ── jupyter_notebook.ipynb\n     ── load_defautls.ipynb\n     ── logging.ipynb\n     ── markups.ipynb\n     ── misc.ipynb\n     ── nbdev.yml\n     ── paths.ipynb\n     ── pdf.ipynb\n     ── registry.ipynb\n     ── report.ipynb\n     ── show.ipynb\n     ── sidebar.yml\n     ── sklegos.ipynb\n     ── tmp.csv\n ── requirements.txt\n ── scripts.ipynb\n ── settings.ini\n ── setup.cfg\n ── setup.py\n ── testing.ipynb\n ── tmp.ini\n ── torch_snippets\n     ── __init__.py\n     ── __module_timing__.py\n     ── __pycache__\n         ── __init__.cpython-312.pyc\n         ── __module_timing__.cpython-312.pyc\n         ── bb_utils.cpython-312.pyc\n         ── bokeh_loader.cpython-312.pyc\n         ── charts.cpython-312.pyc\n         ── cli.cpython-312.pyc\n         ── dates.cpython-312.pyc\n         ── decorators.cpython-312.pyc\n         ── icecream.cpython-312.pyc\n         ── inspector.cpython-312.pyc\n         ── ipython.cpython-312.pyc\n         ── load_defaults.cpython-312.pyc\n         ── loader.cpython-312.pyc\n         ── logger.cpython-312.pyc\n         ── markup.cpython-312.pyc\n         ── markup2.cpython-312.pyc\n         ── misc.cpython-312.pyc\n         ── paths.cpython-312.pyc\n         ── pdf_loader.cpython-312.pyc\n         ── registry.cpython-312.pyc\n         ── s3_loader.cpython-312.pyc\n         ── torch_loader.cpython-312.pyc\n         ── zen.cpython-312.pyc\n     ── _modidx.py\n     ── _nbdev.py\n     ── adapters.py\n     ── bb_utils.py\n     ── bokeh_loader.py\n     ── charts.py\n     ── cli.py\n     ── dates.py\n     ── decorators.py\n     ── fastcores.py\n     ── icecream.py\n     ── imgaug_loader.py\n     ── inspector.py\n     ── interactive_show.py\n     ── ipython.py\n     ── load_defaults.py\n     ── loader.py\n     ── logger.py\n     ── markup.py\n     ── markup2.py\n     ── misc.py\n     ── paths.py\n     ── pdf_loader.py\n     ── registry.py\n     ── s3_loader.py\n     ── scp.py\n     ── sklegos.py\n     ── text_utils.py\n     ── thinc_parser\n         ── __init__.py\n         ── __pycache__\n             ── __init__.cpython-312.pyc\n             ── parser.cpython-312.pyc\n         ── parser.py\n     ── tmp.py\n     ── torch_loader.py\n     ── trainer\n         ── __init__.py\n         ── __pycache__\n             ── __init__.cpython-312.pyc\n             ── capsule.cpython-312.pyc\n         ── capsule.py\n         ── config.py\n         ── hooks.py\n         ── neural_graph.py\n     ── video.py\n     ── zen.py\n ── torch_snippets.egg-info\n     ── PKG-INFO\n     ── SOURCES.txt\n     ── dependency_links.txt\n     ── entry_points.txt\n     ── not-zip-safe\n     ── requires.txt\n     ── top_level.txt\n\n61 directories, 348 files\n\n\n\n\n\n\n\n\n folder_structure_to_json (path, output_file=None)\n\nCreates a JSON file representing the folder structure of the given directory.\n\n\n\n\n\n folder_structure_to_dict (path)\n\nRecursively constructs a nested dictionary that represents the folder structure.\n\nx = P(\"tmp.txt\")\nx.touch()\nx.write_lines([i for i in range(1000)], mode=\"w\")\nlines = x.read_lines()\nassert lines == [f\"{i}\" for i in range(1000)]\nlogger.info(x.size())\n\nx.rm(confirm_prompt=False)\n\n[08/24/24 11:12:13] INFO     loaded 1000 lines                                                                                                   2901855681.py:read_lines:13\n\n\n\n                    INFO     3 KB                                                                                                                   1033976698.py:&lt;module&gt;:6\n\n\n\n\n\n\n\n\n loaddill (fpath)\n\nLoad a python object from a dill file\n\n\n\n\n\n dumpdill (obj, fpath, silent=False, message='Dumped object of size\n           ≈{fsize} @ \"{fpath}\" in {dumptime:.2e} seconds')\n\nDump a python object as a dill file (better replacement to pickle)\n\np = P(\"test.tmp\")\ndumpdill([1, 2, 3], p)\ny = loaddill(p)\np.rm(confirm_prompt=False)\nassert y == [1, 2, 3]\n\n                    INFO     Dumped object of size ≈0 KB @ \"test.tmp\" in 4.11e-04 seconds                                                            554288780.py:&lt;module&gt;:2",
    "crumbs": [
      "Paths"
    ]
  },
  {
    "objectID": "pdf.html",
    "href": "pdf.html",
    "title": "PDF",
    "section": "",
    "text": "preview_pdf\n\n preview_pdf (path)\n\nPreview a PDF file\n\n\n\ndump_pdf_images\n\n dump_pdf_images (path, folder,\n                  create_new_folder_with_same_name:bool=True,\n                  show_after_dump:bool=False)\n\nDump all images from a PDF file to a folder\n\n\n\nPDF\n\n PDF (path, dfs=None, dpi=150)\n\nLoad a PDF file from path as a list of images Use show function to see the images WIP",
    "crumbs": [
      "PDF"
    ]
  },
  {
    "objectID": "bounding_boxes.html",
    "href": "bounding_boxes.html",
    "title": "Bounding Box",
    "section": "",
    "text": "Bounding Box\n\nCreate a box by mentioning the top-left (x, y) and bottom-right (X, Y) coordinates\nSay x, y, X, Y are 10, 20, 40, 50 respectively\n\nbb = BB([10, 20, 40, 50])\n\nYou get the following attributes for free\n\n\n\nbb.x=10              (top left - x)\nbb.y=20              (top left - y)\nbb.X=40              (bottom right - x)\nbb.Y=50              (bottom right - y)\nbb.w=30              (width)\nbb.h=30              (height)\nbb.xc=25.0           (center x)\nbb.yc=35.0           (center y)\nbb.c=(25.0, 35.0)    (center)\nbb.area=900          (area)\nbb.shape=(30, 30)    (height, width)\n\n\n\n\nfrom torch_snippets import show, read, P, pd\n\n\nassets = P(\"/Users/yeshwanth.y/code/torch_snippets/assets/\")\nim = read(assets / \"Preamble.png\")\ndf = pd.read_csv(assets / \"Preamble.csv\")\nshow(df.head())\ndf = to_absolute(df, *im.shape[:2])\nshow(df.head())\ndf = to_relative(df, *im.shape[:2])\nshow(df.head())\n\n\n  \n    \n      \n      x\n      y\n      X\n      Y\n      text\n      block_id\n    \n  \n  \n    \n      0\n      135\n      181\n      308\n      218\n      ConstITUtIO\n      0\n    \n    \n      1\n      156\n      264\n      217\n      284\n      NLTHE\n      1\n    \n    \n      2\n      218\n      264\n      276\n      284\n      PEOPLE\n      1\n    \n    \n      3\n      267\n      265\n      295\n      282\n      OF\n      1\n    \n    \n      4\n      297\n      264\n      341\n      284\n      INDIA,\n      1\n    \n  \n\n\n\n\n  \n    \n      \n      x\n      y\n      X\n      Y\n      text\n      block_id\n    \n  \n  \n    \n      0\n      135\n      181\n      308\n      218\n      ConstITUtIO\n      0\n    \n    \n      1\n      156\n      264\n      217\n      284\n      NLTHE\n      1\n    \n    \n      2\n      218\n      264\n      276\n      284\n      PEOPLE\n      1\n    \n    \n      3\n      267\n      265\n      295\n      282\n      OF\n      1\n    \n    \n      4\n      297\n      264\n      341\n      284\n      INDIA,\n      1\n    \n  \n\n\n\n\n  \n    \n      \n      x\n      y\n      X\n      Y\n      text\n      block_id\n    \n  \n  \n    \n      0\n      0.249538\n      0.253501\n      0.569316\n      0.305322\n      ConstITUtIO\n      0\n    \n    \n      1\n      0.288355\n      0.369748\n      0.401109\n      0.397759\n      NLTHE\n      1\n    \n    \n      2\n      0.402957\n      0.369748\n      0.510166\n      0.397759\n      PEOPLE\n      1\n    \n    \n      3\n      0.493530\n      0.371148\n      0.545287\n      0.394958\n      OF\n      1\n    \n    \n      4\n      0.548983\n      0.369748\n      0.630314\n      0.397759\n      INDIA,\n      1\n    \n  \n\n\n\n\nshow(im, df=df, sz=10)\n\n\n\n\n\n\n\n\n\nshow(im, df=to_absolute(df, *im.shape[:2]), sz=10)\n\n\n\n\n\n\n\n\n\n_df = to_absolute(df, *im.shape[:2])\nshow(im, df=to_relative(_df, *im.shape[:2]), sz=10)\n\n\n\n\n\n\n\n\n\n_df = combine_xyXY_to_bb(_df)\nshow(im, df=to_relative(_df, *im.shape[:2]), sz=10)\n\n\n\n\n\n\n\n\n\nto_relative(_df, *im.shape[:2])\n\n\n\n\n\n\n\n\ntext\nblock_id\nbb\n\n\n\n\n0\nConstITUtIO\n0\n[0.24953789279112754, 0.2535014005602241, 0.56...\n\n\n1\nNLTHE\n1\n[0.28835489833641403, 0.3697478991596639, 0.40...\n\n\n2\nPEOPLE\n1\n[0.4029574861367837, 0.3697478991596639, 0.510...\n\n\n3\nOF\n1\n[0.49353049907578556, 0.3711484593837535, 0.54...\n\n\n4\nINDIA,\n1\n[0.5489833641404805, 0.3697478991596639, 0.630...\n\n\n...\n...\n...\n...\n\n\n68\nGIVE\n13\n[0.4011090573012939, 0.7366946778711485, 0.478...\n\n\n69\nTO\n13\n[0.4879852125693161, 0.7366946778711485, 0.536...\n\n\n70\noUrSELVES\n13\n[0.5508317929759704, 0.7394957983193278, 0.706...\n\n\n71\nTHIS\n13\n[0.7190388170055453, 0.7366946778711485, 0.783...\n\n\n72\nCONSTITUTION.\n14\n[0.23290203327171904, 0.7689075630252101, 0.44...\n\n\n\n\n73 rows × 3 columns\n\n\n\n\n\nisin\n\n isin (bboxes1, bboxes2, return_matrix=True)\n\nreturn indexes of those boxes from bboxes1 that are completely inside bboxes2\n\n\n\nmerge_by_bb\n\n merge_by_bb (df1, df2, suffixes=('_x', '_y'), iou_threshold=0.1)\n\nMerge df1 columns to df2 by using iou Make sure both df1 & df2 are relative or both absolute",
    "crumbs": [
      "Bounding Box"
    ]
  },
  {
    "objectID": "load_defautls.html",
    "href": "load_defautls.html",
    "title": "File Exists",
    "section": "",
    "text": "loadifexists (fpath, default)\n\nLoad data from a dill file if it exists, else return default value\n\n\n\n\n\n exists (fpath)\n\nAlias for os.path.exists",
    "crumbs": [
      "File Exists"
    ]
  },
  {
    "objectID": "load_defautls.html#section",
    "href": "load_defautls.html#section",
    "title": "File Exists",
    "section": "",
    "text": "loadifexists (fpath, default)\n\nLoad data from a dill file if it exists, else return default value\n\n\n\n\n\n exists (fpath)\n\nAlias for os.path.exists",
    "crumbs": [
      "File Exists"
    ]
  },
  {
    "objectID": "interactive_show.html",
    "href": "interactive_show.html",
    "title": "torch_snippets",
    "section": "",
    "text": "ishow\n\n ishow (im, df, additional_attrs=None, **kwargs)\n\n\n\n\ndf2graph_nodes\n\n df2graph_nodes (df, text_attr='text', additional_attrs=None)\n\n\n\n\nviz2\n\n viz2 (graph, node_attrs=None, undirected=True, **kwargs)\n\n\n\n\nconvert_to_nx\n\n convert_to_nx (g, node_attrs=None, undirected=True)\n\n\n\n\ntolist\n\n tolist (i)\n\n\n\n\ntonp\n\n tonp (i)\n\n\n\n\nplot_graph\n\n plot_graph (g, output, im=None, **kwargs)\n\n\n\n\nplot_image\n\n plot_image (p, image, sz)\n\n\n\n\nto_networkx\n\n to_networkx (data, node_attrs:Optional[Iterable[str]]=None,\n              edge_attrs:Optional[Iterable[str]]=None,\n              graph_attrs:Optional[Iterable[str]]=None,\n              to_undirected:Union[bool,str,NoneType]=False,\n              remove_self_loops:bool=False)",
    "crumbs": [
      "interactive_show.html"
    ]
  },
  {
    "objectID": "nbs/jupyter_notebook.html",
    "href": "nbs/jupyter_notebook.html",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "backup_folders_of_nbs\n\n backup_folders_of_nbs (src, dest)\n\n\n\n\nbackup_all_notebooks\n\n backup_all_notebooks (folder)\n\n\n\n\nbackup_this_notebook\n\n backup_this_notebook (this_file_path, save_html_to_dir=None,\n                       override_previous_backup=False, changelog=None,\n                       exclude_input=False, force_save_notebook=True)\n\n\n\n\nsave_notebook\n\n save_notebook (file_path)\n\n\nbackup_this_notebook(\"jupyter_notebook.ipynb\")\n\n\n\n\nshow_big_dataframe\n\n show_big_dataframe (df, max_rows=30)\n\n\n\n\ndisplay_dfs_side_by_side\n\n display_dfs_side_by_side (*args, titles=&lt;itertools.cycle object at\n                           0x12a1b5b80&gt;, max_rows=50)\n\n\n\n\nh6\n\n h6 (text)\n\n\n\n\nh5\n\n h5 (text)\n\n\n\n\nh4\n\n h4 (text)\n\n\n\n\nh3\n\n h3 (text)\n\n\n\n\nh2\n\n h2 (text)\n\n\n\n\nh1\n\n h1 (text)\n\n\n\n\nstore_scrap\n\n store_scrap (at)\n\n\n\n\nshutdown_current_notebook\n\n shutdown_current_notebook (delay:int=None)"
  },
  {
    "objectID": "nbs/load_defautls.html",
    "href": "nbs/load_defautls.html",
    "title": "File Exists",
    "section": "",
    "text": "loadifexists (fpath, default)\n\nLoad data from a dill file if it exists, else return default value\n\n\n\n\n\n exists (fpath)\n\nAlias for os.path.exists"
  },
  {
    "objectID": "nbs/load_defautls.html#section",
    "href": "nbs/load_defautls.html#section",
    "title": "File Exists",
    "section": "",
    "text": "loadifexists (fpath, default)\n\nLoad data from a dill file if it exists, else return default value\n\n\n\n\n\n exists (fpath)\n\nAlias for os.path.exists"
  },
  {
    "objectID": "nbs/markups.html",
    "href": "nbs/markups.html",
    "title": "Markups",
    "section": "",
    "text": "AttrDict\n\n AttrDict (*args, given_input_to_ad=None, **kwargs)\n\n*Utility class to interact with a dictionary as if it were an object. AD is an alias to this class\nFEATURES: 0. Access and modify keys (including nested keys) as if they were object attributes, supporting tab-completion. Example: self.key1.key2[0].key3 1. Keys and values are recursively converted to AttrDict instances. 2. Pretty-print the dictionary using print. 3. Convert the entire structure to a regular dictionary at any time using self.to_dict() / self.dict(). 3. Recursively remove keys using self.drop(key) from a JSON object. 4. Apply a function to all values at all levels using map.\nGOTCHAS: 1. All integer keys are implicitly converted to strings due to the enforced self.key format. 2. You can still use self[int], but this internally converts the integer to a string.\nMETHODS: - items(): Return the items of the AttrDict as key-value pairs. - keys(): Return the keys of the AttrDict. - values(): Return the values of the AttrDict. - update(dict): Update the AttrDict with key-value pairs from another dictionary. - get(key, default=None): Get the value associated with a key, with an optional default value. - __iter__(): Allow iteration over the keys of the AttrDict. - __len__(): Return the number of keys in the AttrDict. - __repr__(): Return a string representation of the AttrDict. - __dir__(): List the keys of the AttrDict as attributes. - __contains__(key): Check if a key exists in the AttrDict, use ‘a.b.c’ notation to directly check for a nested attribute. - __delitem__(key): Delete a key from the AttrDict. - map(func): Apply a function to all values in the AttrDict. - drop(key): Recursively remove a key and its values from the AttrDict. - to_dict(): Convert the AttrDict and its nested structure to a regular dictionary. - pretty(print_with_logger=False, *args, **kwargs): Pretty-print the AttrDict as JSON. - __eq__(other): Compare the AttrDict with another dictionary for equality. - find_address(key, current_path=\"\"): Find and return all addresses (paths) of a given key in the AttrDict. - summary(current_path='', summary_str='', depth=0, sep='  '): Generate a summary of the structure and values in the AttrDict. - write_summary(to, **kwargs): Write the summary to a file or stream. - fetch(addr): Retrieve a value at a specified address (path).\nPARAMETERS: - data (dict, optional): Initial data to populate the AttrDict.\nUSAGE: - Create an AttrDict instance by providing an optional initial dictionary, and then access and manipulate its contents as if they were object attributes.\nEXAMPLE:\nmy_dict = {'name': 'John', 'age': 30, 'address': {'city': 'New York', 'zip': '10001'}}\nattr_dict = AttrDict(my_dict)\nprint(attr_dict.name)  # Access values like attributes\nattr_dict.address.city = 'Los Angeles'  # Modify nested values\n```*\n\n\n::: {#bfb4146f-90bf-42bc-bf40-69fb6d612ea2 .cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nxx = AttrDict({\"a\": 1, \"b\": [{\"c\": 2, \"d\": 4}, {\"e\": 3}], \"f\": {\"g\": {\"h\": 20}}})\nprint(type(xx.b[0]))\nprint(type(xx.to_dict()[\"b\"][0]))\nprint(\"f.g.h\" in xx)\nxx.pretty()\n\n&lt;class 'torch_snippets.markup2.AttrDict'&gt;\n&lt;class 'dict'&gt;\nTrue\n{\n    \"a\": 1,\n    \"b\": [\n        {\n            \"c\": 2,\n            \"d\": 4\n        },\n        {\n            \"e\": 3\n        }\n    ],\n    \"f\": {\n        \"g\": {\n            \"h\": 20\n        }\n    }\n}\n\n:::\n\nx = {\"abc\": {\"b\": 10, \"c\": 11}, \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234]}}}\n\ny = AttrDict(x)\n\nassert y.abc.b == 10\nassert y.d.e.f == [2, {\"abc\": \"pqrs\"}, 2.234]\n\ny.d.e.g = 11\n\n# del y.abc.c\n# OR\ndel y[\"abc\"][\"c\"]\n\nassert y.to_dict() == {\n    \"abc\": {\"b\": 10},\n    \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234], \"g\": 11}},\n}\n\ny.pretty(indent=2)\n\nassert \"abc\" in y\nassert \"def\" not in y\nprint(\"e\" in y.d)\n\n{\n  \"abc\": {\n    \"b\": 10\n  },\n  \"d\": {\n    \"e\": {\n      \"f\": [\n        2,\n        {\n          \"abc\": \"pqrs\"\n        },\n        2.234\n      ],\n      \"g\": 11\n    }\n  }\n}\nTrue\n\n\n\nx = {\"abc\": {\"b\": 10, \"c\": 11}, \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234]}}}\ny = AttrDict(x)\ny.abc[[\"b\", \"c\"]]\n\n\n```↯ AttrDict ↯\nb - 10 (🏷️ int)\nc - 11 (🏷️ int)\n\n```\n\n\n\n\n\nwrite_json\n\n write_json (obj, fpath, silent=False)\n\n\n\n\nread_json\n\n read_json (fpath)\n\n\ntry:\n    import torch\n\n    d = AD(a=torch.Tensor([1, 2, 3]), b=\"hello\")\n    write_json(d, \"/tmp/tmp.json\")\n    print(\"\\n\".join(readlines(\"/tmp/tmp.json\")))\nexcept ModuleNotFoundError:\n    ...\n\n{\n\"a\": [\n1.0,\n2.0,\n3.0\n],\n\"b\": \"hello\"\n}\n\n\n[06/15/25 19:05:57] INFO     loaded 8 lines                                                                                        &lt;ipython-input-1-e6d68859b80d&gt;:&lt;module&gt;:6\n\n\n\n\nd = [1, {1: 1, 2: 2}, 3]\n\npretty_json({1: 1, 2: 2})\npretty_json(d)\n\nf = write_json(d, \"/tmp/test.json\")\nprint(f)\nread_json(f)\n\n/tmp/test.json\n\n\n[1, {'1': 1, '2': 2}, 3]\n\n\n\n\n\nread_jsonl\n\n read_jsonl (file)\n\n\n\n\nwrite_jsonl\n\n write_jsonl (items, dest, mode='a')\n\n\n\n\nwrite_yaml\n\n write_yaml (content, fpath)\n\n\n\n\nread_yaml\n\n read_yaml (file)\n\n\n\n\nwrite_xml\n\n write_xml (data:Union[torch_snippets.markup2.AttrDict,dict],\n            file_path:Union[str,pathlib._local.Path])\n\n\n\n\nread_xml\n\n read_xml (file_path:Union[str,pathlib._local.Path])\n\nRead xml data as a dictionary\n\ny.to_dict()\n\n{'abc': {'b': 10, 'c': 11}, 'd': {'e': {'f': [2, {'abc': 'pqrs'}, 2.234]}}}\n\n\n\ny\n\n\n```↯ AttrDict ↯\nabc\n  b - 10 (🏷️ int)\n  c - 11 (🏷️ int)\nd\n  e\n    f\n      0 - 2 (🏷️ int)\n      1\n        abc - pqrs (🏷️ str)\n      2 - 2.234 (🏷️ float)\n\n```"
  },
  {
    "objectID": "changelog.html",
    "href": "changelog.html",
    "title": "Changelog",
    "section": "",
    "text": "✨ basic_ad_repr for any class, inspired from fastcore 🎉 tryy can accept a callable for output_to_return_on_fail instead of the usual static variable 🎉 show can directly show s3 paths! 🎉 show will cast pandas series into a dataframe for a better preview 🎉 dates will also consider separators such as ‘17 / 12 / 2025’ 🐛 dates was not checking all formats as expected 🐛 P.rm will pass if the file does not exist and missing_ok is True 🎉 AD.fetch2 can now fetch multiple keys at once 🎉 AD.drop can now return a full, fresh copy so that the orginal is still intact 🎉 AD supports |\n\n\n\n✨ testing a new make target 🐛 bug fix in track2\n\n\n\n🎉 Any method with __show__ will act as a shortcut for the show function 🐛 bug fix in choose\n\n\n\n✨ current_file_dir is a new function that return’s the directory where the file exists ✨ ll method in P 🎉 track2 can take optional info to display 🐛 choose can optionally be silent (useful in funcs like rand) 🐛 tryy will Warn instead of print during an exception\n\n\n\n🐛 fixed a bug where timer was asserting N &gt; 0 instead of N&gt;=0\n\n\n\n✨ printfile will act like cat for linux ✨ choose will let you know what was chosen ✨ Timer can accept N=None and it will simply time the current activities without any estimate ✨ tryy is pickleable (helps with multiprocessing)\n\n\n\n✨ Add profiler\n\n\n\n✨ environment variable AD_SHOW_FULL_STRINGS can be set to non-empty to show full strings in summary 🎉 better integration for unknown datatypes in AD.summary\n\n\n\n🎉 Quality of life improvements in logging 🎉 Add support for dataclass in AD 🎉 DeepDiff integrated into AD. Now you can call x.diff(y) where x is AD and y is ADable 🎉 AD.d (no brackets, d is a property) to convert the object to dictionary ✨ read_json can also do json.loads if input is not a file path ✨ json is loaded by default on import *\n\n\n\n✨ Made all imports lazy for a faster import experience\n\n\n\n✨ set AD_SHOW_TAB_STOPS env variable to anything to print with tab-stops (only recommended to see on REPL. Default is good for storing files) ✨ crop_from_bb has padding (px,py,pX,pY) 🐞 minor bugfix in AD 🎉 AD has a fetch2 which preserves json structure while fetching all the leafs of the same name 🎉 AD has a flatten which flattens all nested jsons into flat dictionary with ‘.’ combined key names 🎉 AD has a flatten_and_make_dataframe which creates one column for each nesting ✨ tryy will store all its errors and can be accessed by calling &lt;func&gt;.error_summary() 🎉 torch snippets as a new cli function called ts, thanks to the wonderful Typer. Try ts time ts zen-of python ts zen-of c++ ts --help\n\n\n\n✨ slightly better error printing in tryy\n\n\n\n🎉 tryy a new decorator to wrap try except with optional default return as well as print stack trace if need be ✨ Timer can given time-remaning approximation based on both instantaneous or average speed ✨ logging_mode functions can be used as both context managers and decorators ✨ better formatting for now() ✨ show auto generates a title if possible ✨ show function includes a framecount parameter to specify which frame of the stack it should search for the title. See its usage in show_big_dataframe ✨ yolo_2_df and df_2_yolo functions in adapters\n\n\n\n✨ AD let’s you know if a collection is list, set or tuple ✨ NEW DEFAULT: use info column to show text else text 🐞 fix a bug where P misbehaves in AD when it doesn’t exist 🐞 fix a bug in show tables 🐞 logger_mode context will gracefully exit ✨ to is compatible with transformers.BatchFeature ⏮️ Revert back P as the code is incompatible with py312\n\n\n\n🆕 parseing a .ini file will add a META key by default which has file and name information. This header can be used in the file variables without creating META to begin with 🆕 parse will merge a base config if a META.base key is found. Works recursively on base files (base of base etc…) 🆕 P can tab complete existing file path name and access that file as an attribute 💡 Did you know parse can perform arithmetic? ✨ registry and parse are imported by default ✨ jitter can work on pd.DataFrame directly 🔨 bbs2df clips negative coordinates ✨ Using 🏷️ to denote data-type in AD 🐞 AD2 is AD now 🐞 AD preserves dict order during serialization ✨ warn_on_fail decorator gives you a free try catch ✨ showing a dataframe of the correct format inside and outside jupyter environments 🐞 AD has improved get, update, map and new write_config, trymap and __json__ ✨ P has two new properties .sz for size of file and .tree to print the tree\n\n\n\n🐞 AD hotfix\n\n\n\n🎉 store_scrap is a new way to store on disk and show jupyter cell outputs in other notebooks.\nBest for presenting complex analyses without worrying about running time-consuming notebooks 🎉 Add support for P in AD summary and write_json 🎉 __json__ supports custom objects’ serializability 🎉 write_json is compatible with above feature 🎉 AD_MAX_ITEMS if given as -1 will change it to 1000 🐞 iou will parse input dataframes more gracefully 🐞 AD minor bug fix 🎉 tree has a better default 🎉 New functions folder_structure_to_dict and folder_structure_to_json in paths 🎉 Add jitter (int) argument to show so that bounding boxes can be a bit jittered 🎉 Add support for changing spinner in notify_waiting 🎉 dumpdill can print a custom message (see store_scrap in paths.py)\n\n\n\n🎉 AD __contains__ can do a nested in ‘x.y.z’ in AD(x={‘y’: {‘z’: 10}}) == True\n\n\n\n☠️ Stop using rich’s print and revert back to builtin print 🐞 Decouple AD and torch 🎉 Add a new chart - spider / radar 🎉 Add scp client with download upload functionality\n\n\n\n🧹 change code to remove future warnings in text_utils\n\n\n\n🐞 AD string summary was buggy\n\n\n\n🐞 all write modes are ‘a’ by default to avoid accidental overwriting 🧹 AD writes better string summary (support for multiline)\n\n\n\n🧹 print_module_ios_for has better targeted functionality where you need to give submodules name 🎉 clean_gpu_mem and get_latest_checkpoint functions in torch_loader 🧹 minor bugfix in AD\n\n\n\n🐞 minor bugfix in AD2 where data keyword misbehaves 🧹 video has better size functionality 🎉 if all is given in print_ios_for_module, all modules are printed 🎉 AD2.dict is an alias for AD2.to_dict 🎉 better AD2.summary for pandas dataframes and AD2.summary respects max_items for keys as well 🎉 new alias pd.read_pqt for pd.read_parquet 🐞 wrap tree into python\n\n\n\n🐞 read loads color image by default 🧹 video utils are present in torch_snippets.video\n\n\n\n🧹 Back to min python version 3.7\n\n\n\n🎉 print_folder_summary\n\n\n\n🧹 import AD from markup2 by default 🎉 pandas dataframe summary in AD.summary\n\n\n\n🐞 print_shapes_hook will gracefully fail\n\n\n\n🐞 attach will add hook to the input module as well (not just the children)\n\n\n\n🐞 minor change in print_shapes_hook\n\n\n\n🎉 print_module_io_for automates attaching and detaching hooks 🎉 AD2 avoids rich printing\n\n\n\n🐞 attach_hooks will accept any custom hook\n\n\n\n🎉 Make markup2.AD.__repr__ the summary 🎉 Expose markup2.AD as AD2 🎉 Make icecream a requirement 🎉 Min python is 3.8\n\n\n\n🎉 New IO hooks system in torch_snippets.trainer.hooks 🎉 Updated markup2.AD.summary and add print_summary methods\n\n\n\n🎉 Experimental AD in torch_snippets.markup2 that infers variable names E.g. - (p=10; AD(p) == {'p': 10}) 🐞 isin will not add +1 (useful for both absolute and relative boxes now) 🐞 write_json will support numpy, torch and AttrDict\n\n\n\n🎉 add find_address to AttrDict that can return all path locations for a specific key 🎉 add summary to AttrDict that can give an outline of the dictionary 🎉 add write_summary to AttrDict that writes the summary to a textfile 🎉 show can now show bb colors {\"r\": (255, 0, 0), \"g\": (0, 255, 0), \"b\": (0, 0, 255), \"y\": (255, 0, 255)} if df has column called color 🎉 AD is an alias for AttrDict 🎉 AD can directly consume kwargs\n\n\n\n🧹 import only important functins from dates.py 🎉 add backup_all_notebooks that backs up every notebook present in a specific folder 🎉 reset_logger can disable stdout logging if needed, using disable_stdout=True kwarg (False by default) common_items will take a list of folders and return common stems from the folders images will show a black border when grid is True\n\n\n\nInfo, Debug, Warn and Excep will format ouputs separated by a ; when args are passed notify_waiting is a new function that letting you know some process is running for an unknown amount of time optional delay during shutdown_current_notebook Info, Debug, Warn and Excep will all have X_mode and in_X_mode functions much like in_debug_mode and debug_mode __init__ will auto pull from logger now Better non-linear Timer (and Report and track2)\n\n\n\n🧹 Info, Debug, Warn and Excep will accept args (instead of a single arg) 🧹 show will show h4 headers instead of h2 for dataframe titles\n\n\n\n🧹 phasify loads by default 🧹 show_big_dataframe can show more rows 🎉 add a new submodule trainer.hooks 🧹 show delegated kwargs to plt.imshow for a better readme 🎉 batchify can batchify multiple containers at once 🎉 cat_with_padding new function in torch_loader 🧹 L is json compatible 🐞 BB will not decide if something is relative/absolute 🎉 __contains__ for config 🎉 to works on AttrDict 👶🏼 track2 is a better version of track uses corouties 👶🏼 debug_mode temporarily activates DEBUG mode on 👶🏼 if in_debug_mode(): lets you know if DEBUG mode is on 🧹 reset_logger can accept lowercase levels also 🧹 dumpdill will return a Path after dumping\n\n\n\nbugfix in loader.show add today function to dates add are_equal_dates to dates add dpi option to pdf\n\n\n\nbugfix in attrdict.map\n\n\n\nAll notebooks are formatted with black parse can parse python expressions Add DeepLearningConfig class that can be used to load model hyperparameters Add GenericConfig class that can be used to load generic (such as training, evaluation) hyperparameters Add date utilities patch_to, Timer, timeit, io are loaded by default lovely_tensors is optional Add phasify function to loader\n\n\n\nattrdict can deserialize “L”\n\n\n\n\nshow can render a dataframe with a title\nshow can accept a csv file as input (no need to load it and send)\nbackup_this_notebook will back up as backups/file/file__0000.html instead of backups/file/0000.html for easier sharability\nmodule loads decorators by default (io, timeit, check_kwargs_not_none)\nishow is less opinionated\nshutdown_this_notebook is a new function\n\n\n\n\noverride_previous_backup should not trigger when there’s no backup to begin with instead of showing markdown objects using display, directly show HTML objects so that the text is preserved on reopen h2 in Backup instead of h1"
  },
  {
    "objectID": "changelog.html#todo",
    "href": "changelog.html#todo",
    "title": "Changelog",
    "section": "",
    "text": "override_previous_backup should not trigger when there’s no backup to begin with instead of showing markdown objects using display, directly show HTML objects so that the text is preserved on reopen h2 in Backup instead of h1"
  },
  {
    "objectID": "decorators.html",
    "href": "decorators.html",
    "title": "Decorator Utilites",
    "section": "",
    "text": "check_kwargs_not_none\n\n check_kwargs_not_none (func)\n\n*A decorator that checks if any keyword argument is None. Raises a ValueError if any argument is None.\nArgs: func: The function to be decorated.\nReturns: The decorated function.\nRaises: ValueError: If any keyword argument is None.*\n\n\n\nio\n\n io (func)\n\n*A decorator that inspects the inputs and outputs of a function.\nArgs: func: The function to be decorated.\nReturns: The decorated function.*\n\n\n\ntimeit\n\n timeit (func)\n\n*A decorator that measures the execution time of a function.\nArgs: func (callable): The function to be timed.\nReturns: callable: The wrapped function.\nExample: @timeit def my_function(): # code to be timed pass\nmy_function()  # prints the execution time of my_function*\n\n\n\nwarn_on_fail\n\n warn_on_fail (func)\n\n\n\n\nformat\n\n format (input)\n\n\n@timeit\n@io\ndef foo(a, b):\n    \"\"\"\n    This function takes two arguments, `a` and `b`, and returns their sum.\n\n    Parameters:\n    a (int): The first number.\n    b (int): The second number.\n\n    Returns:\n    int: The sum of `a` and `b`.\n    \"\"\"\n    import time\n\n    time.sleep(1)\n    return a + b\n\n\nfoo(10, 11)\n\n══════════════════════════════════════════════════════════════════\nINPUTS:ARGS:\ntuple of 2 items\n    int: 10\n    int: 11\n══════════════════════════════════════════════════════════════════\n══════════════════════════════════════════════════════════════════\nOUTPUTS:\nint: 21\n══════════════════════════════════════════════════════════════════\n[06/15/25 18:56:18] INFO     foo took 1.00 seconds to execute                                                                      &lt;ipython-input-1-6ac2073623b5&gt;:wrapper:47\n\n\n21\n\n\n\n@check_kwargs_not_none\n@io\ndef foo(*, a=None, b=None):\n    return a + b\n\n\nfoo(a=None, b=10)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[34], line 6\n      1 @check_kwargs_not_none\n      2 @io\n      3 def foo(*, a=None, b=None):\n      4     return a + b\n----&gt; 6 foo(a=None, b=10)\n\nCell In[32], line 32, in check_kwargs_not_none.&lt;locals&gt;.wrapper(*args, **kwargs)\n     30 for key, value in kwargs.items():\n     31     if value is None:\n---&gt; 32         raise ValueError(f\"Input argument '{key}' cannot be None\")\n     33 return func(*args, **kwargs)\n\nValueError: Input argument 'a' cannot be None\n\n\n\n\nimport nbdev\n\nnbdev.nbdev_export()",
    "crumbs": [
      "Decorator Utilites"
    ]
  },
  {
    "objectID": "markups.html",
    "href": "markups.html",
    "title": "Markups",
    "section": "",
    "text": "AttrDict\n\n AttrDict (*args, given_input_to_ad=None, **kwargs)\n\n*Utility class to interact with a dictionary as if it were an object. AD is an alias to this class\nFEATURES: 0. Access and modify keys (including nested keys) as if they were object attributes, supporting tab-completion. Example: self.key1.key2[0].key3 1. Keys and values are recursively converted to AttrDict instances. 2. Pretty-print the dictionary using print. 3. Convert the entire structure to a regular dictionary at any time using self.to_dict() / self.dict(). 3. Recursively remove keys using self.drop(key) from a JSON object. 4. Apply a function to all values at all levels using map.\nGOTCHAS: 1. All integer keys are implicitly converted to strings due to the enforced self.key format. 2. You can still use self[int], but this internally converts the integer to a string.\nMETHODS: - items(): Return the items of the AttrDict as key-value pairs. - keys(): Return the keys of the AttrDict. - values(): Return the values of the AttrDict. - update(dict): Update the AttrDict with key-value pairs from another dictionary. - get(key, default=None): Get the value associated with a key, with an optional default value. - __iter__(): Allow iteration over the keys of the AttrDict. - __len__(): Return the number of keys in the AttrDict. - __repr__(): Return a string representation of the AttrDict. - __dir__(): List the keys of the AttrDict as attributes. - __contains__(key): Check if a key exists in the AttrDict, use ‘a.b.c’ notation to directly check for a nested attribute. - __delitem__(key): Delete a key from the AttrDict. - map(func): Apply a function to all values in the AttrDict. - drop(key): Recursively remove a key and its values from the AttrDict. - to_dict(): Convert the AttrDict and its nested structure to a regular dictionary. - pretty(print_with_logger=False, *args, **kwargs): Pretty-print the AttrDict as JSON. - __eq__(other): Compare the AttrDict with another dictionary for equality. - find_address(key, current_path=\"\"): Find and return all addresses (paths) of a given key in the AttrDict. - summary(current_path='', summary_str='', depth=0, sep='  '): Generate a summary of the structure and values in the AttrDict. - write_summary(to, **kwargs): Write the summary to a file or stream. - fetch(addr): Retrieve a value at a specified address (path).\nPARAMETERS: - data (dict, optional): Initial data to populate the AttrDict.\nUSAGE: - Create an AttrDict instance by providing an optional initial dictionary, and then access and manipulate its contents as if they were object attributes.\nEXAMPLE:\nmy_dict = {'name': 'John', 'age': 30, 'address': {'city': 'New York', 'zip': '10001'}}\nattr_dict = AttrDict(my_dict)\nprint(attr_dict.name)  # Access values like attributes\nattr_dict.address.city = 'Los Angeles'  # Modify nested values\n```*\n\n\n::: {#bfb4146f-90bf-42bc-bf40-69fb6d612ea2 .cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nxx = AttrDict({\"a\": 1, \"b\": [{\"c\": 2, \"d\": 4}, {\"e\": 3}], \"f\": {\"g\": {\"h\": 20}}})\nprint(type(xx.b[0]))\nprint(type(xx.to_dict()[\"b\"][0]))\nprint(\"f.g.h\" in xx)\nxx.pretty()\n\n&lt;class 'torch_snippets.markup2.AttrDict'&gt;\n&lt;class 'dict'&gt;\nTrue\n{\n    \"a\": 1,\n    \"b\": [\n        {\n            \"c\": 2,\n            \"d\": 4\n        },\n        {\n            \"e\": 3\n        }\n    ],\n    \"f\": {\n        \"g\": {\n            \"h\": 20\n        }\n    }\n}\n\n:::\n\nx = {\"abc\": {\"b\": 10, \"c\": 11}, \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234]}}}\n\ny = AttrDict(x)\n\nassert y.abc.b == 10\nassert y.d.e.f == [2, {\"abc\": \"pqrs\"}, 2.234]\n\ny.d.e.g = 11\n\n# del y.abc.c\n# OR\ndel y[\"abc\"][\"c\"]\n\nassert y.to_dict() == {\n    \"abc\": {\"b\": 10},\n    \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234], \"g\": 11}},\n}\n\ny.pretty(indent=2)\n\nassert \"abc\" in y\nassert \"def\" not in y\nprint(\"e\" in y.d)\n\n{\n  \"abc\": {\n    \"b\": 10\n  },\n  \"d\": {\n    \"e\": {\n      \"f\": [\n        2,\n        {\n          \"abc\": \"pqrs\"\n        },\n        2.234\n      ],\n      \"g\": 11\n    }\n  }\n}\nTrue\n\n\n\nx = {\"abc\": {\"b\": 10, \"c\": 11}, \"d\": {\"e\": {\"f\": [2, {\"abc\": \"pqrs\"}, 2.234]}}}\ny = AttrDict(x)\ny.abc[[\"b\", \"c\"]]\n\n\n```↯ AttrDict ↯\nb - 10 (🏷️ int)\nc - 11 (🏷️ int)\n\n```\n\n\n\n\n\nwrite_json\n\n write_json (obj, fpath, silent=False)\n\n\n\n\nread_json\n\n read_json (fpath)\n\n\ntry:\n    import torch\n\n    d = AD(a=torch.Tensor([1, 2, 3]), b=\"hello\")\n    write_json(d, \"/tmp/tmp.json\")\n    print(\"\\n\".join(readlines(\"/tmp/tmp.json\")))\nexcept ModuleNotFoundError:\n    ...\n\n[06/15/25 18:56:21] INFO     loaded 8 lines                                                                                        &lt;ipython-input-1-e6d68859b80d&gt;:&lt;module&gt;:6\n{\n\"a\": [\n1.0,\n2.0,\n3.0\n],\n\"b\": \"hello\"\n}\n\n\n\nd = [1, {1: 1, 2: 2}, 3]\n\npretty_json({1: 1, 2: 2})\npretty_json(d)\n\nf = write_json(d, \"/tmp/test.json\")\nprint(f)\nread_json(f)\n\n/tmp/test.json\n\n\n[1, {'1': 1, '2': 2}, 3]\n\n\n\n\n\nread_jsonl\n\n read_jsonl (file)\n\n\n\n\nwrite_jsonl\n\n write_jsonl (items, dest, mode='a')\n\n\n\n\nwrite_yaml\n\n write_yaml (content, fpath)\n\n\n\n\nread_yaml\n\n read_yaml (file)\n\n\n\n\nwrite_xml\n\n write_xml (data:Union[torch_snippets.markup2.AttrDict,dict],\n            file_path:Union[str,pathlib._local.Path])\n\n\n\n\nread_xml\n\n read_xml (file_path:Union[str,pathlib._local.Path])\n\nRead xml data as a dictionary\n\ny.to_dict()\n\n{'abc': {'b': 10, 'c': 11}, 'd': {'e': {'f': [2, {'abc': 'pqrs'}, 2.234]}}}\n\n\n\ny\n\n\n```↯ AttrDict ↯\nabc\n  b - 10 (🏷️ int)\n  c - 11 (🏷️ int)\nd\n  e\n    f\n      0 - 2 (🏷️ int)\n      1\n        abc - pqrs (🏷️ str)\n      2 - 2.234 (🏷️ float)\n\n```",
    "crumbs": [
      "Markups"
    ]
  },
  {
    "objectID": "attrdict.html",
    "href": "attrdict.html",
    "title": "AttrDict / AD",
    "section": "",
    "text": "from torch_snippets import AD\n\nenv: AD_MAX_ITEMS=30",
    "crumbs": [
      "AttrDict / AD"
    ]
  },
  {
    "objectID": "attrdict.html#basic-invocations",
    "href": "attrdict.html#basic-invocations",
    "title": "AttrDict / AD",
    "section": "Basic Invocations",
    "text": "Basic Invocations\n\nJust replace dict with AD\nAD is simply a dictionary, so you can create one in the same way you would create any dictionary.\n\nad = AD(\n    x=\"1\",\n    y=2.0,\n    z=3 + 5j,\n    k=AD(\n        l={\"you\": \"can\", \"nest\": \"dictionaries\"},\n        m=2,\n        n=3,\n        _tuple=(1, 2, 3, (4, 5, 6)),\n        _set={1, 2, 3},\n        _list=[1, 2, 3, [4, 5, 6]],\n    ),\n)\n\nprint(ad)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nz - (3+5j) (🏷️ complex)\nk\n  l\n    you - can (🏷️ str)\n    nest - dictionaries (🏷️ str)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```\n\n\n\n\n\nAD supports args\nAD(x,y,z) == AD(x=x, y=y, z=z)\nIf you want to create a dictionary from variables, there’s a good chance that the key you’d want to assign to that variable is the same as your variable name. AttrDict introspects the args intelligently (thanks to icecream module) and assigns the variable itself as the key name\n\nx, y, z = \"1\", 2.0, 3 + 5j\nl, m, n = (\n    {\"y\": {\"c\": {\"n\": \"d\", \"greet\": \"hello\", \"o\": [1, 2, 3, {\"m\": {\"n\": [4, 5, 6]}}]}}},\n    2,\n    3,\n)\n_tuple=(1, 2, 3, (4, 5, 6))\n_set={1, 2, 3}\n_list=[1, 2, 3, [4, 5, 6]]\nk = AD(l, m, n, _tuple, _set, _list)\nad = AD(x, y, z, k)\nprint(ad)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nz - (3+5j) (🏷️ complex)\nk\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```\n\n\n\nDon’t worry if you want to control the key names, you can still give your own kwargs, or even mix it up with both args and kwargs\n\n_tuple=(1, 2, 3, (4, 5, 6))\n_set={1, 2, 3}\n_list=[1, 2, 3, [4, 5, 6]]\nk = AD(l, m, n, _tuple, _set, _list)\nad = AD(x, y, zed=z, kay=k)\nprint(ad)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```",
    "crumbs": [
      "AttrDict / AD"
    ]
  },
  {
    "objectID": "attrdict.html#methods",
    "href": "attrdict.html#methods",
    "title": "AttrDict / AD",
    "section": "Methods",
    "text": "Methods\nSince AD is an extension of a dictionary, all the dictionary methods such as .keys(), .values(), .items() work exactly as expected\n\n.keys\n\nad.keys()\n\ndict_keys(['x', 'y', 'zed', 'kay'])\n\n\n\n\n.values\n\nad.values()\n\ndict_values(['1', 2.0, (3+5j), \n```↯ AttrDict ↯\nl\n  y\n    c\n      n - d (🏷️ str)\n      greet - hello (🏷️ str)\n      o[]\n        0 - 1 (🏷️ int)\n        1 - 2 (🏷️ int)\n        2 - 3 (🏷️ int)\n        3\n          m\n            n[]\n              0 - 4 (🏷️ int)\n              1 - 5 (🏷️ int)\n              2 - 6 (🏷️ int)\nm - 2 (🏷️ int)\nn - 3 (🏷️ int)\n_tuple()\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3()\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n_set{}\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n_list[]\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3[]\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n\n```\n])\n\n\n\n\n.items\n\nad.items()\n\ndict_items([('x', '1'), ('y', 2.0), ('zed', (3+5j)), ('kay', \n```↯ AttrDict ↯\nl\n  y\n    c\n      n - d (🏷️ str)\n      greet - hello (🏷️ str)\n      o[]\n        0 - 1 (🏷️ int)\n        1 - 2 (🏷️ int)\n        2 - 3 (🏷️ int)\n        3\n          m\n            n[]\n              0 - 4 (🏷️ int)\n              1 - 5 (🏷️ int)\n              2 - 6 (🏷️ int)\nm - 2 (🏷️ int)\nn - 3 (🏷️ int)\n_tuple()\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3()\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n_set{}\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n_list[]\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3[]\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n\n```\n)])\n\n\n\n\nUse .d/.dict()/.to_dict() to Create a Vanilla Dict\nAll the three are identical. The latter two are present mostly for backward compatibility.\n\nassert ad.d == ad.dict() == ad.to_dict()\n\n\nd = ad.d\nd\n\n{'x': '1',\n 'y': 2.0,\n 'zed': (3+5j),\n 'kay': {'l': {'y': {'c': {'n': 'd',\n     'greet': 'hello',\n     'o': (#4) [1,2,3,{'m': {'n': [4, 5, 6]}}]}}},\n  'm': 2,\n  'n': 3,\n  '_tuple': (1, 2, 3, (4, 5, 6)),\n  '_set': {1, 2, 3},\n  '_list': (#4) [1,2,3,[4, 5, 6]]}}\n\n\n\n\nAD From Vanilla Dict (Another Basic Invocation)\n\nassert AD(ad.d) == ad\n\n\nad = AD(ad.d)\nad\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```\n\n\n\n\n. Accessing a key\nAs the name of the class suggests, keys can be accessed as if they are attributes\n\nassert ad.x == d[\"x\"]\nassert ad.kay.l.y.c.n == d[\"kay\"][\"l\"][\"y\"][\"c\"][\"n\"]\nassert ad.kay.l.y.c.o[3].m.n == d[\"kay\"][\"l\"][\"y\"][\"c\"][\"o\"][3][\"m\"][\"n\"]\n\n\n\nin Searching for keys\nHighlevel keys are anyway accessable just like, in a normal dictionary\n\nassert \"zed\" in ad\n\nyou can check for presence/absence of nested keys by joining them with a ‘.’\n\nassert \"kay.l.y.c.n\" in ad\n\n\n\n.find_address Find if a key exists and return where it is, i.e., the address of the key\nThe method always returns a list of addresses\n\nad.find_address(\"c\")\n\n['kay.l.y.c']\n\n\n\nad.find_address(\"n\")\n\n['kay.l.y.c.n', 'kay.l.y.c.o.3.m.n', 'kay.n']\n\n\n\nad.find_address(\"hello\")\n\n[]\n\n\n\n\n.fetch fetch all the addresses\n\nad.fetch(ad.find_address(\"n\"))\n\n(#3) ['d',[4, 5, 6],3]\n\n\n\nad.fetch([\"kay.l.y.c.n\", \"kay.l.y.c.o.3.m.n\", \"kay.n\"])\n\n(#3) ['d',[4, 5, 6],3]\n\n\n\n\n.fetch2 fetches all the addresses while preserving the key hierarchy\n\nad.fetch2(addrs=[\"kay.l.y.c.n\", \"kay.l.y.c.o.3.m.n\", \"kay.n\"])\n\n\n```↯ AttrDict ↯\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        o\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  n - 3 (🏷️ int)\n\n```\n\n\n\n\n.fetch2 can also directly fetch all the keys at once (by first finding all addresses and then fetching all of them)\n\nad.fetch2(key=\"n\")\n\n\n```↯ AttrDict ↯\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        o\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  n - 3 (🏷️ int)\n\n```\n\n\n\n\n.slice make a dictionary out of all keys present anywhere in the dictionary\n\nad.slice(\"n\")\n\n\n```↯ AttrDict ↯\nkay.l.y.c.n - d (🏷️ str)\nkay.l.y.c.o.3.m.n[]\n  0 - 4 (🏷️ int)\n  1 - 5 (🏷️ int)\n  2 - 6 (🏷️ int)\nkay.n - 3 (🏷️ int)\n\n```\n\n\n\n\n.get\nGet works as usual but can also work with nested keys\n\nad.get(\"x\", 10)\n\n'1'\n\n\n\nad.get(\"yolo\", 10)\n\n10\n\n\n\nad.get(\"kay.l.y.c\", 20)\n\n\n```↯ AttrDict ↯\nn - d (🏷️ str)\ngreet - hello (🏷️ str)\no[]\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3\n    m\n      n[]\n        0 - 4 (🏷️ int)\n        1 - 5 (🏷️ int)\n        2 - 6 (🏷️ int)\n\n```\n\n\n\nad.get(\"kay.l.y.hello\", 20)\n\n20\n\n\n\n\n.set\nWill also work similarly as get\n\nad.set(\"bee.sea.dee\", \"e\")\n\n\nad\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\n\n.map Map a function on all leaf nodes\n\nfrom torch_snippets import h4\n\ndef into_two(x):\n    try:\n        return 2 * x\n    except:\n        return x\n\nad2 = ad.map(into_two)\nh4(\"Original\")\nprint(ad)\nh4(\"New\")\nprint(ad2)\n\nOriginal\n\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\nNew\n\n\n\n```↯ AttrDict ↯\nx - 11 (🏷️ str)\ny - 4.0 (🏷️ float)\nzed - (6+10j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - dd (🏷️ str)\n        greet - hellohello (🏷️ str)\n        o[]\n          0 - 2 (🏷️ int)\n          1 - 4 (🏷️ int)\n          2 - 6 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 8 (🏷️ int)\n                1 - 10 (🏷️ int)\n                2 - 12 (🏷️ int)\n  m - 4 (🏷️ int)\n  n - 6 (🏷️ int)\n  _tuple[]\n    0 - 2 (🏷️ int)\n    1 - 4 (🏷️ int)\n    2 - 6 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n      3 - 4 (🏷️ int)\n      4 - 5 (🏷️ int)\n      5 - 6 (🏷️ int)\n  _set[]\n    0 - 2 (🏷️ int)\n    1 - 4 (🏷️ int)\n    2 - 6 (🏷️ int)\n  _list[]\n    0 - 2 (🏷️ int)\n    1 - 4 (🏷️ int)\n    2 - 6 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - ee (🏷️ str)\n\n```\n\n\n\n\n\n.trymap Map a function on all leaf nodes and preserve the leaf as it is, if the function fails\n\ndef plus_thousand(x):\n    return x + 1000\n\n\nad2 = ad.trymap(plus_thousand)\nprint(ad2)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 1002.0 (🏷️ float)\nzed - (1003+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1001 (🏷️ int)\n          1 - 1002 (🏷️ int)\n          2 - 1003 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 1004 (🏷️ int)\n                1 - 1005 (🏷️ int)\n                2 - 1006 (🏷️ int)\n  m - 1002 (🏷️ int)\n  n - 1003 (🏷️ int)\n  _tuple[]\n    0 - 1001 (🏷️ int)\n    1 - 1002 (🏷️ int)\n    2 - 1003 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set[]\n    0 - 1001 (🏷️ int)\n    1 - 1002 (🏷️ int)\n    2 - 1003 (🏷️ int)\n  _list[]\n    0 - 1001 (🏷️ int)\n    1 - 1002 (🏷️ int)\n    2 - 1003 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n      3 - 1000 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\n\n\n.drop Drop a key, even if it is present somewhere nested\n\nad.find_address(\"n\")\n\n['kay.l.y.c.n', 'kay.l.y.c.o.3.m.n', 'kay.n']\n\n\n\nfrom copy import deepcopy\n\nad2 = deepcopy(ad)\nad2.drop(\"n\")\n\n\nad2\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n  m - 2 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\n\n.update\n\nad2.update(\n    {\"y\": \"γ\", \"greek\": {\"alpha\": \"α\", \"beta\": \"β\", \"gamma\": [1, 2, {\"theta\": \"θ\"}]}}\n)\nad2\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - γ (🏷️ str)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n  m - 2 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\ngreek\n  alpha - α (🏷️ str)\n  beta - β (🏷️ str)\n  gamma[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2\n      theta - θ (🏷️ str)\n\n```\n\n\n\n\n.flatten will flatten all the nests into a single level\n\nad2.flatten()\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - γ (🏷️ str)\nzed - (3+5j) (🏷️ complex)\nkay.l.y.c.greet - hello (🏷️ str)\nkay.l.y.c.o.0 - 1 (🏷️ int)\nkay.l.y.c.o.1 - 2 (🏷️ int)\nkay.l.y.c.o.2 - 3 (🏷️ int)\nkay.m - 2 (🏷️ int)\nkay._tuple.0 - 1 (🏷️ int)\nkay._tuple.1 - 2 (🏷️ int)\nkay._tuple.2 - 3 (🏷️ int)\nkay._tuple.3()\n  0 - 4 (🏷️ int)\n  1 - 5 (🏷️ int)\n  2 - 6 (🏷️ int)\nkay._set.0 - 1 (🏷️ int)\nkay._set.1 - 2 (🏷️ int)\nkay._set.2 - 3 (🏷️ int)\nkay._list.0 - 1 (🏷️ int)\nkay._list.1 - 2 (🏷️ int)\nkay._list.2 - 3 (🏷️ int)\nkay._list.3[]\n  0 - 4 (🏷️ int)\n  1 - 5 (🏷️ int)\n  2 - 6 (🏷️ int)\nbee.sea.dee - e (🏷️ str)\ngreek.alpha - α (🏷️ str)\ngreek.beta - β (🏷️ str)\ngreek.gamma.0 - 1 (🏷️ int)\ngreek.gamma.1 - 2 (🏷️ int)\ngreek.gamma.2.theta - θ (🏷️ str)\n\n```\n\n\n\n\n.flatten_and_make_dataframe is self explanatory\n\nad2.flatten_and_make_dataframe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\nx\n1\nNone\nNone\nNone\nNone\nNaN\n\n\n1\ny\nγ\nNone\nNone\nNone\nNone\nNaN\n\n\n2\nzed\n(3+5j)\nNone\nNone\nNone\nNone\nNaN\n\n\n3\nkay\nl\ny\nc\ngreet\nhello\nNaN\n\n\n4\nkay\nl\ny\nc\no\n0\n1.0\n\n\n5\nkay\nl\ny\nc\no\n1\n2.0\n\n\n6\nkay\nl\ny\nc\no\n2\n3.0\n\n\n7\nkay\nm\n2\nNone\nNone\nNone\nNaN\n\n\n8\nkay\n_tuple\n0\n1\nNone\nNone\nNaN\n\n\n9\nkay\n_tuple\n1\n2\nNone\nNone\nNaN\n\n\n10\nkay\n_tuple\n2\n3\nNone\nNone\nNaN\n\n\n11\nkay\n_tuple\n3\n(4, 5, 6)\nNone\nNone\nNaN\n\n\n12\nkay\n_set\n0\n1\nNone\nNone\nNaN\n\n\n13\nkay\n_set\n1\n2\nNone\nNone\nNaN\n\n\n14\nkay\n_set\n2\n3\nNone\nNone\nNaN\n\n\n15\nkay\n_list\n0\n1\nNone\nNone\nNaN\n\n\n16\nkay\n_list\n1\n2\nNone\nNone\nNaN\n\n\n17\nkay\n_list\n2\n3\nNone\nNone\nNaN\n\n\n18\nkay\n_list\n3\n[4, 5, 6]\nNone\nNone\nNaN\n\n\n19\nbee\nsea\ndee\ne\nNone\nNone\nNaN\n\n\n20\ngreek\nalpha\nα\nNone\nNone\nNone\nNaN\n\n\n21\ngreek\nbeta\nβ\nNone\nNone\nNone\nNaN\n\n\n22\ngreek\ngamma\n0\n1\nNone\nNone\nNaN\n\n\n23\ngreek\ngamma\n1\n2\nNone\nNone\nNaN\n\n\n24\ngreek\ngamma\n2\ntheta\nθ\nNone\nNaN\n\n\n\n\n\n\n\n\n\n.diff on other ADs/dicts\n\na = AD(w=0, x=1, y=3, _list=[1,2,3], _set={1,2,3}, _tuple=(1,2,3), z=10, a=AD(a=1))\nb = AD(w=0, x=2, z=2, _list=[1,3,4,5], _set={1,3,4}, _tuple=(1,3,4,5), k=20, b=AD(b=1))\na.diff(b)\n\n\n```↯ AttrDict ↯\ndictionary_item_added - SetOrdered([\"root['k']\", \"root['b']\"]) (🏷️ SetOrdered)\ndictionary_item_removed - SetOrdered([\"root['y']\", \"root['a']\"]) (🏷️ SetOrdered)\nvalues_changed\n  root['x']\n    new_value - 2 (🏷️ int)\n    old_value - 1 (🏷️ int)\n  root['z']\n    new_value - 2 (🏷️ int)\n    old_value - 10 (🏷️ int)\n  root['_list'][1]\n    new_value - 3 (🏷️ int)\n    old_value - 2 (🏷️ int)\n  root['_list'][2]\n    new_value - 4 (🏷️ int)\n    old_value - 3 (🏷️ int)\n  root['_tuple'][1]\n    new_value - 3 (🏷️ int)\n    old_value - 2 (🏷️ int)\n  root['_tuple'][2]\n    new_value - 4 (🏷️ int)\n    old_value - 3 (🏷️ int)\niterable_item_added\n  root['_list'][3] - 5 (🏷️ int)\n  root['_tuple'][3] - 5 (🏷️ int)\nset_item_removed - SetOrdered([\"root['_set'][2]\"]) (🏷️ SetOrdered)\nset_item_added - SetOrdered([\"root['_set'][4]\"]) (🏷️ SetOrdered)\n\n```",
    "crumbs": [
      "AttrDict / AD"
    ]
  },
  {
    "objectID": "attrdict.html#display-exotic-objects",
    "href": "attrdict.html#display-exotic-objects",
    "title": "AttrDict / AD",
    "section": "Display exotic objects",
    "text": "Display exotic objects\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass DC:\n    w: int\n    x: int\n    y: int\n    _list: list\n    _set: set\n\ndc = DC(1,2,3,[1,2,3],{1,2,3})\nprint(dc)\n\nDC(w=1, x=2, y=3, _list=[1, 2, 3], _set={1, 2, 3})\n\n\nnot bad, but we can always do this\n\nprint(AD(dc))\n\n\n```↯ AttrDict ↯\ndc(🏷️ DC:dataclass)\n  w - 1 (🏷️ int)\n  x - 2 (🏷️ int)\n  y - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n\n```\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'x': np.random.randint(0, 100, size=10), 'y': np.random.uniform(0, 1, size=10)})\nprint(df)\n\n    x         y\n0  76  0.492719\n1  89  0.091474\n2   9  0.428809\n3  46  0.359179\n4  43  0.839773\n5  58  0.344325\n6  66  0.563592\n7  33  0.512554\n8  81  0.813390\n9  44  0.932230\n\n\n\nprint(AD(df))\n\n\n```↯ AttrDict ↯\ndf - DataFrame - shape (10, 2) - columns Index(['x', 'y'], dtype='object') - ID:#06c311\n\n```\n\n\n\nCan show torch and numpy tensors in a really pretty way thanks to lovely-tensors module\n\nfrom torch_snippets import *\ninit_torch()\n\nt1 = torch.Tensor([1,2,3]).long()\nt2 = torch.Tensor([1,2,3])\nn1 = np.array([4,5,6])\nn1 = np.array([4,5,6]).astype(float)\nn2 = np.array([4,5,6]).astype(np.float32)\nts = AD(t=AD(t1, t2), n=AD(n1, n2))\nts\n\n\n```↯ AttrDict ↯\nt\n  t1 - 🔦tensor[3] i64 x∈[1, 3] μ=2.000 σ=1.000 [1, 2, 3] - ID:#e2e2033a\n  t2 - 🔦tensor[3] x∈[1.000, 3.000] μ=2.000 σ=1.000 [1.000, 2.000, 3.000] - ID:#8e628779\nn\n  n1 - np.tensor[3] f64 x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#88d24967\n  n2 - np.tensor[3] x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#3928b709\n\n```\n\n\n\nfrom torch_snippets import P\np = AD(p=P().resolve())\np\n\n\n```↯ AttrDict ↯\np - /Users/yeshwanth/Code/Personal/torch_snippets/nbs (🏷️ PosixPath)\n\n```\n\n\n\nsmall_string = '123'\nbig_string = '123'*100\nmultiline_big_string = '\\n'.join([big_string]*100)\nstrs = AD(small_string, big_string, multiline_big_string)\nstrs\n\n\n```↯ AttrDict ↯\nsmall_string - 123 (🏷️ str)\nbig_string - 12312312312312312312312312312312312.........23123123123123123123123123123123123 (🏷️ str)\nmultiline_big_string - ↓\n  ```\n  12312312312312312312312312312312312 ...\n  ...\n  ...\n  ...\n  ... 23123123123123123123123123123123123\n  ``` (🏷️ Multiline str)\n\n```\n\n\nAnd cmbining all of them we have\n\nAD(dc, df, ts, p, strs)\n\n\n```↯ AttrDict ↯\ndc(🏷️ DC:dataclass)\n  w - 1 (🏷️ int)\n  x - 2 (🏷️ int)\n  y - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\ndf - DataFrame - shape (10, 2) - columns Index(['x', 'y'], dtype='object') - ID:#06c311\nts\n  t\n    t1 - 🔦tensor[3] i64 x∈[1, 3] μ=2.000 σ=1.000 [1, 2, 3] - ID:#e2e2033a\n    t2 - 🔦tensor[3] x∈[1.000, 3.000] μ=2.000 σ=1.000 [1.000, 2.000, 3.000] - ID:#8e628779\n  n\n    n1 - np.tensor[3] f64 x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#88d24967\n    n2 - np.tensor[3] x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#3928b709\np\n  p - /Users/yeshwanth/Code/Personal/torch_snippets/nbs (🏷️ PosixPath)\nstrs\n  small_string - 123 (🏷️ str)\n  big_string - 12312312312312312312312312312312312.........23123123123123123123123123123123123 (🏷️ str)\n  multiline_big_string - ↓\n    ```\n    12312312312312312312312312312312312 ...\n    ...\n    ...\n    ...\n    ... 23123123123123123123123123123123123\n    ``` (🏷️ Multiline str)\n\n```",
    "crumbs": [
      "AttrDict / AD"
    ]
  },
  {
    "objectID": "nbs/attrdict.html",
    "href": "nbs/attrdict.html",
    "title": "AttrDict / AD",
    "section": "",
    "text": "from torch_snippets import AD\n\nenv: AD_MAX_ITEMS=30"
  },
  {
    "objectID": "nbs/attrdict.html#basic-invocations",
    "href": "nbs/attrdict.html#basic-invocations",
    "title": "AttrDict / AD",
    "section": "Basic Invocations",
    "text": "Basic Invocations\n\nJust replace dict with AD\nAD is simply a dictionary, so you can create one in the same way you would create any dictionary.\n\nad = AD(\n    x=\"1\",\n    y=2.0,\n    z=3 + 5j,\n    k=AD(\n        l={\"you\": \"can\", \"nest\": \"dictionaries\"},\n        m=2,\n        n=3,\n        _tuple=(1, 2, 3, (4, 5, 6)),\n        _set={1, 2, 3},\n        _list=[1, 2, 3, [4, 5, 6]],\n    ),\n)\n\nprint(ad)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nz - (3+5j) (🏷️ complex)\nk\n  l\n    you - can (🏷️ str)\n    nest - dictionaries (🏷️ str)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```\n\n\n\n\n\nAD supports args\nAD(x,y,z) == AD(x=x, y=y, z=z)\nIf you want to create a dictionary from variables, there’s a good chance that the key you’d want to assign to that variable is the same as your variable name. AttrDict introspects the args intelligently (thanks to icecream module) and assigns the variable itself as the key name\n\nx, y, z = \"1\", 2.0, 3 + 5j\nl, m, n = (\n    {\"y\": {\"c\": {\"n\": \"d\", \"greet\": \"hello\", \"o\": [1, 2, 3, {\"m\": {\"n\": [4, 5, 6]}}]}}},\n    2,\n    3,\n)\n_tuple=(1, 2, 3, (4, 5, 6))\n_set={1, 2, 3}\n_list=[1, 2, 3, [4, 5, 6]]\nk = AD(l, m, n, _tuple, _set, _list)\nad = AD(x, y, z, k)\nprint(ad)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nz - (3+5j) (🏷️ complex)\nk\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```\n\n\n\nDon’t worry if you want to control the key names, you can still give your own kwargs, or even mix it up with both args and kwargs\n\n_tuple=(1, 2, 3, (4, 5, 6))\n_set={1, 2, 3}\n_list=[1, 2, 3, [4, 5, 6]]\nk = AD(l, m, n, _tuple, _set, _list)\nad = AD(x, y, zed=z, kay=k)\nprint(ad)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```"
  },
  {
    "objectID": "nbs/attrdict.html#methods",
    "href": "nbs/attrdict.html#methods",
    "title": "AttrDict / AD",
    "section": "Methods",
    "text": "Methods\nSince AD is an extension of a dictionary, all the dictionary methods such as .keys(), .values(), .items() work exactly as expected\n\n.keys\n\nad.keys()\n\ndict_keys(['x', 'y', 'zed', 'kay'])\n\n\n\n\n.values\n\nad.values()\n\ndict_values(['1', 2.0, (3+5j), \n```↯ AttrDict ↯\nl\n  y\n    c\n      n - d (🏷️ str)\n      greet - hello (🏷️ str)\n      o[]\n        0 - 1 (🏷️ int)\n        1 - 2 (🏷️ int)\n        2 - 3 (🏷️ int)\n        3\n          m\n            n[]\n              0 - 4 (🏷️ int)\n              1 - 5 (🏷️ int)\n              2 - 6 (🏷️ int)\nm - 2 (🏷️ int)\nn - 3 (🏷️ int)\n_tuple()\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3()\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n_set{}\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n_list[]\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3[]\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n\n```\n])\n\n\n\n\n.items\n\nad.items()\n\ndict_items([('x', '1'), ('y', 2.0), ('zed', (3+5j)), ('kay', \n```↯ AttrDict ↯\nl\n  y\n    c\n      n - d (🏷️ str)\n      greet - hello (🏷️ str)\n      o[]\n        0 - 1 (🏷️ int)\n        1 - 2 (🏷️ int)\n        2 - 3 (🏷️ int)\n        3\n          m\n            n[]\n              0 - 4 (🏷️ int)\n              1 - 5 (🏷️ int)\n              2 - 6 (🏷️ int)\nm - 2 (🏷️ int)\nn - 3 (🏷️ int)\n_tuple()\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3()\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n_set{}\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n_list[]\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3[]\n    0 - 4 (🏷️ int)\n    1 - 5 (🏷️ int)\n    2 - 6 (🏷️ int)\n\n```\n)])\n\n\n\n\nUse .d/.dict()/.to_dict() to Create a Vanilla Dict\nAll the three are identical. The latter two are present mostly for backward compatibility.\n\nassert ad.d == ad.dict() == ad.to_dict()\n\n\nd = ad.d\nd\n\n{'x': '1',\n 'y': 2.0,\n 'zed': (3+5j),\n 'kay': {'l': {'y': {'c': {'n': 'd',\n     'greet': 'hello',\n     'o': (#4) [1,2,3,{'m': {'n': [4, 5, 6]}}]}}},\n  'm': 2,\n  'n': 3,\n  '_tuple': (1, 2, 3, (4, 5, 6)),\n  '_set': {1, 2, 3},\n  '_list': (#4) [1,2,3,[4, 5, 6]]}}\n\n\n\n\nAD From Vanilla Dict (Another Basic Invocation)\n\nassert AD(ad.d) == ad\n\n\nad = AD(ad.d)\nad\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n\n```\n\n\n\n\n. Accessing a key\nAs the name of the class suggests, keys can be accessed as if they are attributes\n\nassert ad.x == d[\"x\"]\nassert ad.kay.l.y.c.n == d[\"kay\"][\"l\"][\"y\"][\"c\"][\"n\"]\nassert ad.kay.l.y.c.o[3].m.n == d[\"kay\"][\"l\"][\"y\"][\"c\"][\"o\"][3][\"m\"][\"n\"]\n\n\n\nin Searching for keys\nHighlevel keys are anyway accessable just like, in a normal dictionary\n\nassert \"zed\" in ad\n\nyou can check for presence/absence of nested keys by joining them with a ‘.’\n\nassert \"kay.l.y.c.n\" in ad\n\n\n\n.find_address Find if a key exists and return where it is, i.e., the address of the key\nThe method always returns a list of addresses\n\nad.find_address(\"c\")\n\n['kay.l.y.c']\n\n\n\nad.find_address(\"n\")\n\n['kay.l.y.c.n', 'kay.l.y.c.o.3.m.n', 'kay.n']\n\n\n\nad.find_address(\"hello\")\n\n[]\n\n\n\n\n.fetch fetch all the addresses\n\nad.fetch(ad.find_address(\"n\"))\n\n(#3) ['d',[4, 5, 6],3]\n\n\n\nad.fetch([\"kay.l.y.c.n\", \"kay.l.y.c.o.3.m.n\", \"kay.n\"])\n\n(#3) ['d',[4, 5, 6],3]\n\n\n\n\n.fetch2 fetches all the addresses while preserving the key hierarchy\n\nad.fetch2(addrs=[\"kay.l.y.c.n\", \"kay.l.y.c.o.3.m.n\", \"kay.n\"])\n\n\n```↯ AttrDict ↯\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        o\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  n - 3 (🏷️ int)\n\n```\n\n\n\n\n.fetch2 can also directly fetch all the keys at once (by first finding all addresses and then fetching all of them)\n\nad.fetch2(key=\"n\")\n\n\n```↯ AttrDict ↯\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        o\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  n - 3 (🏷️ int)\n\n```\n\n\n\n\n.slice make a dictionary out of all keys present anywhere in the dictionary\n\nad.slice(\"n\")\n\n\n```↯ AttrDict ↯\nkay.l.y.c.n - d (🏷️ str)\nkay.l.y.c.o.3.m.n[]\n  0 - 4 (🏷️ int)\n  1 - 5 (🏷️ int)\n  2 - 6 (🏷️ int)\nkay.n - 3 (🏷️ int)\n\n```\n\n\n\n\n.get\nGet works as usual but can also work with nested keys\n\nad.get(\"x\", 10)\n\n'1'\n\n\n\nad.get(\"yolo\", 10)\n\n10\n\n\n\nad.get(\"kay.l.y.c\", 20)\n\n\n```↯ AttrDict ↯\nn - d (🏷️ str)\ngreet - hello (🏷️ str)\no[]\n  0 - 1 (🏷️ int)\n  1 - 2 (🏷️ int)\n  2 - 3 (🏷️ int)\n  3\n    m\n      n[]\n        0 - 4 (🏷️ int)\n        1 - 5 (🏷️ int)\n        2 - 6 (🏷️ int)\n\n```\n\n\n\nad.get(\"kay.l.y.hello\", 20)\n\n20\n\n\n\n\n.set\nWill also work similarly as get\n\nad.set(\"bee.sea.dee\", \"e\")\n\n\nad\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\n\n.map Map a function on all leaf nodes\n\nfrom torch_snippets import h4\n\ndef into_two(x):\n    try:\n        return 2 * x\n    except:\n        return x\n\nad2 = ad.map(into_two)\nh4(\"Original\")\nprint(ad)\nh4(\"New\")\nprint(ad2)\n\nOriginal\n\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 4 (🏷️ int)\n                1 - 5 (🏷️ int)\n                2 - 6 (🏷️ int)\n  m - 2 (🏷️ int)\n  n - 3 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\nNew\n\n\n\n```↯ AttrDict ↯\nx - 11 (🏷️ str)\ny - 4.0 (🏷️ float)\nzed - (6+10j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - dd (🏷️ str)\n        greet - hellohello (🏷️ str)\n        o[]\n          0 - 2 (🏷️ int)\n          1 - 4 (🏷️ int)\n          2 - 6 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 8 (🏷️ int)\n                1 - 10 (🏷️ int)\n                2 - 12 (🏷️ int)\n  m - 4 (🏷️ int)\n  n - 6 (🏷️ int)\n  _tuple[]\n    0 - 2 (🏷️ int)\n    1 - 4 (🏷️ int)\n    2 - 6 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n      3 - 4 (🏷️ int)\n      4 - 5 (🏷️ int)\n      5 - 6 (🏷️ int)\n  _set[]\n    0 - 2 (🏷️ int)\n    1 - 4 (🏷️ int)\n    2 - 6 (🏷️ int)\n  _list[]\n    0 - 2 (🏷️ int)\n    1 - 4 (🏷️ int)\n    2 - 6 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - ee (🏷️ str)\n\n```\n\n\n\n\n\n.trymap Map a function on all leaf nodes and preserve the leaf as it is, if the function fails\n\ndef plus_thousand(x):\n    return x + 1000\n\n\nad2 = ad.trymap(plus_thousand)\nprint(ad2)\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 1002.0 (🏷️ float)\nzed - (1003+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        n - d (🏷️ str)\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1001 (🏷️ int)\n          1 - 1002 (🏷️ int)\n          2 - 1003 (🏷️ int)\n          3\n            m\n              n[]\n                0 - 1004 (🏷️ int)\n                1 - 1005 (🏷️ int)\n                2 - 1006 (🏷️ int)\n  m - 1002 (🏷️ int)\n  n - 1003 (🏷️ int)\n  _tuple[]\n    0 - 1001 (🏷️ int)\n    1 - 1002 (🏷️ int)\n    2 - 1003 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set[]\n    0 - 1001 (🏷️ int)\n    1 - 1002 (🏷️ int)\n    2 - 1003 (🏷️ int)\n  _list[]\n    0 - 1001 (🏷️ int)\n    1 - 1002 (🏷️ int)\n    2 - 1003 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n      3 - 1000 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\n\n\n.drop Drop a key, even if it is present somewhere nested\n\nad.find_address(\"n\")\n\n['kay.l.y.c.n', 'kay.l.y.c.o.3.m.n', 'kay.n']\n\n\n\nfrom copy import deepcopy\n\nad2 = deepcopy(ad)\nad2.drop(\"n\")\n\n\nad2\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - 2.0 (🏷️ float)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n  m - 2 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\n\n```\n\n\n\n\n.update\n\nad2.update(\n    {\"y\": \"γ\", \"greek\": {\"alpha\": \"α\", \"beta\": \"β\", \"gamma\": [1, 2, {\"theta\": \"θ\"}]}}\n)\nad2\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - γ (🏷️ str)\nzed - (3+5j) (🏷️ complex)\nkay\n  l\n    y\n      c\n        greet - hello (🏷️ str)\n        o[]\n          0 - 1 (🏷️ int)\n          1 - 2 (🏷️ int)\n          2 - 3 (🏷️ int)\n          3\n            m\n  m - 2 (🏷️ int)\n  _tuple()\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3()\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n    3[]\n      0 - 4 (🏷️ int)\n      1 - 5 (🏷️ int)\n      2 - 6 (🏷️ int)\nbee\n  sea\n    dee - e (🏷️ str)\ngreek\n  alpha - α (🏷️ str)\n  beta - β (🏷️ str)\n  gamma[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2\n      theta - θ (🏷️ str)\n\n```\n\n\n\n\n.flatten will flatten all the nests into a single level\n\nad2.flatten()\n\n\n```↯ AttrDict ↯\nx - 1 (🏷️ str)\ny - γ (🏷️ str)\nzed - (3+5j) (🏷️ complex)\nkay.l.y.c.greet - hello (🏷️ str)\nkay.l.y.c.o.0 - 1 (🏷️ int)\nkay.l.y.c.o.1 - 2 (🏷️ int)\nkay.l.y.c.o.2 - 3 (🏷️ int)\nkay.m - 2 (🏷️ int)\nkay._tuple.0 - 1 (🏷️ int)\nkay._tuple.1 - 2 (🏷️ int)\nkay._tuple.2 - 3 (🏷️ int)\nkay._tuple.3()\n  0 - 4 (🏷️ int)\n  1 - 5 (🏷️ int)\n  2 - 6 (🏷️ int)\nkay._set.0 - 1 (🏷️ int)\nkay._set.1 - 2 (🏷️ int)\nkay._set.2 - 3 (🏷️ int)\nkay._list.0 - 1 (🏷️ int)\nkay._list.1 - 2 (🏷️ int)\nkay._list.2 - 3 (🏷️ int)\nkay._list.3[]\n  0 - 4 (🏷️ int)\n  1 - 5 (🏷️ int)\n  2 - 6 (🏷️ int)\nbee.sea.dee - e (🏷️ str)\ngreek.alpha - α (🏷️ str)\ngreek.beta - β (🏷️ str)\ngreek.gamma.0 - 1 (🏷️ int)\ngreek.gamma.1 - 2 (🏷️ int)\ngreek.gamma.2.theta - θ (🏷️ str)\n\n```\n\n\n\n\n.flatten_and_make_dataframe is self explanatory\n\nad2.flatten_and_make_dataframe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\n0\nx\n1\nNone\nNone\nNone\nNone\nNaN\n\n\n1\ny\nγ\nNone\nNone\nNone\nNone\nNaN\n\n\n2\nzed\n(3+5j)\nNone\nNone\nNone\nNone\nNaN\n\n\n3\nkay\nl\ny\nc\ngreet\nhello\nNaN\n\n\n4\nkay\nl\ny\nc\no\n0\n1.0\n\n\n5\nkay\nl\ny\nc\no\n1\n2.0\n\n\n6\nkay\nl\ny\nc\no\n2\n3.0\n\n\n7\nkay\nm\n2\nNone\nNone\nNone\nNaN\n\n\n8\nkay\n_tuple\n0\n1\nNone\nNone\nNaN\n\n\n9\nkay\n_tuple\n1\n2\nNone\nNone\nNaN\n\n\n10\nkay\n_tuple\n2\n3\nNone\nNone\nNaN\n\n\n11\nkay\n_tuple\n3\n(4, 5, 6)\nNone\nNone\nNaN\n\n\n12\nkay\n_set\n0\n1\nNone\nNone\nNaN\n\n\n13\nkay\n_set\n1\n2\nNone\nNone\nNaN\n\n\n14\nkay\n_set\n2\n3\nNone\nNone\nNaN\n\n\n15\nkay\n_list\n0\n1\nNone\nNone\nNaN\n\n\n16\nkay\n_list\n1\n2\nNone\nNone\nNaN\n\n\n17\nkay\n_list\n2\n3\nNone\nNone\nNaN\n\n\n18\nkay\n_list\n3\n[4, 5, 6]\nNone\nNone\nNaN\n\n\n19\nbee\nsea\ndee\ne\nNone\nNone\nNaN\n\n\n20\ngreek\nalpha\nα\nNone\nNone\nNone\nNaN\n\n\n21\ngreek\nbeta\nβ\nNone\nNone\nNone\nNaN\n\n\n22\ngreek\ngamma\n0\n1\nNone\nNone\nNaN\n\n\n23\ngreek\ngamma\n1\n2\nNone\nNone\nNaN\n\n\n24\ngreek\ngamma\n2\ntheta\nθ\nNone\nNaN\n\n\n\n\n\n\n\n\n\n.diff on other ADs/dicts\n\na = AD(w=0, x=1, y=3, _list=[1,2,3], _set={1,2,3}, _tuple=(1,2,3), z=10, a=AD(a=1))\nb = AD(w=0, x=2, z=2, _list=[1,3,4,5], _set={1,3,4}, _tuple=(1,3,4,5), k=20, b=AD(b=1))\na.diff(b)\n\n\n```↯ AttrDict ↯\ndictionary_item_added - SetOrdered([\"root['k']\", \"root['b']\"]) (🏷️ SetOrdered)\ndictionary_item_removed - SetOrdered([\"root['y']\", \"root['a']\"]) (🏷️ SetOrdered)\nvalues_changed\n  root['x']\n    new_value - 2 (🏷️ int)\n    old_value - 1 (🏷️ int)\n  root['z']\n    new_value - 2 (🏷️ int)\n    old_value - 10 (🏷️ int)\n  root['_list'][1]\n    new_value - 3 (🏷️ int)\n    old_value - 2 (🏷️ int)\n  root['_list'][2]\n    new_value - 4 (🏷️ int)\n    old_value - 3 (🏷️ int)\n  root['_tuple'][1]\n    new_value - 3 (🏷️ int)\n    old_value - 2 (🏷️ int)\n  root['_tuple'][2]\n    new_value - 4 (🏷️ int)\n    old_value - 3 (🏷️ int)\niterable_item_added\n  root['_list'][3] - 5 (🏷️ int)\n  root['_tuple'][3] - 5 (🏷️ int)\nset_item_removed - SetOrdered([\"root['_set'][2]\"]) (🏷️ SetOrdered)\nset_item_added - SetOrdered([\"root['_set'][4]\"]) (🏷️ SetOrdered)\n\n```"
  },
  {
    "objectID": "nbs/attrdict.html#display-exotic-objects",
    "href": "nbs/attrdict.html#display-exotic-objects",
    "title": "AttrDict / AD",
    "section": "Display exotic objects",
    "text": "Display exotic objects\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass DC:\n    w: int\n    x: int\n    y: int\n    _list: list\n    _set: set\n\ndc = DC(1,2,3,[1,2,3],{1,2,3})\nprint(dc)\n\nDC(w=1, x=2, y=3, _list=[1, 2, 3], _set={1, 2, 3})\n\n\nnot bad, but we can always do this\n\nprint(AD(dc))\n\n\n```↯ AttrDict ↯\ndc(🏷️ DC:dataclass)\n  w - 1 (🏷️ int)\n  x - 2 (🏷️ int)\n  y - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n\n```\n\n\n\n\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({'x': np.random.randint(0, 100, size=10), 'y': np.random.uniform(0, 1, size=10)})\nprint(df)\n\n    x         y\n0  76  0.492719\n1  89  0.091474\n2   9  0.428809\n3  46  0.359179\n4  43  0.839773\n5  58  0.344325\n6  66  0.563592\n7  33  0.512554\n8  81  0.813390\n9  44  0.932230\n\n\n\nprint(AD(df))\n\n\n```↯ AttrDict ↯\ndf - DataFrame - shape (10, 2) - columns Index(['x', 'y'], dtype='object') - ID:#06c311\n\n```\n\n\n\nCan show torch and numpy tensors in a really pretty way thanks to lovely-tensors module\n\nfrom torch_snippets import *\ninit_torch()\n\nt1 = torch.Tensor([1,2,3]).long()\nt2 = torch.Tensor([1,2,3])\nn1 = np.array([4,5,6])\nn1 = np.array([4,5,6]).astype(float)\nn2 = np.array([4,5,6]).astype(np.float32)\nts = AD(t=AD(t1, t2), n=AD(n1, n2))\nts\n\n\n```↯ AttrDict ↯\nt\n  t1 - 🔦tensor[3] i64 x∈[1, 3] μ=2.000 σ=1.000 [1, 2, 3] - ID:#e2e2033a\n  t2 - 🔦tensor[3] x∈[1.000, 3.000] μ=2.000 σ=1.000 [1.000, 2.000, 3.000] - ID:#8e628779\nn\n  n1 - np.tensor[3] f64 x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#88d24967\n  n2 - np.tensor[3] x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#3928b709\n\n```\n\n\n\nfrom torch_snippets import P\np = AD(p=P().resolve())\np\n\n\n```↯ AttrDict ↯\np - /Users/yeshwanth/Code/Personal/torch_snippets/nbs (🏷️ PosixPath)\n\n```\n\n\n\nsmall_string = '123'\nbig_string = '123'*100\nmultiline_big_string = '\\n'.join([big_string]*100)\nstrs = AD(small_string, big_string, multiline_big_string)\nstrs\n\n\n```↯ AttrDict ↯\nsmall_string - 123 (🏷️ str)\nbig_string - 12312312312312312312312312312312312.........23123123123123123123123123123123123 (🏷️ str)\nmultiline_big_string - ↓\n  ```\n  12312312312312312312312312312312312 ...\n  ...\n  ...\n  ...\n  ... 23123123123123123123123123123123123\n  ``` (🏷️ Multiline str)\n\n```\n\n\nAnd cmbining all of them we have\n\nAD(dc, df, ts, p, strs)\n\n\n```↯ AttrDict ↯\ndc(🏷️ DC:dataclass)\n  w - 1 (🏷️ int)\n  x - 2 (🏷️ int)\n  y - 3 (🏷️ int)\n  _list[]\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\n  _set{}\n    0 - 1 (🏷️ int)\n    1 - 2 (🏷️ int)\n    2 - 3 (🏷️ int)\ndf - DataFrame - shape (10, 2) - columns Index(['x', 'y'], dtype='object') - ID:#06c311\nts\n  t\n    t1 - 🔦tensor[3] i64 x∈[1, 3] μ=2.000 σ=1.000 [1, 2, 3] - ID:#e2e2033a\n    t2 - 🔦tensor[3] x∈[1.000, 3.000] μ=2.000 σ=1.000 [1.000, 2.000, 3.000] - ID:#8e628779\n  n\n    n1 - np.tensor[3] f64 x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#88d24967\n    n2 - np.tensor[3] x∈[4.000, 6.000] μ=5.000 σ=1.000 [4.000, 5.000, 6.000] - ID:#3928b709\np\n  p - /Users/yeshwanth/Code/Personal/torch_snippets/nbs (🏷️ PosixPath)\nstrs\n  small_string - 123 (🏷️ str)\n  big_string - 12312312312312312312312312312312312.........23123123123123123123123123123123123 (🏷️ str)\n  multiline_big_string - ↓\n    ```\n    12312312312312312312312312312312312 ...\n    ...\n    ...\n    ...\n    ... 23123123123123123123123123123123123\n    ``` (🏷️ Multiline str)\n\n```"
  },
  {
    "objectID": "nbs/show.html#section",
    "href": "nbs/show.html#section",
    "title": "torch_snippets",
    "section": "",
    "text": "Show is intended to show numpy-arrays/PIL-images\n\nfrom torch_snippets import *\n\nim = np.random.rand(100, 100)\nshow(im)\n\n\n\n\n\n\n\n\n\nshow(im, sz=4)\n\n\n\n\n\n\n\n\nShow will even accept pytorch Tensors and show them as images, even if they are on GPU and have channels first\nIt can accept bounding boxes as tuples of (x,y,X,Y) which can be integers (i.e., absolute coordinates) or fractions (between \\([0,1]\\)). There’s provision to give bb_colors and texts as well\n\nshow(im, bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)])\n\nshow(im, bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)], bb_colors=[\"r\", \"g\"])\n\nshow(\n    im,\n    bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)],\n    bb_colors=[\"b\", \"g\"],\n    texts=[\"bb1\", \"bb2\"],\n    sz=10,\n    text_sz=15,\n)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nIt can also read a file path directly and display the image\n\nshow(\"../docs/images/company_logo_big.png\", sz=3)\n\n\n\n\n\n\n\n\nif the input is not an image or string, show will simply display the given input as intended by jupyter notebook\n\ndf = pd.DataFrame(np.random.rand(100, 2))\nshow(df)\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n0.242478\n0.929517\n\n\n1\n0.971890\n0.506750\n\n\n2\n0.139826\n0.753227\n\n\n3\n0.864799\n0.524166\n\n\n4\n0.563610\n0.135709\n\n\n...\n...\n...\n\n\n95\n0.379874\n0.639771\n\n\n96\n0.993731\n0.811343\n\n\n97\n0.621683\n0.763054\n\n\n98\n0.844509\n0.915156\n\n\n99\n0.314272\n0.392418\n\n\n\n\n100 rows × 2 columns\n\n\n\n\nchart = Chart(df).mark_circle().encode(x=\"0:Q\", y=\"1:Q\")\nshow(chart.interactive())"
  },
  {
    "objectID": "nbs/show.html#subplots",
    "href": "nbs/show.html#subplots",
    "title": "torch_snippets",
    "section": "Subplots",
    "text": "Subplots\ndisplay multiple images Subplots is a wapper around plt.subplots that accepts a list of images, number of columns as nc and additional kwargs\n\nfrom torch_snippets import subplots\n\nims = [np.random.rand(100, 100) for _ in range(16)]\n\nsubplots(ims, nc=4, sz=5)\n\n\n\n\n\n\n\n\n\nsubplots(\n    ims,\n    nc=2,\n    sz=(5, 15),\n    suptitle=\"RANDOM IMAGES\",\n    titles=[f\"random_{i}\" for i in range(16)],\n)"
  },
  {
    "objectID": "nbs/registry.html",
    "href": "nbs/registry.html",
    "title": "Registry",
    "section": "",
    "text": "Suppose you have a file called config.ini like so…\n\n!cat /tmp/config.ini\n\n\n[META]\nversion = 0.0.1\nname = mnist\nroot = /home/me/projects/${META.name}\ndescription = This is a sample\n    config file with a multiline\n    description. These are useful for\n    project descriptions/changelog/devnotes etc...\n\n[Data]\nsource = https://files.fast.ai/data/examples/mnist_tiny.tgz\nroot = ${META.root}/data/\n\n[misc]\nx = 1\ny = 20\nz = float(${x}*${y}**2)\na = ['hello','hi','how','are','you', ${x}*${z}*${y}]\nb = {\"hi\": 1, \"hello\": 2}\n\n[load]\n    [load.test]\n    @load = print_root_location\n    root = ${Data.root}\n    \n    [load.csv]\n    @load = load_csv_function\n    root = ${Data.root}\n    \n    [load.json]\n    @load = load_json_class\n    root = ${Data.root}\n    \n    \n\n\n\nYou can load it up as an AttrDict\n\nconfig = parse(\"/tmp/config.ini\")\nassert config.META.version == \"0.0.1\"\nassert config.META.root == \"/home/me/projects/mnist\"\nassert isinstance(config.misc.b, AttrDict), type(config.project.data.b)\nassert isinstance(config.misc.a, L)\n\nNotice, how the ${} variables got resolved.\nNot just that, the varaible z got computed on the fly.\nNot just that, some of the variables like list and dict got resolved into their respective python data structures.\n\nconfig.pretty()\n\n{\n    \"Data\": {\n        \"root\": \"/home/me/projects/mnist/data/\",\n        \"source\": \"https://files.fast.ai/data/examples/mnist_tiny.tgz\"\n    },\n    \"META\": {\n        \"description\": \"This is a sample\\nconfig file with a multiline\\ndescription. These are useful for\\nproject \ndescriptions/changelog/devnotes etc...\",\n        \"name\": \"mnist\",\n        \"root\": \"/home/me/projects/mnist\",\n        \"version\": \"0.0.1\"\n    },\n    \"load\": {\n        \"csv\": {\n            \"@load\": null,\n            \"root\": \"/home/me/projects/mnist/data/\"\n        },\n        \"json\": {\n            \"@load\": \"load_json_class\",\n            \"root\": \"/home/me/projects/mnist/data/\"\n        },\n        \"test\": {\n            \"@load\": \"print_root_location\",\n            \"root\": \"/home/me/projects/mnist/data/\"\n        }\n    },\n    \"misc\": {\n        \"a\": [\n            \"hello\",\n            \"hi\",\n            \"how\",\n            \"are\",\n            \"you\",\n            8000.0\n        ],\n        \"b\": {\n            \"hello\": 2,\n            \"hi\": 1\n        },\n        \"x\": 1,\n        \"y\": 20,\n        \"z\": 400.0\n    }\n}\n\n\n\n\nprint(config.META.description)\n\nThis is a sample\nconfig file with a multiline\ndescription. These are useful for\nproject descriptions/changelog/devnotes etc...\n\n\nYou can also register/call python functions/callables/classes/objects to strings by running\n\nregistry.create(\"load\")\n\n\n@registry.load.register(\"print_root_location\")\ndef printer(root):\n    return root\n\n\n@registry.load.register(\"load_csv_function\")\ndef _load_csv_function(root):\n    def load_csv_function(file):\n        return f\"Loading file from {root}/{file}\"\n\n    return load_csv_function\n\n\n@registry.load.register(\"load_json_class\")\nclass JsonLoader:\n    def __init__(self, root):\n        self.root = root\n\n    def __call__(self, file):\n        assert file.endswith(\"json\")\n        return f\"Loading file from {self.root}/{file}\"\n\n… and resolve them on parse\n\nconfig = parse_and_resolve(\"/tmp/config.ini\")\n\n\nconfig.load.test\n\n'/home/me/projects/mnist/data/'\n\n\n\nconfig.load.csv(file=\"file.csv\")\n\n'Loading file from /home/me/projects/mnist/data//file.csv'\n\n\n\nconfig.load.json(file=\"file.json\")\n\n'Loading file from /home/me/projects/mnist/data//file.json'"
  },
  {
    "objectID": "profiler.html",
    "href": "profiler.html",
    "title": "Profiler",
    "section": "",
    "text": "The time profiler decorator measures the execution time of a function, including any sub-functions that the main function calls. It allows users to specify a file name or complete file path to store the profiling results. The output includes the total time taken by the function, which can be useful for understanding performance bottlenecks in the code. By applying this decorator to any function, developers can easily track its runtime and optimize accordingly.\n\ndef inner_function_1():\n    # Simulating some work by counting\n    total = 0\n    for i in range(500000):\n        total += i\n    return total\n\n\ndef inner_function_2():\n    # Simulating some different work, like squaring numbers\n    total = 0\n    for i in range(10000000):\n        total += i * i\n    return total\n\n\n@time_profiler(\"outer_function_profile.txt\")\ndef outer_function():\n    result_1 = inner_function_1()\n    print(f\"Result from inner_function_1: {result_1}\")\n\n    result_2 = inner_function_2()\n    print(f\"Result from inner_function_2: {result_2}\")\n\n\n# Call the outer function\nouter_function()\n\nResult from inner_function_1: 124999750000\nResult from inner_function_2: 333333283333335000000\n\n\n\n\n         67 function calls in 1.362 seconds\n\n   Ordered by: cumulative time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000    1.362    1.362 /tmp/ipykernel_156766/1515566242.py:15(outer_function)\n        1    1.303    1.303    1.303    1.303 /tmp/ipykernel_156766/1515566242.py:8(inner_function_2)\n        1    0.058    0.058    0.058    0.058 /tmp/ipykernel_156766/1515566242.py:1(inner_function_1)\n        2    0.000    0.000    0.001    0.000 {built-in method builtins.print}\n        4    0.000    0.000    0.001    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:655(write)\n        4    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:577(_schedule_flush)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:259(schedule)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/zmq/sugar/socket.py:621(send)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/threading.py:1185(is_alive)\n        4    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:505(parent_header)\n        4    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:550(_is_master_process)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/threading.py:1118(_wait_for_tstate_lock)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:138(_event_pipe)\n        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n        4    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n        4    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/threading.py:568(is_set)\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n        4    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n        1    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/dateutil/tz/tz.py:74(utcoffset)\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        2    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}",
    "crumbs": [
      "Profiler"
    ]
  },
  {
    "objectID": "profiler.html#time-profiler",
    "href": "profiler.html#time-profiler",
    "title": "Profiler",
    "section": "",
    "text": "The time profiler decorator measures the execution time of a function, including any sub-functions that the main function calls. It allows users to specify a file name or complete file path to store the profiling results. The output includes the total time taken by the function, which can be useful for understanding performance bottlenecks in the code. By applying this decorator to any function, developers can easily track its runtime and optimize accordingly.\n\ndef inner_function_1():\n    # Simulating some work by counting\n    total = 0\n    for i in range(500000):\n        total += i\n    return total\n\n\ndef inner_function_2():\n    # Simulating some different work, like squaring numbers\n    total = 0\n    for i in range(10000000):\n        total += i * i\n    return total\n\n\n@time_profiler(\"outer_function_profile.txt\")\ndef outer_function():\n    result_1 = inner_function_1()\n    print(f\"Result from inner_function_1: {result_1}\")\n\n    result_2 = inner_function_2()\n    print(f\"Result from inner_function_2: {result_2}\")\n\n\n# Call the outer function\nouter_function()\n\nResult from inner_function_1: 124999750000\nResult from inner_function_2: 333333283333335000000\n\n\n\n\n         67 function calls in 1.362 seconds\n\n   Ordered by: cumulative time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n        1    0.000    0.000    1.362    1.362 /tmp/ipykernel_156766/1515566242.py:15(outer_function)\n        1    1.303    1.303    1.303    1.303 /tmp/ipykernel_156766/1515566242.py:8(inner_function_2)\n        1    0.058    0.058    0.058    0.058 /tmp/ipykernel_156766/1515566242.py:1(inner_function_1)\n        2    0.000    0.000    0.001    0.000 {built-in method builtins.print}\n        4    0.000    0.000    0.001    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:655(write)\n        4    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:577(_schedule_flush)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:259(schedule)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/zmq/sugar/socket.py:621(send)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/threading.py:1185(is_alive)\n        4    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:505(parent_header)\n        4    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:550(_is_master_process)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/threading.py:1118(_wait_for_tstate_lock)\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/ipykernel/iostream.py:138(_event_pipe)\n        2    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n        4    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n        4    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n        2    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/threading.py:568(is_set)\n        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n        4    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n        1    0.000    0.000    0.000    0.000 /home/user/miniconda3/lib/python3.11/site-packages/dateutil/tz/tz.py:74(utcoffset)\n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n        2    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}",
    "crumbs": [
      "Profiler"
    ]
  },
  {
    "objectID": "sklegos.html",
    "href": "sklegos.html",
    "title": "SK-Legos",
    "section": "",
    "text": "{}\n\n\nYou can find 1. train_test_split which also resets the dataframes’ indexes 2. MakeFrame 3. ImputeMisingValues 4. Cat2Num 5. Other scikit-lego blocks that I use a lot\n\n\n\n\n MakeFrame (column_names)\n\nConvert sklearn’s output to a pandas dataframe Especially useful when working with an ensemble of models\nUsage\nCall MakeFrame as the last component in your pipeline with the desired column names.\npipeline = Pipeline([\n    ...,\n    ('output', MakeFrame(['outlier', 'class'])),\n])\n\nRefer to this notebook for an example\n\n\n\n\n\n\n ImputeMissingValues (num_mode=&lt;function mean at 0x106a801b0&gt;,\n                      cat_mode='MISSING')\n\n*DataFrame input - DataFrame output During fit - 1. Store imputable value for each column During transform - 2. Impute missing values with imputable value 3. Create a ’{col}_na’ boolean column to tell if cells contained missing value*\n\n\n\n\n\n LambdaTransformer (fn)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\n\n\n MakeFrame (column_names)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\n\n\n Cat2Num ()\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\n\n\n SplitDateColumn (column_names, has_date, has_time, date_format=None)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*",
    "crumbs": [
      "SK-Legos"
    ]
  },
  {
    "objectID": "sklegos.html#utilities-to-do-common-ml-tasks",
    "href": "sklegos.html#utilities-to-do-common-ml-tasks",
    "title": "SK-Legos",
    "section": "",
    "text": "{}\n\n\nYou can find 1. train_test_split which also resets the dataframes’ indexes 2. MakeFrame 3. ImputeMisingValues 4. Cat2Num 5. Other scikit-lego blocks that I use a lot\n\n\n\n\n MakeFrame (column_names)\n\nConvert sklearn’s output to a pandas dataframe Especially useful when working with an ensemble of models\nUsage\nCall MakeFrame as the last component in your pipeline with the desired column names.\npipeline = Pipeline([\n    ...,\n    ('output', MakeFrame(['outlier', 'class'])),\n])\n\nRefer to this notebook for an example\n\n\n\n\n\n\n ImputeMissingValues (num_mode=&lt;function mean at 0x106a801b0&gt;,\n                      cat_mode='MISSING')\n\n*DataFrame input - DataFrame output During fit - 1. Store imputable value for each column During transform - 2. Impute missing values with imputable value 3. Create a ’{col}_na’ boolean column to tell if cells contained missing value*\n\n\n\n\n\n LambdaTransformer (fn)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\n\n\n MakeFrame (column_names)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\n\n\n Cat2Num ()\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*\n\n\n\n\n\n SplitDateColumn (column_names, has_date, has_time, date_format=None)\n\n*Base class for all estimators in scikit-learn.\nInheriting from this class provides default implementations of:\n\nsetting and getting parameters used by GridSearchCV and friends;\ntextual and HTML representation displayed in terminals and IDEs;\nestimator serialization;\nparameters validation;\ndata validation;\nfeature names validation.\n\nRead more in the :ref:User Guide &lt;rolling_your_own_estimator&gt;.*",
    "crumbs": [
      "SK-Legos"
    ]
  },
  {
    "objectID": "show.html#section",
    "href": "show.html#section",
    "title": "torch_snippets",
    "section": "",
    "text": "Show is intended to show numpy-arrays/PIL-images\n\nfrom torch_snippets import *\n\nim = np.random.rand(100, 100)\nshow(im)\n\n\n\n\n\n\n\n\n\nshow(im, sz=4)\n\n\n\n\n\n\n\n\nShow will even accept pytorch Tensors and show them as images, even if they are on GPU and have channels first\nIt can accept bounding boxes as tuples of (x,y,X,Y) which can be integers (i.e., absolute coordinates) or fractions (between \\([0,1]\\)). There’s provision to give bb_colors and texts as well\n\nshow(im, bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)])\n\nshow(im, bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)], bb_colors=[\"r\", \"g\"])\n\nshow(\n    im,\n    bbs=[(0, 0, 0.5, 0.35), (0, 0.2, 0.35, 0.95)],\n    bb_colors=[\"b\", \"g\"],\n    texts=[\"bb1\", \"bb2\"],\n    sz=10,\n    text_sz=15,\n)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\nIt can also read a file path directly and display the image\n\nshow(\"../docs/images/company_logo_big.png\", sz=3)\n\n\n\n\n\n\n\n\nif the input is not an image or string, show will simply display the given input as intended by jupyter notebook\n\ndf = pd.DataFrame(np.random.rand(100, 2))\nshow(df)\n\n\n\n\n\n\n\n\n0\n1\n\n\n\n\n0\n0.242478\n0.929517\n\n\n1\n0.971890\n0.506750\n\n\n2\n0.139826\n0.753227\n\n\n3\n0.864799\n0.524166\n\n\n4\n0.563610\n0.135709\n\n\n...\n...\n...\n\n\n95\n0.379874\n0.639771\n\n\n96\n0.993731\n0.811343\n\n\n97\n0.621683\n0.763054\n\n\n98\n0.844509\n0.915156\n\n\n99\n0.314272\n0.392418\n\n\n\n\n100 rows × 2 columns\n\n\n\n\nchart = Chart(df).mark_circle().encode(x=\"0:Q\", y=\"1:Q\")\nshow(chart.interactive())",
    "crumbs": [
      "Show"
    ]
  },
  {
    "objectID": "show.html#subplots",
    "href": "show.html#subplots",
    "title": "torch_snippets",
    "section": "Subplots",
    "text": "Subplots\ndisplay multiple images Subplots is a wapper around plt.subplots that accepts a list of images, number of columns as nc and additional kwargs\n\nfrom torch_snippets import subplots\n\nims = [np.random.rand(100, 100) for _ in range(16)]\n\nsubplots(ims, nc=4, sz=5)\n\n\n\n\n\n\n\n\n\nsubplots(\n    ims,\n    nc=2,\n    sz=(5, 15),\n    suptitle=\"RANDOM IMAGES\",\n    titles=[f\"random_{i}\" for i in range(16)],\n)",
    "crumbs": [
      "Show"
    ]
  },
  {
    "objectID": "charts.html",
    "href": "charts.html",
    "title": "Altair and Other Charts",
    "section": "",
    "text": "Altair and Other Charts\n\n\nfrom torch_snippets.loader import *\nfrom sklearn.datasets import make_moons\n\nnp.random.seed(10)\nx, y = make_moons(1000, noise=0.1)\ndf = pd.DataFrame({\"x1\": x[:, 0], \"x2\": x[:, 1], \"y\": y})\n\nChart(df).mark_circle().encode(x=\"x1:Q\", y=\"x2:Q\", color=\"y:N\").interactive()\n\n\n\n\n\n\n\nRefer to altair-viz.github.io for more awesome charts.\ntorch-snippets exposes a confusion matrix function CM as an example\n\nMethod 1\n\nn = 10\na = \"qwertyuiopasdfghjklzxcvbnm\"\ntruth = np.random.randint(4, size=1000000)\npred = np.random.randint(4, size=1000000)\nshow(CM(truth=truth, pred=pred, mapping={i: a for i, a in enumerate(a)}))\n# mapping is optional\n\n              precision    recall  f1-score   support\n\n           0       0.25      0.25      0.25    250150\n           1       0.25      0.25      0.25    250245\n           2       0.25      0.25      0.25    249836\n           3       0.25      0.25      0.25    249769\n\n    accuracy                           0.25   1000000\n   macro avg       0.25      0.25      0.25   1000000\nweighted avg       0.25      0.25      0.25   1000000\n\n\n\n\n\n\n\n\n\n\n\nMethod 2\n\ndf = pd.DataFrame(\n    {\n        \"truth\": [randint(n) for _ in range(1000)],\n        \"pred\": [randint(n) for _ in range(1000)],\n    }\n)\nshow(CM(df, \"truth\", \"pred\", mapping={i: a for i, a in enumerate(a)}))\n# mapping is optional\n\n              precision    recall  f1-score   support\n\n           0       0.13      0.14      0.13        92\n           1       0.08      0.09      0.08       101\n           2       0.13      0.12      0.13       107\n           3       0.06      0.06      0.06       105\n           4       0.12      0.11      0.11        94\n           5       0.12      0.09      0.10       115\n           6       0.08      0.10      0.09        88\n           7       0.08      0.07      0.08       113\n           8       0.09      0.09      0.09        99\n           9       0.12      0.15      0.13        86\n\n    accuracy                           0.10      1000\n   macro avg       0.10      0.10      0.10      1000\nweighted avg       0.10      0.10      0.10      1000\n\n\n\n\n\n\n\n\n\n\n\nMethod 3\n\ndf = pd.DataFrame(\n    {\n        \"truth\": [choose(\"abcd\") for _ in range(1000)],\n        \"pred\": [choose(\"abcd\") for _ in range(1000)],\n    }\n)\nshow(CM(df, \"truth\", \"pred\"))\n# mapping is optional\n\n              precision    recall  f1-score   support\n\n           a       0.25      0.29      0.27       229\n           b       0.28      0.29      0.28       256\n           c       0.27      0.24      0.26       267\n           d       0.26      0.25      0.25       248\n\n    accuracy                           0.27      1000\n   macro avg       0.26      0.27      0.26      1000\nweighted avg       0.27      0.27      0.26      1000\n\n\n\n\n\n\n\n\n\n\n\n\nspider\n\n spider (df, id_column=None, title=None, max_values=None, padding=1.25,\n         global_scale=False, ax=None, sz=10)\n\n*Plot a spider chart based on the given dataframe.\nParameters: - df: pandas DataFrame The input dataframe containing the data to be plotted. - id_column: str, optional The column name to be used as the identifier for each data point. If not provided, the index of the dataframe will be used. - title: str, optional The title of the spider chart. - max_values: dict, optional A dictionary specifying the maximum values for each category. If not provided, the maximum values will be calculated based on the data. - padding: float, optional The padding factor to be applied when calculating the maximum values. Default is 1.25. - global_scale: bool or float, optional If False, each category will have its own maximum value. If True, a single maximum value will be used for all categories. If a float value is provided, it will be used as the maximum value for all categories. - ax: matplotlib Axes, optional The axes on which to plot the spider chart. If not provided, a new figure and axes will be created. - sz: float, optional The size of the figure (both width and height) in inches. Default is 10.\nReturns: - None\nExample usage: spider(df, id_column=‘model’, title=‘Spider Chart’, max_values={‘category1’: 10, ‘category2’: 20}, padding=1.5)*\n\nimport pandas as pd\n\nspider(\n    pd.DataFrame(\n        {\n            \"x\": [*\"abcde\"],\n            \"c1\": [10, 11, 12, 13, 14],\n            \"c2\": [0.1, 0.3, 0.4, 0.1, 0.9],\n            \"c3\": [1e5, 2e5, 3.5e5, 8e4, 5e4],\n            \"c4\": [9, 12, 5, 2, 0.2],\n            \"test\": [1, 1, 1, 1, 5],\n        },\n        index=[*\"abcde\"],\n    ),\n    title=\"Sample Spider\",\n    padding=1.1,\n)\n\n\n\n\n\n\n\n\n\n\n\nUpSetAltair\n\n UpSetAltair (data=None, title='', subtitle='', sets=None, abbre=None,\n              sort_by='frequency', sort_order='ascending', width=1200,\n              height=700, height_ratio=0.6,\n              horizontal_bar_chart_width=300, color_range=['#55A8DB',\n              '#3070B5', '#30363F', '#F1AD60', '#DF6234', '#BDC6CA'],\n              highlight_color='#EA4667', glyph_size=200,\n              set_label_bg_size=1000, line_connection_size=2,\n              horizontal_bar_size=20, vertical_bar_label_size=16,\n              vertical_bar_padding=20)\n\n*This function generates Altair-based interactive UpSet plots.\nParameters: - data (pandas.DataFrame): Tabular data containing the membership of each element (row) in exclusive intersecting sets (column). - sets (list): List of set names of interest to show in the UpSet plots. This list reflects the order of sets to be shown in the plots as well. - abbre (list): Abbreviated set names. - sort_by (str): “frequency” or “degree” - sort_order (str): “ascending” or “descending” - width (int): Vertical size of the UpSet plot. - height (int): Horizontal size of the UpSet plot. - height_ratio (float): Ratio of height between upper and under views, ranges from 0 to 1. - horizontal_bar_chart_width (int): Width of horizontal bar chart on the bottom-right. - color_range (list): Color to encode sets. - highlight_color (str): Color to encode intersecting sets upon mouse hover. - glyph_size (int): Size of UpSet glyph (⬤). - set_label_bg_size (int): Size of label background in the horizontal bar chart. - line_connection_size (int): width of lines in matrix view. - horizontal_bar_size (int): Height of bars in the horizontal bar chart. - vertical_bar_label_size (int): Font size of texts in the vertical bar chart on the top. - vertical_bar_padding (int): Gap between a pair of bars in the vertical bar charts.*\n\n\n\nupsetaltair_top_level_configuration\n\n upsetaltair_top_level_configuration (base, legend_orient='top-left',\n                                      legend_symbol_size=30)\n\n*Configure the top-level settings for an UpSet plot in Altair.\nParameters: - base: The base chart to configure. - legend_orient: The orientation of the legend. Default is “top-left”. - legend_symbol_size: The size of the legend symbols. Default is 30.\nReturns: - The configured chart.*\n\ndf\n\n\n\n\n\n\n\n\ntruth\npred\n\n\n\n\n0\nc\nd\n\n\n1\nc\nc\n\n\n2\nd\nd\n\n\n3\nc\na\n\n\n4\nd\nc\n\n\n...\n...\n...\n\n\n995\nc\nc\n\n\n996\na\nc\n\n\n997\nb\na\n\n\n998\nb\nc\n\n\n999\na\nd\n\n\n\n\n1000 rows × 2 columns\n\n\n\n\n# import numpy as np\n\n# i = np.random.randn(300, 7) &gt; 0.33\n# df = pd.DataFrame(i.astype(int))\n# df.columns = [rand() for _ in range(len(df.columns))]\n# show(df)\n\n# UpSetAltair(\n#     df,\n#     sets=list(df.columns),\n#     abbre=list(df.columns),\n#     sort_by=\"frequencey\",\n#     sort_order=\"ascending\",\n# )\n\ndf\n\n\n\n\n4wST3l\nv6Vv72\nWKSGX4\nLBlidv\ng0LDKa\nxpK2f5\npW4oKO\n\n\n\n\n0\n0\n1\n0\n1\n0\n0\n1\n\n\n1\n1\n0\n0\n1\n0\n1\n0\n\n\n2\n1\n0\n1\n0\n0\n1\n0\n\n\n3\n1\n0\n0\n0\n0\n0\n1\n\n\n4\n0\n0\n1\n0\n1\n0\n1\n\n\n5\n0\n0\n0\n1\n0\n0\n0\n\n\n6\n1\n0\n0\n1\n1\n0\n1\n\n\n7\n1\n1\n1\n1\n0\n1\n1\n\n\n8\n1\n0\n0\n1\n0\n1\n1\n\n\n9\n1\n0\n0\n1\n0\n0\n0\n\n\n10\n1\n0\n0\n0\n0\n0\n1\n\n\n11\n1\n0\n1\n1\n0\n0\n0\n\n\n12\n0\n1\n0\n1\n0\n0\n1\n\n\n13\n1\n0\n0\n1\n0\n1\n1\n\n\n14\n1\n1\n0\n1\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n285\n1\n0\n0\n0\n0\n0\n0\n\n\n286\n1\n0\n0\n1\n1\n1\n1\n\n\n287\n0\n0\n1\n1\n0\n1\n0\n\n\n288\n0\n1\n1\n1\n0\n0\n0\n\n\n289\n0\n1\n1\n1\n0\n0\n0\n\n\n290\n0\n1\n1\n1\n1\n0\n0\n\n\n291\n0\n0\n1\n0\n1\n0\n0\n\n\n292\n0\n0\n1\n1\n0\n0\n1\n\n\n293\n1\n0\n0\n0\n0\n1\n0\n\n\n294\n0\n0\n0\n0\n0\n0\n1\n\n\n295\n0\n1\n1\n1\n0\n0\n0\n\n\n296\n0\n0\n0\n1\n0\n1\n0\n\n\n297\n1\n0\n1\n0\n0\n0\n1\n\n\n298\n0\n1\n1\n0\n1\n0\n0\n\n\n299\n0\n0\n1\n0\n0\n0\n0\n\n\n\n\n\n\n/opt/miniconda3/lib/python3.12/site-packages/altair/utils/deprecation.py:65: AltairDeprecationWarning: 'selection_multi' is deprecated.  Use 'selection_point'\n  warnings.warn(message, AltairDeprecationWarning, stacklevel=1)\n/opt/miniconda3/lib/python3.12/site-packages/altair/utils/deprecation.py:65: AltairDeprecationWarning: 'selection_single' is deprecated.  Use 'selection_point'\n  warnings.warn(message, AltairDeprecationWarning, stacklevel=1)\n\n\n\n---------------------------------------------------------------------------\nSchemaValidationError                     Traceback (most recent call last)\nCell In[14], line 8\n      5 df.columns = [rand() for _ in range(len(df.columns))]\n      6 show(df)\n----&gt; 8 UpSetAltair(\n      9     df,\n     10     sets=list(df.columns),\n     11     abbre=list(df.columns),\n     12     sort_by=\"frequencey\",\n     13     sort_order=\"ascending\",\n     14 )\n\nCell In[10], line 239, in UpSetAltair(data, title, subtitle, sets, abbre, sort_by, sort_order, width, height, height_ratio, horizontal_bar_chart_width, color_range, highlight_color, glyph_size, set_label_bg_size, line_connection_size, horizontal_bar_size, vertical_bar_label_size, vertical_bar_padding)\n    177 base = (\n    178     alt.Chart(data)\n    179     .transform_filter(legend_selection)\n   (...)\n    232     )\n    233 )\n    234 # Now, we have data in the following format:\n    235 # count, set, is_intersect, degree, intersection_id, set_abbre\n    236 \n    237 # Cardinality by intersecting sets (vertical bar chart)\n    238 vertical_bar = (\n--&gt; 239     base.mark_bar(color=main_color, size=vertical_bar_size)\n    240     .encode(\n    241         x=alt.X(\n    242             \"intersection_id:N\",\n    243             axis=alt.Axis(grid=False, labels=False, ticks=False, domain=True),\n    244             sort=x_sort,\n    245             title=None,\n    246         ),\n    247         y=alt.Y(\n    248             \"max(count):Q\",\n    249             axis=alt.Axis(grid=False, tickCount=3, orient=\"right\"),\n    250             title=\"Intersection Size\",\n    251         ),\n    252         color=brush_color,\n    253         tooltip=tooltip,\n    254     )\n    255     .properties(width=matrix_width, height=vertical_bar_chart_height)\n    256 )\n    258 vertical_bar_text = vertical_bar.mark_text(\n    259     color=main_color, dy=-10, size=vertical_bar_label_size\n    260 ).encode(text=alt.Text(\"count:Q\", format=\".0f\"))\n    262 vertical_bar_chart = (vertical_bar + vertical_bar_text).add_selection(\n    263     color_selection\n    264 )\n\nFile /opt/miniconda3/lib/python3.12/site-packages/altair/vegalite/v5/schema/mixins.py:2786, in MarkMethodMixin.mark_bar(self, align, angle, aria, ariaRole, ariaRoleDescription, aspect, bandSize, baseline, binSpacing, blend, clip, color, continuousBandSize, cornerRadius, cornerRadiusBottomLeft, cornerRadiusBottomRight, cornerRadiusEnd, cornerRadiusTopLeft, cornerRadiusTopRight, cursor, description, dir, discreteBandSize, dx, dy, ellipsis, fill, fillOpacity, filled, font, fontSize, fontStyle, fontWeight, height, href, innerRadius, interpolate, invalid, limit, line, lineBreak, lineHeight, minBandSize, opacity, order, orient, outerRadius, padAngle, point, radius, radius2, radius2Offset, radiusOffset, shape, size, smooth, stroke, strokeCap, strokeDash, strokeDashOffset, strokeJoin, strokeMiterLimit, strokeOffset, strokeOpacity, strokeWidth, style, tension, text, theta, theta2, theta2Offset, thetaOffset, thickness, timeUnitBandPosition, timeUnitBandSize, tooltip, url, width, x, x2, x2Offset, xOffset, y, y2, y2Offset, yOffset, **kwds)\n   2784 copy = self.copy(deep=False)  # type: ignore[attr-defined]\n   2785 if any(val is not Undefined for val in kwds.values()):\n-&gt; 2786     copy.mark = core.MarkDef(type=\"bar\", **kwds)\n   2787 else:\n   2788     copy.mark = \"bar\"\n\nFile /opt/miniconda3/lib/python3.12/site-packages/altair/vegalite/v5/schema/core.py:23720, in MarkDef.__init__(self, type, align, angle, aria, ariaRole, ariaRoleDescription, aspect, bandSize, baseline, binSpacing, blend, clip, color, continuousBandSize, cornerRadius, cornerRadiusBottomLeft, cornerRadiusBottomRight, cornerRadiusEnd, cornerRadiusTopLeft, cornerRadiusTopRight, cursor, description, dir, discreteBandSize, dx, dy, ellipsis, fill, fillOpacity, filled, font, fontSize, fontStyle, fontWeight, height, href, innerRadius, interpolate, invalid, limit, line, lineBreak, lineHeight, minBandSize, opacity, order, orient, outerRadius, padAngle, point, radius, radius2, radius2Offset, radiusOffset, shape, size, smooth, stroke, strokeCap, strokeDash, strokeDashOffset, strokeJoin, strokeMiterLimit, strokeOffset, strokeOpacity, strokeWidth, style, tension, text, theta, theta2, theta2Offset, thetaOffset, thickness, timeUnitBandPosition, timeUnitBandSize, tooltip, url, width, x, x2, x2Offset, xOffset, y, y2, y2Offset, yOffset, **kwds)\n  22901 def __init__(\n  22902     self,\n  22903     type: Union[\n   (...)\n  23718     **kwds,\n  23719 ):\n&gt; 23720     super(MarkDef, self).__init__(\n  23721         type=type,\n  23722         align=align,\n  23723         angle=angle,\n  23724         aria=aria,\n  23725         ariaRole=ariaRole,\n  23726         ariaRoleDescription=ariaRoleDescription,\n  23727         aspect=aspect,\n  23728         bandSize=bandSize,\n  23729         baseline=baseline,\n  23730         binSpacing=binSpacing,\n  23731         blend=blend,\n  23732         clip=clip,\n  23733         color=color,\n  23734         continuousBandSize=continuousBandSize,\n  23735         cornerRadius=cornerRadius,\n  23736         cornerRadiusBottomLeft=cornerRadiusBottomLeft,\n  23737         cornerRadiusBottomRight=cornerRadiusBottomRight,\n  23738         cornerRadiusEnd=cornerRadiusEnd,\n  23739         cornerRadiusTopLeft=cornerRadiusTopLeft,\n  23740         cornerRadiusTopRight=cornerRadiusTopRight,\n  23741         cursor=cursor,\n  23742         description=description,\n  23743         dir=dir,\n  23744         discreteBandSize=discreteBandSize,\n  23745         dx=dx,\n  23746         dy=dy,\n  23747         ellipsis=ellipsis,\n  23748         fill=fill,\n  23749         fillOpacity=fillOpacity,\n  23750         filled=filled,\n  23751         font=font,\n  23752         fontSize=fontSize,\n  23753         fontStyle=fontStyle,\n  23754         fontWeight=fontWeight,\n  23755         height=height,\n  23756         href=href,\n  23757         innerRadius=innerRadius,\n  23758         interpolate=interpolate,\n  23759         invalid=invalid,\n  23760         limit=limit,\n  23761         line=line,\n  23762         lineBreak=lineBreak,\n  23763         lineHeight=lineHeight,\n  23764         minBandSize=minBandSize,\n  23765         opacity=opacity,\n  23766         order=order,\n  23767         orient=orient,\n  23768         outerRadius=outerRadius,\n  23769         padAngle=padAngle,\n  23770         point=point,\n  23771         radius=radius,\n  23772         radius2=radius2,\n  23773         radius2Offset=radius2Offset,\n  23774         radiusOffset=radiusOffset,\n  23775         shape=shape,\n  23776         size=size,\n  23777         smooth=smooth,\n  23778         stroke=stroke,\n  23779         strokeCap=strokeCap,\n  23780         strokeDash=strokeDash,\n  23781         strokeDashOffset=strokeDashOffset,\n  23782         strokeJoin=strokeJoin,\n  23783         strokeMiterLimit=strokeMiterLimit,\n  23784         strokeOffset=strokeOffset,\n  23785         strokeOpacity=strokeOpacity,\n  23786         strokeWidth=strokeWidth,\n  23787         style=style,\n  23788         tension=tension,\n  23789         text=text,\n  23790         theta=theta,\n  23791         theta2=theta2,\n  23792         theta2Offset=theta2Offset,\n  23793         thetaOffset=thetaOffset,\n  23794         thickness=thickness,\n  23795         timeUnitBandPosition=timeUnitBandPosition,\n  23796         timeUnitBandSize=timeUnitBandSize,\n  23797         tooltip=tooltip,\n  23798         url=url,\n  23799         width=width,\n  23800         x=x,\n  23801         x2=x2,\n  23802         x2Offset=x2Offset,\n  23803         xOffset=xOffset,\n  23804         y=y,\n  23805         y2=y2,\n  23806         y2Offset=y2Offset,\n  23807         yOffset=yOffset,\n  23808         **kwds,\n  23809     )\n\nFile /opt/miniconda3/lib/python3.12/site-packages/altair/vegalite/v5/schema/core.py:149, in AnyMark.__init__(self, *args, **kwds)\n    148 def __init__(self, *args, **kwds):\n--&gt; 149     super(AnyMark, self).__init__(*args, **kwds)\n\nFile /opt/miniconda3/lib/python3.12/site-packages/altair/utils/schemapi.py:771, in SchemaBase.__init__(self, *args, **kwds)\n    768 object.__setattr__(self, \"_kwds\", kwds)\n    770 if DEBUG_MODE and self._class_is_valid_at_instantiation:\n--&gt; 771     self.to_dict(validate=True)\n\nFile /opt/miniconda3/lib/python3.12/site-packages/altair/utils/schemapi.py:978, in SchemaBase.to_dict(self, validate, ignore, context)\n    971         self.validate(result)\n    972     except jsonschema.ValidationError as err:\n    973         # We do not raise `from err` as else the resulting\n    974         # traceback is very long as it contains part\n    975         # of the Vega-Lite schema. It would also first\n    976         # show the less helpful ValidationError instead of\n    977         # the more user friendly SchemaValidationError\n--&gt; 978         raise SchemaValidationError(self, err) from None\n    979 return result\n\nSchemaValidationError: '-7.628865979381443' is an invalid value for `size`.\n\n-7.628865979381443 is less than the minimum of 0\n\n\n\n\n\n\nERROR:root:No traceback has been produced, nothing to debug.",
    "crumbs": [
      "Altair and Other Charts"
    ]
  },
  {
    "objectID": "jupyter_notebook.html",
    "href": "jupyter_notebook.html",
    "title": "Jupyter Notebooks",
    "section": "",
    "text": "backup_folders_of_nbs\n\n backup_folders_of_nbs (src, dest)\n\n\n\n\nbackup_all_notebooks\n\n backup_all_notebooks (folder)\n\n\n\n\nbackup_this_notebook\n\n backup_this_notebook (this_file_path, save_html_to_dir=None,\n                       override_previous_backup=False, changelog=None,\n                       exclude_input=False, force_save_notebook=True)\n\n\n\n\nsave_notebook\n\n save_notebook (file_path)\n\n\nbackup_this_notebook(\"jupyter_notebook.ipynb\")\n\n\n\n\nshow_big_dataframe\n\n show_big_dataframe (df, max_rows=30)\n\n\n\n\ndisplay_dfs_side_by_side\n\n display_dfs_side_by_side (*args, titles=&lt;itertools.cycle object at\n                           0x10fcb3f80&gt;, max_rows=50)\n\n\n\n\nh6\n\n h6 (text)\n\n\n\n\nh5\n\n h5 (text)\n\n\n\n\nh4\n\n h4 (text)\n\n\n\n\nh3\n\n h3 (text)\n\n\n\n\nh2\n\n h2 (text)\n\n\n\n\nh1\n\n h1 (text)\n\n\n\n\nstore_scrap\n\n store_scrap (at)\n\n\n\n\nshutdown_current_notebook\n\n shutdown_current_notebook (delay:int=None)",
    "crumbs": [
      "Jupyter Notebooks"
    ]
  },
  {
    "objectID": "misc.html",
    "href": "misc.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "Use timer as a standalone class so you have full control on when to call a lap (most useful in while loops)…\n\nN = 50\nt = Timer(N)\ninfo = None\n\nfor i in range(N):\n    time.sleep(0.01)\n    t(info=info)  # Lap and present the time\n    if i == N // 2:\n        print()\n        info = f\"My Info: {i*3.122}\"\n\n26/50 (0.32s  - 0.30s remaining - 81.30 iters/s)          \nMy Info: 78.05  50/50 (0.61s  - 0.00s remaining - 81.75 iters/s)",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#timer",
    "href": "misc.html#timer",
    "title": "Miscellaneous",
    "section": "",
    "text": "Use timer as a standalone class so you have full control on when to call a lap (most useful in while loops)…\n\nN = 50\nt = Timer(N)\ninfo = None\n\nfor i in range(N):\n    time.sleep(0.01)\n    t(info=info)  # Lap and present the time\n    if i == N // 2:\n        print()\n        info = f\"My Info: {i*3.122}\"\n\n26/50 (0.32s  - 0.30s remaining - 81.30 iters/s)          \nMy Info: 78.05  50/50 (0.61s  - 0.00s remaining - 81.75 iters/s)",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#track2",
    "href": "misc.html#track2",
    "title": "Miscellaneous",
    "section": "Track2",
    "text": "Track2\n… or use track2 to directly track a for loop\n\nN = 50\ninfo = None\n\nfor i in (tracker := track2(range(N), total=N)):\n    time.sleep(0.01)\n    info = f\"My Info: {i*3.122:.2f}\"\n    if i == N // 2:\n        print()\n    if i &gt;= N // 2:\n        tracker.send(info)\n\n25/50 (0.31s  - 0.31s remaining - 81.55 iters/s)          \nMy Info: 152.98 50/50 (0.61s  - 0.00s remaining - 82.52 iters/s)          \n\n\nWarning! NEVER RUN tracker.send(None) as this will skip variables silently",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#print-execution-time",
    "href": "misc.html#print-execution-time",
    "title": "Miscellaneous",
    "section": "Print execution time",
    "text": "Print execution time\n@timeit decorates and prints time taken to execute a function as an info log\n\n@timeit\ndef foo(a, b=None):\n    if b is None:\n        return a + 1\n    else:\n        time.sleep(2)\n        return a + b\n\n\nfoo(10)\nfoo(10, b=20)\n\n[01/02/25 20:59:04] INFO     0.00 seconds to execute `foo`                                                                                            3546464892.py:inner:16\n\n\n\n[01/02/25 20:59:06] INFO     2.01 seconds to execute `foo`                                                                                            3546464892.py:inner:16\n\n\n\n30",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#print-io",
    "href": "misc.html#print-io",
    "title": "Miscellaneous",
    "section": "Print IO",
    "text": "Print IO\n@io will decorate to show inputs and outputs (along with time taken to execute) as a debug log\n\n@io\ndef foo(a, b=None):\n    if b is None:\n        return a + 1\n    else:\n        time.sleep(2)\n        return a + b\n\n\nwith debug_mode():\n    foo(10)\n    foo(10, b=20)\n\n[01/02/25 20:59:10] DEBUG                                                                                                                          3679299354.py:&lt;module&gt;:11\n                             0.00 seconds to execute `foo`                                                                                                                  \n                             args()                                                                                                                                         \n                               0 - 10 (🏷️ int)                                                                                                                               \n                             kwargs                                                                                                                                         \n                             outputs - 11 (🏷️ int)                                                                                                                           \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n[01/02/25 20:59:12] DEBUG                                                                                                                          3679299354.py:&lt;module&gt;:12\n                             2.01 seconds to execute `foo`                                                                                                                  \n                             args()                                                                                                                                         \n                               0 - 10 (🏷️ int)                                                                                                                               \n                             kwargs                                                                                                                                         \n                               b - 20 (🏷️ int)                                                                                                                               \n                             outputs - 30 (🏷️ int)                                                                                                                           \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\n@io can be forced to print as log/trace if needed\n\n@io(level=\"trace\")\ndef foo(a, b=None):\n    if b is None:\n        return a + 1\n    else:\n        time.sleep(2)\n        return a + b\n\n\nwith trace_mode():\n    foo(10)\n    import time\n\n    time.sleep(1)\n    foo(10, b=20)\n\n[06/15/25 18:58:59] TRACE                                                                                                         &lt;ipython-input-1-57a17d8aa123&gt;:&lt;module&gt;:11\n                             0.00 seconds to execute `foo`                                                                                                                  \n                             args()                                                                                                                                         \n                               0 - 10 (🏷️ int)                                                                                                                               \n                             kwargs                                                                                                                                         \n                             outputs - 11 (🏷️ int)                                                                                                                           \n                                                                                                                                                                            \n                                                                                                                                                                            \n[06/15/25 18:59:02] TRACE                                                                                                         &lt;ipython-input-1-57a17d8aa123&gt;:&lt;module&gt;:15\n                             2.01 seconds to execute `foo`                                                                                                                  \n                             args()                                                                                                                                         \n                               0 - 10 (🏷️ int)                                                                                                                               \n                             kwargs                                                                                                                                         \n                               b - 20 (🏷️ int)                                                                                                                               \n                             outputs - 30 (🏷️ int)                                                                                                                           \n                                                                                                                                                                            \n                                                                                                                                                                            \n\n\n\nSource path:... &lt;ipython-input-1-57a17d8aa123&gt;\n\nStarting var:.. a = 10\n\nStarting var:.. b = None\n\n18:58:59.237764 call         1 SOURCE IS UNAVAILABLE\n\n18:58:59.237840 line         3 SOURCE IS UNAVAILABLE\n\n18:58:59.237855 line         4 SOURCE IS UNAVAILABLE\n\n18:58:59.237865 return       4 SOURCE IS UNAVAILABLE\n\nReturn value:.. 11\n\nElapsed time: 00:00:00.000309\n\nSource path:... &lt;ipython-input-1-57a17d8aa123&gt;\n\nStarting var:.. a = 10\n\nStarting var:.. b = 20\n\n18:59:00.636968 call         1 SOURCE IS UNAVAILABLE\n\n18:59:00.637033 line         3 SOURCE IS UNAVAILABLE\n\n18:59:00.637046 line         6 SOURCE IS UNAVAILABLE\n\n18:59:02.642140 line         7 SOURCE IS UNAVAILABLE\n\n18:59:02.642571 return       7 SOURCE IS UNAVAILABLE\n\nReturn value:.. 30\n\nElapsed time: 00:00:02.006072",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "misc.html#try-catch-with-a-single-line",
    "href": "misc.html#try-catch-with-a-single-line",
    "title": "Miscellaneous",
    "section": "Try Catch with a single line",
    "text": "Try Catch with a single line\n\n@tryy\ndef do(a, b, c):\n    return 1 / 0\n\n\nx = do(1, 2, c=10)\nassert x is None  # tryy returns None by default\n\n[01/02/25 20:59:38] WARNING  Error for `do`: ZeroDivisionError: division by zero                                                                     579939537.py:wrapper:27\n\n\n\nUse your own default on failure\n\n@tryy(output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    return 1 / 0\n\n\ndo(1, 2, c=10)\n\n                    WARNING  Error for `do`: ZeroDivisionError: division by zero                                                                     579939537.py:wrapper:27\n\n\n\n'😔'\n\n\nOptionally print the full stacktrace if needed\n\n@tryy(print_traceback=True, output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    return 1 / 0\n\n\ndo(1, 2, c=10)\n\n                    WARNING  Error for `do`:                                                                                                         579939537.py:wrapper:32\n                             Traceback (most recent call last):                                                                                                             \n                               File \"/var/folders/1_/71dqv9vx2750gmyz77q_f45w0000gn/T/ipykernel_70802/579939537.py\", line 22, in wrapper                                    \n                                 return f(*args, **kwargs)                                                                                                                  \n                                        ^^^^^^^^^^^^^^^^^^                                                                                                                  \n                               File \"/var/folders/1_/71dqv9vx2750gmyz77q_f45w0000gn/T/ipykernel_70802/580638143.py\", line 3, in do                                          \n                                 return 1 / 0                                                                                                                               \n                                        ~~^~~                                                                                                                               \n                             ZeroDivisionError: division by zero                                                                                                            \n                                                                                                                                                                            \n\n\n\n'😔'\n\n\nYou can also silence the errors completely\n\n@tryy(silence_errors=True, output_to_return_on_fail=\"😔\")\ndef do(a, b, c):\n    return 1 / 0\n\n\ndo(1, 2, c=10)\n\n'😔'\n\n\nYou can collect all your errors in a list\n\nimport random\n\nerrors = []\n\n\n@tryy(silence_errors=True, store_errors=errors)\ndef do(a, b, c):\n    if random.randint(0, 100) &lt; 50:\n        return 1 / 0\n    else:\n        raise NotImplementedError(\"🤔\")\n\n\nfor _ in range(4):\n    do(1, random.randint(0, 10), c=random.randint(0, 100))\n\nprint(errors)\n\n[{'func': 'do', 'args': (1, 4), 'kwargs': {'c': 53}, 'tb': None, 'err_type': 'ZeroDivisionError'}, {'func': 'do', 'args': (1, 3), 'kwargs': {'c': 68}, 'tb': None, 'err_type': 'ZeroDivisionError'}, {'func': 'do', 'args': (1, 1), 'kwargs': {'c': 2}, 'tb': None, 'err_type': 'NotImplementedError'}, {'func': 'do', 'args': (1, 10), 'kwargs': {'c': 96}, 'tb': None, 'err_type': 'NotImplementedError'}]\n\n\nThere’s onlly one usecase where you would want to send in a list by yourself - when you want to append your errors to an existing list. The sensible default is to always store the errors, especially because this is a debugging tool.\nJust access all the errors in a dataframe like so\n\nimport random\n\nrandom.seed(10)\n\n\n@tryy(silence_errors=True)\ndef do(a, b, c):\n    if c &lt; 50:\n        return 1 / 0\n    else:\n        raise NotImplementedError(\"🤔\")\n\n\nfor _ in range(4):\n    do(1, random.randint(0, 10), c=random.randint(0, 100))\n\ndo.error_summary()\n\n\n\n\n\n\n\n\nfunc\nargs\nkwargs\ntb\nerr_type\n\n\n\n\n0\ndo\n(1, 9)\n{'c': 4}\nNone\nZeroDivisionError\n\n\n1\ndo\n(1, 6)\n{'c': 61}\nNone\nNotImplementedError\n\n\n2\ndo\n(1, 9)\n{'c': 1}\nNone\nZeroDivisionError\n\n\n3\ndo\n(1, 3)\n{'c': 59}\nNone\nNotImplementedError\n\n\n\n\n\n\n\nand the actual list of errors like so\n\ndo.error_store\n\n[{'func': 'do',\n  'args': (1, 9),\n  'kwargs': {'c': 4},\n  'tb': None,\n  'err_type': 'ZeroDivisionError'},\n {'func': 'do',\n  'args': (1, 6),\n  'kwargs': {'c': 61},\n  'tb': None,\n  'err_type': 'NotImplementedError'},\n {'func': 'do',\n  'args': (1, 9),\n  'kwargs': {'c': 1},\n  'tb': None,\n  'err_type': 'ZeroDivisionError'},\n {'func': 'do',\n  'args': (1, 3),\n  'kwargs': {'c': 59},\n  'tb': None,\n  'err_type': 'NotImplementedError'}]\n\n\nFinally, you want to run the function (without try) to reproduce the error and actually start debugging. Just use the .F attribute to access the original function that you created\n\nix = 2\ndata = do.error_store[ix]\ntry:\n    do.F(*data.args, **data.kwargs)\nexcept Exception as e:\n    print(f\"ERROR: \", e)\n\nERROR:  'dict' object has no attribute 'args'\n\n\n\n\n\ncast_inputs\n\n cast_inputs (func)\n\n\n@cast_inputs\ndef do(a: int, b: int):\n    return a + b\n\nassert do(1, 2) == 3\nassert do(1, '2') == 3\nassert do('1', '2') == 3",
    "crumbs": [
      "Miscellaneous"
    ]
  },
  {
    "objectID": "adapters.html",
    "href": "adapters.html",
    "title": "Adapters",
    "section": "",
    "text": "{}\n\n\n\n\n\n\n file_2_bytes (fpath)\n\n\n\n\n\n\n bytes_2_file (input:bytes, fpath:Union[str,pathlib._local.Path],\n               silent:bool=False)\n\nSave bytes input at given fpath\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput\nbytes\n\nbytes\n\n\nfpath\nUnion\n\nPlace where you want to save the file\n\n\nsilent\nbool\nFalse\n\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\n\n b64_2_file (input:str, fpath:Union[str,pathlib._local.Path])\n\nSave a file encoded as a base64 input at given fpath\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nstr\nbase64 encoded string\n\n\nfpath\nUnion\nPlace where you want to save the file\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\n b64_2_np (input:str)\n\n*Converts a base64 encoded image to a NumPy array.\nArgs: input (str): The base64 encoded image.\nReturns: np.ndarray: The NumPy array representation of the image in RGB format.*\n\n\n\n\n\n np_2_b64 (image:numpy.ndarray)\n\nConvert a numpy image to base64 string\n\n\n\n\n\n cvat_2_csvs (xmlfile, csvs_folder)\n\n*Convert CVAT XML annotations to CSV files.\nArgs: xmlfile (str): Path to the CVAT XML file. csvs_folder (str): Path to the folder where the CSV files will be saved.\nReturns: None*\n\n\n\n\n\n csvs_2_cvat (images_folder, csvs_folder, xml_output_file, items=None,\n              parquet=False, relative_df=True, default_label='Background',\n              extension='jpg')\n\n*Convert CSV annotations to CVAT XML format.\nArgs: images_folder (str): Path to the folder containing the images. csvs_folder (str): Path to the folder containing the CSV annotations. xml_output_file (str): Path to the output XML file. items (list, optional): List of items to process. If None, all items will be processed. Defaults to None. parquet (bool, optional): Whether the annotations are stored in Parquet format. Defaults to False. relative_df (bool, optional): Whether the bounding box coordinates in the CSV are relative to the image size. Defaults to True. default_label (str, optional): Default label for the bounding boxes. Defaults to “Background”. extension (str, optional): Image file extension. Defaults to “jpg”.\nReturns: None*\n\n\n\n\n\n yolo_2_df (yolo, h, w, id2class, class_column)\n\n\n\n\n\n\n df_2_yolo (df, h, w, class2id, class_column)",
    "crumbs": [
      "Adapters"
    ]
  },
  {
    "objectID": "adapters.html#to-convert-data-fromto-various-formats",
    "href": "adapters.html#to-convert-data-fromto-various-formats",
    "title": "Adapters",
    "section": "",
    "text": "{}\n\n\n\n\n\n\n file_2_bytes (fpath)\n\n\n\n\n\n\n bytes_2_file (input:bytes, fpath:Union[str,pathlib._local.Path],\n               silent:bool=False)\n\nSave bytes input at given fpath\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput\nbytes\n\nbytes\n\n\nfpath\nUnion\n\nPlace where you want to save the file\n\n\nsilent\nbool\nFalse\n\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\n\n b64_2_file (input:str, fpath:Union[str,pathlib._local.Path])\n\nSave a file encoded as a base64 input at given fpath\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nstr\nbase64 encoded string\n\n\nfpath\nUnion\nPlace where you want to save the file\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\n b64_2_np (input:str)\n\n*Converts a base64 encoded image to a NumPy array.\nArgs: input (str): The base64 encoded image.\nReturns: np.ndarray: The NumPy array representation of the image in RGB format.*\n\n\n\n\n\n np_2_b64 (image:numpy.ndarray)\n\nConvert a numpy image to base64 string\n\n\n\n\n\n cvat_2_csvs (xmlfile, csvs_folder)\n\n*Convert CVAT XML annotations to CSV files.\nArgs: xmlfile (str): Path to the CVAT XML file. csvs_folder (str): Path to the folder where the CSV files will be saved.\nReturns: None*\n\n\n\n\n\n csvs_2_cvat (images_folder, csvs_folder, xml_output_file, items=None,\n              parquet=False, relative_df=True, default_label='Background',\n              extension='jpg')\n\n*Convert CSV annotations to CVAT XML format.\nArgs: images_folder (str): Path to the folder containing the images. csvs_folder (str): Path to the folder containing the CSV annotations. xml_output_file (str): Path to the output XML file. items (list, optional): List of items to process. If None, all items will be processed. Defaults to None. parquet (bool, optional): Whether the annotations are stored in Parquet format. Defaults to False. relative_df (bool, optional): Whether the bounding box coordinates in the CSV are relative to the image size. Defaults to True. default_label (str, optional): Default label for the bounding boxes. Defaults to “Background”. extension (str, optional): Image file extension. Defaults to “jpg”.\nReturns: None*\n\n\n\n\n\n yolo_2_df (yolo, h, w, id2class, class_column)\n\n\n\n\n\n\n df_2_yolo (df, h, w, class2id, class_column)",
    "crumbs": [
      "Adapters"
    ]
  },
  {
    "objectID": "capsule.html",
    "href": "capsule.html",
    "title": "Capsule (Tutorial)",
    "section": "",
    "text": "Let’s load the iris dataset first\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\ndata = load_iris()\nX, y = data.data, data.target\nX_trn, X_val, y_trn, y_val = train_test_split(X, y, random_state=42)\n\n… and create the data loaders\n\nfrom torch_snippets.markup2 import AD\nfrom torch.utils.data import TensorDataset\n\ntrn_ds = TensorDataset(*[torch.Tensor(i) for i in [X_trn, y_trn]])\ntrn_dl = DataLoader(trn_ds, batch_size=32)\n\nval_ds = TensorDataset(*[torch.Tensor(i) for i in [X_val, y_val]])\nval_dl = DataLoader(val_ds, batch_size=32)\n\nAD(next(iter(val_dl)))\n\n\n```↯ AttrDict ↯\nnext(iter(val_dl))[]\n  0 - 🔦tensor[32, 4] n=128 x∈[0.100, 7.900] μ=3.487 σ=2.034 - ID:#56f55949\n  1 - 🔦tensor[32] x∈[0., 2.000] μ=0.969 σ=0.861 - ID:#b365fa0a\n\n```\n\n\nNext we’ll import Capsule and a few decorators that will tell the model to change it’s mode to train/test during the fit function\nfrom torch_snippets.trainer.capsule import Capsule, train, validate, predict\nCreate the neural network and define it’s forward function as usual pytorch business. Only difference now is that you’ll also add self.loss_fn and self.optimizer attributes in the init\nclass IrisModel(Capsule):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.BatchNorm1d(4),\n            nn.Linear(4, 16),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(16),\n            nn.ReLU(inplace=True),\n            nn.Linear(16, 8),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(8),\n            nn.ReLU(inplace=True),\n            nn.Linear(8, 3),\n        )\n        self.loss_fn = nn.CrossEntropyLoss()\n        self.optimizer = optim.Adam(self.parameters())\n\n    def forward(self, x):\n        return self.model(x)\nTo fully describe the model’s behaviour we still need to define three functions\n1. train_batch\n2. validate_batch and,\n3. predict which is optional\nlike so\n\n    @train\n    def train_batch(self, batch):\n        x, y = batch\n        _y = self.forward(x)\n        loss = self.loss_fn(_y, y.long())\n        return {\"loss\": loss}\n\n    @validate\n    def validate_batch(self, batch=None, dl=None):\n        if dl is not None:\n            output = []\n            for batch in dl:\n                output.extend(self.predict(batch=batch)[\"val_acc\"])\n            return np.mean(output)\n        x, y = batch\n        _y = self.forward(x)\n        loss = self.loss_fn(_y, y.long())\n        acc = (y == _y.max(-1)[1]).float().mean()\n        return {\"val_loss\": loss, \"val_acc\": acc}\n\n    @predict\n    def predict(self, batch=None, dl=None):\n        if dl is not None:\n            output = []\n            for batch in dl:\n                output.extend(self.predict(batch=batch))\n            return output\n        x, y = batch\n        _y = self.forward(x)\n        o = _y.max(-1)[1].cpu().detach().numpy().tolist()\n        return o\n\nEnsure you return dictionaries of losses, accuracy metrics in train_batch and validate_batch functions. You can return as many metrics during training and validation, they will be auto logged.\n\nAlso make sure at least one of the keys in train_batch is the key loss, as this is used to compute gradients.*\n\nWe could now create the model…\n\nmodel = IrisModel()\nmodel.device = \"cpu\"\n\n… and run model.fit with an optional number of logs to print to the console\n\nmodel.fit(trn_dl, val_dl, num_epochs=100, print_total=2, device=\"cpu\")\n\nEPOCH: 1.000  val_acc: 0.281  loss: 1.118  val_loss: 1.159  (0.05s - 5.02s remaining)\nEPOCH: 50.000  val_acc: 1.000  loss: 0.490  val_loss: 0.406  (0.18s - 0.18s remaining)\nEPOCH: 100.000  val_acc: 1.000  loss: 0.238  val_loss: 0.162  (0.31s - 0.00s remaining)\n\n\n\n\n\n\n\n\n\nmodel.evaluate accepts a validation data loader that will repeatedly call validate_batch and return aggregated metrics\n\nmodel.evaluate(val_dl, device=\"cpu\")\n\nEPOCH: 1.000  val_acc: 1.000  val_loss: 0.164  (0.00s - 0.00s remaining)\n\n\n{'epoch_val_acc': np.float64(1.0),\n 'epoch_val_loss': np.float64(0.16414348781108856)}",
    "crumbs": [
      "Capsule (Tutorial)"
    ]
  },
  {
    "objectID": "inspector.html",
    "href": "inspector.html",
    "title": "Inspect",
    "section": "",
    "text": "import torch, numpy as np\nfrom torch_snippets import inspect\n\ninspect(torch.randint(0, 100, size=(4, 3, 5)), np.random.randint(-10, 10, (9, 19, 1)))\n\n══════════════════════════════════════════════════════════════════\n\n\n\nTensor  Shape: torch.Size([4, 3, 5])    Min: 2.000      Max: 97.000     Mean: 46.317    dtype: torch.int64 @ cpu\n\n\n\n══════════════════════════════════════════════════════════════════\n\n\n\nndarray Shape: (9, 19, 1)       Min: -10.000    Max: 9.000      Mean: -0.345    dtype: int64\n\n\n\n══════════════════════════════════════════════════════════════════\n\n\n\n\nx = {\n    \"a\": [0, 1, 2, 3],\n    \"b\": torch.rand(10, 10),\n    \"c\": {\n        \"d\": np.arange(10),\n        \"e\": [\n            \"np.arange\",\n            {},\n            tuple(\n                [\n                    1,\n                    2,\n                ]\n            ),\n            set([1, 2, 3]),\n            [],\n            [11, 10],\n        ],\n    },\n}\ninspect(x)\n\n══════════════════════════════════════════════════════════════════\n\n\n\ndict of 3 items\n\n\n\n        A:\n        list of 4 items\n\n\n\n                int: 0\n\n\n\n                int: 1\n\n\n\n                int: 2\n\n\n\n                int: 3\n\n\n\n        B:\n        Tensor  Shape: torch.Size([10, 10])     Min: 0.000      Max: 0.989      Mean: 0.463     dtype: \ntorch.float32 @ cpu\n\n\n\n        C:\n        dict of 2 items\n\n\n\n                D:\n                ndarray Shape: (10,)    Min: 0.000      Max: 9.000      Mean: 4.500     dtype: int64\n\n\n\n                E:\n                list of 6 items\n\n\n\n                        str `np.arange`\n\n\n\n                        dict of 0 items\n\n\n\n                        tuple of 2 items\n\n\n\n                                int: 1\n\n\n\n                                int: 2\n\n\n\n                        set Length: 3\n\n\n\n                        list of 0 items\n\n\n\n                        and ... ... 1 more item(s)\n\n\n\n══════════════════════════════════════════════════════════════════",
    "crumbs": [
      "Inspect"
    ]
  },
  {
    "objectID": "scripts.html",
    "href": "scripts.html",
    "title": "torch_snippets",
    "section": "",
    "text": "from torch_snippets import *\n\nVERSION = find(\"version\", readlines(\"settings.ini\")).split(\"=\")[1].strip()\nVERSION\n\n» /Users/yeshwanth\n\n\n\n\n# !rm -rf _proc\n# !rm -rf docs\nimport nbdev\n\n# !nbdev_docs\nfrom nbdev.quarto import nbdev_docs\n\nnbdev_docs(\"./\")\n\n/Users/yeshwanth/.venv/lib/python3.13/site-packages/nbdev/doclinks.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools&lt;81.\n  import pkg_resources,importlib\n\n\n\n---------------------------------------------------------------------------\nInterpolationMissingOptionError           Traceback (most recent call last)\nCell In[3], line 8\n      5 # !nbdev_docs\n      6 from nbdev.quarto import nbdev_docs\n----&gt; 8 nbdev_docs(\"./\")\n\nFile ~/.venv/lib/python3.13/site-packages/fastcore/script.py:116, in call_parse.&lt;locals&gt;._f(*args, **kwargs)\n    113 @wraps(func)\n    114 def _f(*args, **kwargs):\n    115     mod = inspect.getmodule(inspect.currentframe().f_back)\n--&gt; 116     if not mod: return func(*args, **kwargs)\n    117     if not SCRIPT_INFO.func and mod.__name__==\"__main__\": SCRIPT_INFO.func = func.__name__\n    118     if len(sys.argv)&gt;1 and sys.argv[1]=='': sys.argv.pop(1)\n\nFile ~/.venv/lib/python3.13/site-packages/nbdev/quarto.py:311, in nbdev_docs(path, n_workers, **kwargs)\n    304 @call_parse\n    305 @delegates(_nbglob_docs)\n    306 def nbdev_docs(\n    307     path:str=None, # Path to notebooks\n    308     n_workers:int=defaults.cpus,  # Number of workers\n    309     **kwargs):\n    310     \"Create Quarto docs and README.md\"\n--&gt; 311     cache,cfg,path = _pre_docs(path, n_workers=n_workers, **kwargs)\n    312     nbdev_readme.__wrapped__(path=path, chk_time=True)\n    313     nbdev_contributing.__wrapped__(path=path, chk_time=True)\n\nFile ~/.venv/lib/python3.13/site-packages/nbdev/quarto.py:203, in _pre_docs(path, n_workers, **kwargs)\n    201 path = Path(path) if path else cfg.nbs_path\n    202 _ensure_quarto()\n--&gt; 203 refresh_quarto_yml()\n    204 import nbdev.doclinks\n    205 nbdev.doclinks._build_modidx()\n\nFile ~/.venv/lib/python3.13/site-packages/nbdev/quarto.py:183, in refresh_quarto_yml()\n    181 cfg = get_config()\n    182 ny = cfg.nbs_path/'nbdev.yml'\n--&gt; 183 vals = {k:cfg[k] for k in ['title', 'description', 'branch', 'git_url', 'doc_host', 'doc_baseurl']}\n    184 vals['doc_path'] = cfg.doc_path.name\n    185 if 'title' not in vals: vals['title'] = vals['lib_name']\n\nFile ~/.venv/lib/python3.13/site-packages/fastcore/foundation.py:281, in Config.__getitem__(self, k)\n--&gt; 281 def __getitem__(self,k):   return stop(IndexError(k)) if k not in self.d else self.get(k)\n\nFile ~/.venv/lib/python3.13/site-packages/fastcore/foundation.py:284, in Config.get(self, k, default)\n    283 def get(self,k,default=None):\n--&gt; 284     v = self.d.get(k, default)\n    285     if v is None: return None\n    286     typ = self.types.get(k, None)\n\nFile ~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/configparser.py:1325, in SectionProxy.get(self, option, fallback, raw, vars, _impl, **kwargs)\n   1323 if not _impl:\n   1324     _impl = self._parser.get\n-&gt; 1325 return _impl(self._name, option, raw=raw, vars=vars,\n   1326              fallback=fallback, **kwargs)\n\nFile ~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/configparser.py:828, in RawConfigParser.get(self, section, option, raw, vars, fallback)\n    826     return value\n    827 else:\n--&gt; 828     return self._interpolation.before_get(self, section, option, value,\n    829                                           d)\n\nFile ~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/configparser.py:415, in BasicInterpolation.before_get(self, parser, section, option, value, defaults)\n    413 def before_get(self, parser, section, option, value, defaults):\n    414     L = []\n--&gt; 415     self._interpolate_some(parser, option, L, value, section, defaults, 1)\n    416     return ''.join(L)\n\nFile ~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/configparser.py:457, in BasicInterpolation._interpolate_some(self, parser, option, accum, rest, section, map, depth)\n    454     raise InterpolationMissingOptionError(\n    455         option, section, rawval, var) from None\n    456 if \"%\" in v:\n--&gt; 457     self._interpolate_some(parser, option, accum, v,\n    458                            section, map, depth + 1)\n    459 else:\n    460     accum.append(v)\n\nFile ~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/configparser.py:454, in BasicInterpolation._interpolate_some(self, parser, option, accum, rest, section, map, depth)\n    452     v = map[var]\n    453 except KeyError:\n--&gt; 454     raise InterpolationMissingOptionError(\n    455         option, section, rawval, var) from None\n    456 if \"%\" in v:\n    457     self._interpolate_some(parser, option, accum, v,\n    458                            section, map, depth + 1)\n\nInterpolationMissingOptionError: Bad value substitution: option 'title' in section 'DEFAULT' contains an interpolation key 'repo' which is not a valid option name. Raw value: '%(lib_name)s'\n\n\n\n\nnbdev_export\nnbdev_docs\nnbdev_pypi\n\n\n# !nbdev_test\n\n\n!nbdev_export\n!nbdev_pypi\n\n/Users/yeshwanth/Code/Personal/torch_snippets/setup.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n  from pkg_resources import parse_version\n/opt/miniconda3/lib/python3.12/site-packages/setuptools/dist.py:476: SetuptoolsDeprecationWarning: Invalid dash-separated options\n!!\n\n        ********************************************************************************\n        Usage of dash-separated 'description-file' will not be supported in future\n        versions. Please use the underscore name 'description_file' instead.\n\n        This deprecation is overdue, please update your project and remove deprecated\n        calls to avoid build errors in the future.\n\n        See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n        ********************************************************************************\n\n!!\n  opt = self.warn_dash_deprecation(opt, section)\nrunning sdist\nrunning egg_info\nwriting torch_snippets.egg-info/PKG-INFO\nwriting dependency_links to torch_snippets.egg-info/dependency_links.txt\nwriting entry points to torch_snippets.egg-info/entry_points.txt\nwriting requirements to torch_snippets.egg-info/requires.txt\nwriting top-level names to torch_snippets.egg-info/top_level.txt\nreading manifest file 'torch_snippets.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwarning: no files found matching 'CONTRIBUTING.md'\nwarning: no previously-included files matching '__pycache__' found under directory '*'\nadding license file 'LICENSE'\nadding license file 'LICENSE.txt'\nwriting manifest file 'torch_snippets.egg-info/SOURCES.txt'\nrunning check\ncreating torch_snippets-0.545\ncreating torch_snippets-0.545/torch_snippets\ncreating torch_snippets-0.545/torch_snippets.egg-info\ncreating torch_snippets-0.545/torch_snippets/thinc_parser\ncreating torch_snippets-0.545/torch_snippets/trainer\ncopying files to torch_snippets-0.545...\ncopying LICENSE -&gt; torch_snippets-0.545\ncopying LICENSE.txt -&gt; torch_snippets-0.545\ncopying MANIFEST.in -&gt; torch_snippets-0.545\ncopying README.md -&gt; torch_snippets-0.545\ncopying settings.ini -&gt; torch_snippets-0.545\ncopying setup.cfg -&gt; torch_snippets-0.545\ncopying setup.py -&gt; torch_snippets-0.545\ncopying torch_snippets/__init__.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/__module_timing__.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/_modidx.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/_nbdev.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/adapters.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/bb_utils.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/bokeh_loader.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/charts.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/cli.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/dates.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/decorators.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/fastcores.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/icecream.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/imgaug_loader.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/inspector.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/interactive_show.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/ipython.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/load_defaults.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/loader.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/logger.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/markup.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/markup2.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/misc.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/paths.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/pdf_loader.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/profiler.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/registry.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/s3_loader.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/scp.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/sklegos.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/text_utils.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/tmp.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/torch_loader.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/video.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets/zen.py -&gt; torch_snippets-0.545/torch_snippets\ncopying torch_snippets.egg-info/PKG-INFO -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets.egg-info/SOURCES.txt -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets.egg-info/dependency_links.txt -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets.egg-info/entry_points.txt -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets.egg-info/not-zip-safe -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets.egg-info/requires.txt -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets.egg-info/top_level.txt -&gt; torch_snippets-0.545/torch_snippets.egg-info\ncopying torch_snippets/thinc_parser/__init__.py -&gt; torch_snippets-0.545/torch_snippets/thinc_parser\ncopying torch_snippets/thinc_parser/parser.py -&gt; torch_snippets-0.545/torch_snippets/thinc_parser\ncopying torch_snippets/trainer/__init__.py -&gt; torch_snippets-0.545/torch_snippets/trainer\ncopying torch_snippets/trainer/capsule.py -&gt; torch_snippets-0.545/torch_snippets/trainer\ncopying torch_snippets/trainer/config.py -&gt; torch_snippets-0.545/torch_snippets/trainer\ncopying torch_snippets/trainer/hooks.py -&gt; torch_snippets-0.545/torch_snippets/trainer\ncopying torch_snippets/trainer/neural_graph.py -&gt; torch_snippets-0.545/torch_snippets/trainer\ncopying torch_snippets.egg-info/SOURCES.txt -&gt; torch_snippets-0.545/torch_snippets.egg-info\nWriting torch_snippets-0.545/setup.cfg\ncreating dist\nCreating tar archive\nremoving 'torch_snippets-0.545' (and everything under it)\nrunning bdist_wheel\nrunning build\nrunning build_py\ncreating build\ncreating build/lib\ncreating build/lib/torch_snippets\ncopying torch_snippets/misc.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/load_defaults.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/text_utils.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/_nbdev.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/paths.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/charts.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/pdf_loader.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/interactive_show.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/registry.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/markup2.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/_modidx.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/inspector.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/__init__.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/tmp.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/torch_loader.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/logger.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/markup.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/fastcores.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/sklegos.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/cli.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/ipython.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/loader.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/s3_loader.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/imgaug_loader.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/zen.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/icecream.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/dates.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/profiler.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/bokeh_loader.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/video.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/scp.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/bb_utils.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/__module_timing__.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/adapters.py -&gt; build/lib/torch_snippets\ncopying torch_snippets/decorators.py -&gt; build/lib/torch_snippets\ncreating build/lib/torch_snippets/thinc_parser\ncopying torch_snippets/thinc_parser/__init__.py -&gt; build/lib/torch_snippets/thinc_parser\ncopying torch_snippets/thinc_parser/parser.py -&gt; build/lib/torch_snippets/thinc_parser\ncreating build/lib/torch_snippets/trainer\ncopying torch_snippets/trainer/neural_graph.py -&gt; build/lib/torch_snippets/trainer\ncopying torch_snippets/trainer/hooks.py -&gt; build/lib/torch_snippets/trainer\ncopying torch_snippets/trainer/capsule.py -&gt; build/lib/torch_snippets/trainer\ncopying torch_snippets/trainer/config.py -&gt; build/lib/torch_snippets/trainer\ncopying torch_snippets/trainer/__init__.py -&gt; build/lib/torch_snippets/trainer\n/opt/miniconda3/lib/python3.12/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\ninstalling to build/bdist.macosx-11.1-arm64/wheel\nrunning install\nrunning install_lib\ncreating build/bdist.macosx-11.1-arm64\ncreating build/bdist.macosx-11.1-arm64/wheel\ncreating build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/misc.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/load_defaults.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/text_utils.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/_nbdev.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/paths.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/charts.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/pdf_loader.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/interactive_show.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/registry.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/markup2.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/_modidx.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/inspector.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/__init__.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/tmp.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/torch_loader.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/logger.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/markup.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/fastcores.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/sklegos.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/cli.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/ipython.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/loader.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/s3_loader.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/imgaug_loader.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/zen.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/icecream.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/dates.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/profiler.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncreating build/bdist.macosx-11.1-arm64/wheel/torch_snippets/thinc_parser\ncopying build/lib/torch_snippets/thinc_parser/__init__.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/thinc_parser\ncopying build/lib/torch_snippets/thinc_parser/parser.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/thinc_parser\ncopying build/lib/torch_snippets/bokeh_loader.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/video.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/scp.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncreating build/bdist.macosx-11.1-arm64/wheel/torch_snippets/trainer\ncopying build/lib/torch_snippets/trainer/neural_graph.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/trainer\ncopying build/lib/torch_snippets/trainer/hooks.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/trainer\ncopying build/lib/torch_snippets/trainer/capsule.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/trainer\ncopying build/lib/torch_snippets/trainer/config.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/trainer\ncopying build/lib/torch_snippets/trainer/__init__.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets/trainer\ncopying build/lib/torch_snippets/bb_utils.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/__module_timing__.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/adapters.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\ncopying build/lib/torch_snippets/decorators.py -&gt; build/bdist.macosx-11.1-arm64/wheel/torch_snippets\nrunning install_egg_info\nCopying torch_snippets.egg-info to build/bdist.macosx-11.1-arm64/wheel/torch_snippets-0.545-py3.12.egg-info\nrunning install_scripts\ncreating build/bdist.macosx-11.1-arm64/wheel/torch_snippets-0.545.dist-info/WHEEL\ncreating 'dist/torch_snippets-0.545-py3-none-any.whl' and adding 'build/bdist.macosx-11.1-arm64/wheel' to it\nadding 'torch_snippets/__init__.py'\nadding 'torch_snippets/__module_timing__.py'\nadding 'torch_snippets/_modidx.py'\nadding 'torch_snippets/_nbdev.py'\nadding 'torch_snippets/adapters.py'\nadding 'torch_snippets/bb_utils.py'\nadding 'torch_snippets/bokeh_loader.py'\nadding 'torch_snippets/charts.py'\nadding 'torch_snippets/cli.py'\nadding 'torch_snippets/dates.py'\nadding 'torch_snippets/decorators.py'\nadding 'torch_snippets/fastcores.py'\nadding 'torch_snippets/icecream.py'\nadding 'torch_snippets/imgaug_loader.py'\nadding 'torch_snippets/inspector.py'\nadding 'torch_snippets/interactive_show.py'\nadding 'torch_snippets/ipython.py'\nadding 'torch_snippets/load_defaults.py'\nadding 'torch_snippets/loader.py'\nadding 'torch_snippets/logger.py'\nadding 'torch_snippets/markup.py'\nadding 'torch_snippets/markup2.py'\nadding 'torch_snippets/misc.py'\nadding 'torch_snippets/paths.py'\nadding 'torch_snippets/pdf_loader.py'\nadding 'torch_snippets/profiler.py'\nadding 'torch_snippets/registry.py'\nadding 'torch_snippets/s3_loader.py'\nadding 'torch_snippets/scp.py'\nadding 'torch_snippets/sklegos.py'\nadding 'torch_snippets/text_utils.py'\nadding 'torch_snippets/tmp.py'\nadding 'torch_snippets/torch_loader.py'\nadding 'torch_snippets/video.py'\nadding 'torch_snippets/zen.py'\nadding 'torch_snippets/thinc_parser/__init__.py'\nadding 'torch_snippets/thinc_parser/parser.py'\nadding 'torch_snippets/trainer/__init__.py'\nadding 'torch_snippets/trainer/capsule.py'\nadding 'torch_snippets/trainer/config.py'\nadding 'torch_snippets/trainer/hooks.py'\nadding 'torch_snippets/trainer/neural_graph.py'\nadding 'torch_snippets-0.545.dist-info/LICENSE'\nadding 'torch_snippets-0.545.dist-info/LICENSE.txt'\nadding 'torch_snippets-0.545.dist-info/METADATA'\nadding 'torch_snippets-0.545.dist-info/WHEEL'\nadding 'torch_snippets-0.545.dist-info/entry_points.txt'\nadding 'torch_snippets-0.545.dist-info/top_level.txt'\nadding 'torch_snippets-0.545.dist-info/RECORD'\nremoving build/bdist.macosx-11.1-arm64/wheel\nUploading distributions to https://upload.pypi.org/legacy/\nUploading torch_snippets-0.545-py3-none-any.whl\n100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.8/125.8 kB • 00:01 • 158.0 MB/s\nWARNING  Error during upload. Retry with the --verbose option for more details. \nERROR    HTTPError: 400 Bad Request from https://upload.pypi.org/legacy/        \n         File already exists ('torch_snippets-0.545-py3-none-any.whl', with     \n         blake2_256 hash                                                        \n         '97db9be264982980d1d4d99a72a0d916ebcd547b529d3d1e39edc39c4255b7ff').   \n         See https://pypi.org/help/#file-name-reuse for more information.       \n\n\n\nfrom torch_snippets import *\n\nVERSION = find(\"version\", readlines(\"settings.ini\")).split(\"=\")[1].strip()\n\n!git add .\n!git commit -m {VERSION}\n!git push\n\n[10/02/24 18:43:56] INFO     loaded 27 lines                                                                                                         678460756.py:&lt;module&gt;:2\n\n\n\n[master bc99bbb] 0.545\n 27 files changed, 446 insertions(+), 598 deletions(-)\n create mode 100644 _proc/sidebar.yml.bak\nEnumerating objects: 63, done.\nCounting objects: 100% (63/63), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (32/32), done.\nWriting objects: 100% (32/32), 6.29 KiB | 6.29 MiB/s, done.\nTotal 32 (delta 30), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (30/30), completed with 30 local objects.\nTo ssh://github.com/sizhky/torch_snippets\n   532b946..bc99bbb  master -&gt; master"
  },
  {
    "objectID": "s3_loader2.html",
    "href": "s3_loader2.html",
    "title": "torch_snippets",
    "section": "",
    "text": "# from torch_snippets.s3_loader2 import S3FileHandler\n\naws_access_key_id = \"AKIAQFXXXXXXXX6CN\"\naws_secret_access_key = \"AC3XXXXZXXXXXXXXXXXXXXXXXXejfXXXXXXh\"\n\n\nmys3 = S3FileHandler(aws_access_key_id, aws_secret_access_key)\n\n\nList all Buckets\nTo lists all the s3 buckets in s3 for given credentials\n\nmys3.list_s3_buckets()\n\n['buckettest0011',\n 'candidate-proctoring',\n 'sagemaker-ap-south-1-011528263565',\n 'sagemaker-studio-011528263565-u1h3juay9nd',\n 'sentiment-classification-fastapi']\n\n\n\n\nList all file objects\nList all files in an S3 bucket or within a specific prefix of the given bucket along with the file size.\n:param bucket_name: str. Name of the S3 bucket.\n:param key: str or None. Specific prefix to list files from, defaults to None.\n\nmys3.list_s3_objects(bucket_name=\"buckettest0011\")\n\n{'attendee_db/sumanth.jpg': 170670,\n 'attendee_db/test/test/line_profiling_results.txt': 921,\n 'attendee_db/test/test/outer_function_profile.txt': 2845,\n 'attendee_db/test_2.mp4': 16330195,\n 'test/test': 921,\n 'test/test/line_profiling_results.txt': 921,\n 'test/test/outer_function_profile.txt': 2845}\n\n\n\n\nS3 Folder Download\nDownload all files from an S3 bucket prefix to a local directory.\n:param bucket_name: str. Name of the S3 bucket.\n:param local_dir: str. Local directory to which files will be downloaded.\n:param prefix: str or None. Prefix path of the folder in the bucket. If None, the whole bucket is downloaded.\n:param verbose: bool. Display the download status\n\nmys3.download_s3_folder(\n    bucket_name=\"buckettest0011\", local_dir=\".\", prefix=\"test/test\", verbose=1\n)\n\ntest/test/\nDownloaded test/test/line_profiling_results.txt to ./test/line_profiling_results.txt\nDownloaded test/test/outer_function_profile.txt to ./test/outer_function_profile.txt\n\n\n\n\nS3 File Download\nDownload a specific file from an S3 bucket and optionally return its metadata.\n:param bucket_name: str. Name of the S3 bucket.\n:param key: str. The key of the file in the S3 bucket.\n:param local_dir: str. Local directory to which the file will be downloaded.\n:param metadata: bool. If True, return the file’s metadata; otherwise, return None.\n:param verbose: bool.\n:return: dict or None. Returns metadata of the file if metadata is True, otherwise None.\n\nmys3.download_s3_file(\n    bucket_name=\"buckettest0011\",\n    key=\"test/test/outer_function_profile.txt\",\n    local_dir=\".\",\n    metadata=True,\n)\n\n{'ResponseMetadata': {'RequestId': 'D699DNH1XH4995EM',\n  'HostId': 'R8MIFqVr0MyVvOwbfM+ZkrgLyxHsPTp8HCqC/x0L5gR+rr9NIQZcVFwJWsmidXJe+VZRclVnONw=',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amz-id-2': 'R8MIFqVr0MyVvOwbfM+ZkrgLyxHsPTp8HCqC/x0L5gR+rr9NIQZcVFwJWsmidXJe+VZRclVnONw=',\n   'x-amz-request-id': 'D699DNH1XH4995EM',\n   'date': 'Wed, 16 Oct 2024 05:48:23 GMT',\n   'last-modified': 'Tue, 15 Oct 2024 09:40:40 GMT',\n   'etag': '\"7c49753bd7d2109ce96bd2568ad8fbef\"',\n   'x-amz-server-side-encryption': 'AES256',\n   'x-amz-meta-author': 'XXXXX',\n   'accept-ranges': 'bytes',\n   'content-type': 'binary/octet-stream',\n   'server': 'AmazonS3',\n   'content-length': '2845'},\n  'RetryAttempts': 0},\n 'AcceptRanges': 'bytes',\n 'LastModified': datetime.datetime(2024, 10, 15, 9, 40, 40, tzinfo=tzutc()),\n 'ContentLength': 2845,\n 'ETag': '\"7c49753bd7d2109ce96bd2568ad8fbef\"',\n 'ContentType': 'binary/octet-stream',\n 'ServerSideEncryption': 'AES256',\n 'Metadata': {'author': 'XXXXX'}}\n\n\n\n\nUploading file from local to s3 with/without metadata\nUpload a file to an S3 bucket with optional metadata.\n:param bucket_name: str. Name of the S3 bucket.\n:param localfile_path: str. Local path to the file to be uploaded.\n:param s3_key: str. S3 key (path within the bucket) where the file will be stored with file name included.\n:param metadata: dict or None. Optional metadata for the file. Defaults to None.\n\nmys3.upload_file_to_s3(\n    bucket_name=\"buckettest0011\",\n    localfile_path=\"/home/user/Documents/line_profiling_results.txt\",\n    s3_key=\"test/test/line_profiling_results.txt\",\n)\n\nFile uploaded successfully to buckettest0011/test/test/line_profiling_results.txt\n\n\n\nmetadata = {\"author\": \"xxxxx\"}\nmys3.upload_file_to_s3(\n    bucket_name=\"buckettest0011\",\n    localfile_path=\"/home/user/Documents/line_profiling_results.txt\",\n    s3_key=\"test/test/line_profiling_results.txt\",\n    metadata=metadata,\n)\n\nFile uploaded successfully to buckettest0011/test/test/line_profiling_results.txt\n\n\nNow lets check by downloading the uploaded file if the metadata is present or not\n\nmys3.download_s3_file(\n    bucket_name=\"buckettest0011\",\n    key=\"test/test/line_profiling_results.txt\",\n    local_dir=\".\",\n    metadata=True,\n    verbose=1,\n)\n\nDownloaded test/test/line_profiling_results.txt to ./line_profiling_results.txt\n\n\n{'ResponseMetadata': {'RequestId': 'D69ARVG7KASXKQH1',\n  'HostId': 'Je/oIjsM1FAf2psIv4aoclG62HSr9CGpXR/zvagTThcupuCz5FsMdN7ecT243Of+/jH2mOCha30=',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'x-amz-id-2': 'Je/oIjsM1FAf2psIv4aoclG62HSr9CGpXR/zvagTThcupuCz5FsMdN7ecT243Of+/jH2mOCha30=',\n   'x-amz-request-id': 'D69ARVG7KASXKQH1',\n   'date': 'Wed, 16 Oct 2024 05:48:23 GMT',\n   'last-modified': 'Wed, 16 Oct 2024 05:48:23 GMT',\n   'etag': '\"5a627cd11fe9a0ec5877b4a4f0f33a62\"',\n   'x-amz-server-side-encryption': 'AES256',\n   'x-amz-meta-author': 'xxxxx',\n   'accept-ranges': 'bytes',\n   'content-type': 'binary/octet-stream',\n   'server': 'AmazonS3',\n   'content-length': '921'},\n  'RetryAttempts': 0},\n 'AcceptRanges': 'bytes',\n 'LastModified': datetime.datetime(2024, 10, 16, 5, 48, 23, tzinfo=tzutc()),\n 'ContentLength': 921,\n 'ETag': '\"5a627cd11fe9a0ec5877b4a4f0f33a62\"',\n 'ContentType': 'binary/octet-stream',\n 'ServerSideEncryption': 'AES256',\n 'Metadata': {'author': 'xxxxx'}}\n\n\n\n\nUploading entire folder from local to s3 with/without metadata\nUpload all files in a local folder to an S3 bucket with optional metadata.\n:param bucket_name: str. Name of the S3 bucket.\n:param local_folder_path: str. Local path to the folder to be uploaded.\n:param s3_prefix: str. S3 prefix (folder path within the bucket) where the files will be stored.\nDefaults to the root of the bucket.\n:param metadata: dict or None. Optional metadata for the files. Defaults to None.\n\nmys3.upload_folder_to_s3(\n    \"buckettest0011\", \"/home/user/Documents/attendee_db\", verbose=1\n)\n\nUploaded attendee_db/sumanth.jpg to buckettest0011/attendee_db/sumanth.jpg\nUploaded attendee_db/test_2.mp4 to buckettest0011/attendee_db/test_2.mp4\nUploaded attendee_db/test/test/outer_function_profile.txt to buckettest0011/attendee_db/test/test/outer_function_profile.txt\nUploaded attendee_db/test/test/line_profiling_results.txt to buckettest0011/attendee_db/test/test/line_profiling_results.txt",
    "crumbs": [
      "List all Buckets"
    ]
  }
]